{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tabular ukraine data\n",
    "ukraine_data = pd.read_csv('data/tabular_data_ukraine.csv')\n",
    "\n",
    "# delete Kyiv and Kyiv_Oblast\n",
    "# ukraine_data = ukraine_data[ukraine_data[\"region\"] != \"Kyiv\"]\n",
    "# ukraine_data = ukraine_data[ukraine_data[\"region\"] != \"Kyiv_Oblast\"]\n",
    "ukraine_data = ukraine_data[ukraine_data[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "\n",
    "\n",
    "# get training, test, pre_war and prediction data\n",
    "train_data = ukraine_data[ukraine_data['year'] < 2021]\n",
    "test_data = ukraine_data[ukraine_data['year'] == 2021]\n",
    "pre_war_data = ukraine_data[ukraine_data['year'] < 2022]\n",
    "prediction_data = ukraine_data[ukraine_data['year'] == 2022]\n",
    "\n",
    "# reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "pre_war_data = pre_war_data.reset_index(drop=True)\n",
    "prediction_data = prediction_data.reset_index(drop=True)\n",
    "\n",
    "# column_prefixes = (\"nearnad_snow_cov\", \"nearnad_snow_free\", \"offnad_snow_cov\",\n",
    "#                    \"offnad_snow_free\", \"allangle_snow_cov\", \"allangle_snow_free\", \n",
    "#                    \"nearnad_snow_free_hq\", \"offnad_snow_free_hq\", \"allangle_snow_free_hq\")\n",
    "\n",
    "# column_prefixes = (\"nearnad_snow_free_hq\", \"offnad_snow_free_hq\", \"allangle_snow_free_hq\")\n",
    "\n",
    "column_prefixes = [\"allangle_snow_free_hq\"]\n",
    "\n",
    "general_characteristics = (\"sum\", \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_war_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "pre_war_data_diff = pre_war_data.groupby('region').diff()\n",
    "pre_war_data_diff['region'] = pre_war_data['region']\n",
    "pre_war_data_diff['year'] = pre_war_data['year']\n",
    "pre_war_data_diff.reset_index(drop=True, inplace=True)\n",
    "pre_war_data_diff = pre_war_data_diff[pre_war_data_diff['year'] != 2012]\n",
    "\n",
    "prediction_data = pd.concat([ukraine_data[ukraine_data['year'] == 2022], ukraine_data[ukraine_data['year'] == 2021]])\n",
    "prediction_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "prediction_data['real_gdp'] = 0\n",
    "prediction_data_diff = prediction_data.groupby('region').diff()\n",
    "prediction_data_diff['region'] = prediction_data['region']\n",
    "prediction_data_diff['year'] = prediction_data['year']\n",
    "prediction_data_diff.reset_index(drop=True, inplace=True)\n",
    "prediction_data_diff = prediction_data_diff[prediction_data_diff['year'] == 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define general functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'eta': [0.01, 0.1, 0.2, 0.3],\n",
    "    'gamma': [10, 20, 50, 100],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_child_weight': [3, 4, 5, 6],\n",
    "    'random_state': [0] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished allangle_snow_free_hq\n"
     ]
    }
   ],
   "source": [
    "# initialise a df to store the results\n",
    "xgb_results = pd.DataFrame(columns=[\"prefix\", \"columns\", \"mae\", \"mpe\", \"national_gdp_change\"])\n",
    "\n",
    "for prefix in column_prefixes:\n",
    "    # create general column names\n",
    "    general_columns, log_bin_columns, idr_bin_columns = create_column_names(prefix, general_characteristics)\n",
    "    \n",
    "    # build xgb models for each year, calculate average mpe and mse, predict the national gdp change, add the results to the df\n",
    "    for selected_columns, columns_category in zip([log_bin_columns], [\"log_bin\"]):\n",
    "        mae, mpe, gdp_change, y_pred, best_params, metrics = build_model_and_predict(pre_war_data_diff, prediction_data_diff, selected_columns, \"xgboost\", param_grid_xgb, log_transform = False, scale = False, total_metrics = True, diff = True)\n",
    "        new_results = pd.DataFrame([{\"prefix\": prefix, \"columns\": columns_category, \"mae\": mae, \"mpe\": mpe, \"national_gdp_change\": gdp_change}])\n",
    "        xgb_results = pd.concat([xgb_results, new_results], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished {prefix}\")\n",
    "\n",
    "# save metrics as a csv\n",
    "metrics.to_csv(\"xgb_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 10, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 8, 'max_leaves': None, 'min_child_weight': 3, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 0, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'eta': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "# 'gamma': 10, 'max_depth': 8, 'min_child_weight': 3,  'eta': 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, 20],  # Maximum depth of the tree\n",
    "    'min_samples_split': [1, 2, 4],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'random_state': [0],  # Ensures reproducibility\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished allangle_snow_free_hq\n"
     ]
    }
   ],
   "source": [
    "# initialise a df to store the results\n",
    "rf_results = pd.DataFrame(columns=[\"prefix\", \"columns\", \"mae\", \"mpe\", \"national_gdp_change\"])\n",
    "\n",
    "for prefix in column_prefixes:\n",
    "    # create general column names\n",
    "    general_columns, log_bin_columns, idr_bin_columns = create_column_names(prefix, general_characteristics)\n",
    "    \n",
    "    # build xgb models and predict the national gdp change, add the results to the df\n",
    "    for selected_columns, columns_category in zip([log_bin_columns], [\"log_bin\"]):\n",
    "        mae, mpe, gdp_change, y_pred, best_params, metrics = build_model_and_predict(pre_war_data_diff, prediction_data_diff, selected_columns, \"random_forest\", param_grid_rf, log_transform = False, scale = False, total_metrics = True, diff = True)\n",
    "        new_results = pd.DataFrame([{\"prefix\": prefix, \"columns\": columns_category, \"mae\": mae, \"mpe\": mpe, \"national_gdp_change\": gdp_change}])\n",
    "        rf_results = pd.concat([rf_results, new_results], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished {prefix}\")\n",
    "\n",
    "# save metrics as a csv\n",
    "metrics.to_csv(\"rf_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 15, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 4, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "# 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50 'max_depth': 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Lasso\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 0.5, 1]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a df to store the results\n",
    "lasso_results = pd.DataFrame(columns=[\"prefix\", \"columns\", \"mae\", \"mpe\", \"national_gdp_change\"])\n",
    "\n",
    "for prefix in column_prefixes:\n",
    "    # create general column names\n",
    "    general_columns, log_bin_columns, idr_bin_columns = create_column_names(prefix, general_characteristics)\n",
    "    \n",
    "    # build xgb models and predict the national gdp change, add the results to the df\n",
    "    for selected_columns, columns_category in zip([general_columns, log_bin_columns, idr_bin_columns], [\"general\", \"log_bin\", \"idr_bin\"]):\n",
    "        mae, mpe, gdp_change, best_params = build_model_and_predict(pre_war_data, prediction_data, selected_columns, \"lasso\", param_grid_lasso, log_transform = False, scale = False, total_metrics = True)\n",
    "        new_results = pd.DataFrame([{\"prefix\": prefix, \"columns\": columns_category, \"mae\": mae, \"mpe\": mpe, \"national_gdp_change\": gdp_change}])\n",
    "        lasso_results = pd.concat([lasso_results, new_results], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished {prefix}\")\n",
    "\n",
    "# sort by mae, print the results\n",
    "lasso_results = lasso_results.sort_values(by=\"mae\")\n",
    "print(lasso_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
