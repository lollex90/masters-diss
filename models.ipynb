{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "from dnb_annual import *\n",
    "from variables import years, composites, ukr_region_map, pol_region_map\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Resizing, Dropout, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Input, Reshape, Conv2DTranspose, Cropping2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tabular ukraine data\n",
    "ukraine_data = pd.read_csv('data/tabular_data_ukraine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the region column into a categorical variable using one hot encoding\n",
    "# ukraine_data = pd.get_dummies(ukraine_data, columns=[\"region\"])\n",
    "\n",
    "# get training, test, pre_war and prediction data\n",
    "train_data = ukraine_data[ukraine_data['year'] < 2021]\n",
    "test_data = ukraine_data[ukraine_data['year'] == 2021]\n",
    "pre_war_data = ukraine_data[ukraine_data['year'] < 2022]\n",
    "prediction_data = ukraine_data[ukraine_data['year'] > 2021]\n",
    "\n",
    "column_prefixes = (\"nearnad_snow_cov\", \"nearnad_snow_free\", \"offnad_snow_cov\",\n",
    "                   \"offnad_snow_free\", \"allangle_snow_cov\", \"allangle_snow_free\", \n",
    "                   \"nearnad_snow_free_hq\", \"offnad_snow_free_hq\", \"allangle_snow_free_hq\")\n",
    "\n",
    "general_characteristics = (\"num_zeros\", \"sum\", \"mean\", \"median\", \"sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_sets(selected_columns, train_data, test_data, scale = False):\n",
    "\n",
    "    # select columns\n",
    "    train_data_selected = train_data[[\"real_gdp\", \"region\"] + selected_columns]\n",
    "    test_data_selected = test_data[[\"real_gdp\", \"region\"] + selected_columns]\n",
    "\n",
    "    # one hot encode region\n",
    "    train_data_selected = pd.get_dummies(train_data_selected, columns=[\"region\"])\n",
    "    test_data_selected = pd.get_dummies(test_data_selected, columns=[\"region\"])\n",
    "\n",
    "    return train_data_selected, test_data_selected\n",
    "\n",
    "def build_xgboost_model(train_data, test_data, selected_columns):\n",
    "\n",
    "    # build train and test sets\n",
    "    train_data_selected, test_data_selected = build_train_test_sets(selected_columns, train_data, test_data)\n",
    "\n",
    "    # get input and output data\n",
    "    X_train = train_data_selected.drop(columns=[\"real_gdp\"])\n",
    "    y_train = train_data_selected[\"real_gdp\"]\n",
    "\n",
    "    X_test = test_data_selected.drop(columns=[\"real_gdp\"])\n",
    "    y_test = test_data_selected[\"real_gdp\"]\n",
    "\n",
    "    # build xgboost model\n",
    "    model = xgb.XGBRegressor(objective ='reg:squarederror', random_state=0)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # calculate mse and mpe\n",
    "    mse = np.mean((y_pred - y_test)**2)\n",
    "    mpe = np.mean(100*(y_pred - y_test) / y_test)\n",
    "\n",
    "    return y_pred, mse, mpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General MSE:  11410510.001277847\n",
      "Log Bin MSE:  77482191.46609668\n",
      "IDR Bin MSE:  115190282.79653612\n",
      "General MPE:  2.4028691400937676\n",
      "Log Bin MPE:  8.959852910793174\n",
      "IDR Bin MPE:  5.49072604468757\n"
     ]
    }
   ],
   "source": [
    "prefix = \"nearnad_snow_free\"\n",
    "\n",
    "# create general column names: prefix + general_characteristics\n",
    "general_columns = [prefix + \"_\" + char for char in general_characteristics]\n",
    "log_bin_columns = [prefix + \"_log_\" + str(i) for i in range(1, 11)]\n",
    "idr_bin_columns = [prefix + \"_idr_\" + str(i) for i in range(1, 11)]\n",
    "\n",
    "# build cgb models\n",
    "y_pred_general, mse_general, mpe_general = build_xgboost_model(train_data, test_data, general_columns)\n",
    "y_pred_log_bin, mse_log_bin, mpe_log_bin = build_xgboost_model(train_data, test_data, log_bin_columns)\n",
    "y_pred_idr_bin, mse_idr_bin, mpe_idr_bin = build_xgboost_model(train_data, test_data, idr_bin_columns)\n",
    "\n",
    "print(\"General MSE: \", mse_general)\n",
    "print(\"Log Bin MSE: \", mse_log_bin)\n",
    "print(\"IDR Bin MSE: \", mse_idr_bin)\n",
    "\n",
    "print(\"General MPE: \", mpe_general)\n",
    "print(\"Log Bin MPE: \", mpe_log_bin)\n",
    "print(\"IDR Bin MPE: \", mpe_idr_bin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
