{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tabular ukraine data\n",
    "ukraine_data = pd.read_csv('data/tabular_data_ukraine.csv')\n",
    "\n",
    "# get training, test, pre_war and prediction data\n",
    "train_data = ukraine_data[ukraine_data['year'] < 2021]\n",
    "test_data = ukraine_data[ukraine_data['year'] == 2021]\n",
    "pre_war_data = ukraine_data[ukraine_data['year'] < 2022]\n",
    "prediction_data = ukraine_data[ukraine_data['year'] == 2022]\n",
    "\n",
    "# column_prefixes = (\"nearnad_snow_cov\", \"nearnad_snow_free\", \"offnad_snow_cov\",\n",
    "#                    \"offnad_snow_free\", \"allangle_snow_cov\", \"allangle_snow_free\", \n",
    "#                    \"nearnad_snow_free_hq\", \"offnad_snow_free_hq\", \"allangle_snow_free_hq\")\n",
    "\n",
    "column_prefixes = (\"nearnad_snow_free_hq\", \"offnad_snow_free_hq\", \"allangle_snow_free_hq\")\n",
    "\n",
    "# column_prefixes = (\"nearnad_snow_free_hq\")\n",
    "\n",
    "general_characteristics = (\"mean\", \"sd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_sets(selected_columns, train_data, test_data, log_transform = False, scale = False):\n",
    "\n",
    "    # select columns\n",
    "    train_data_selected = train_data[[\"real_gdp\", \"region\", \"year\"] + selected_columns]\n",
    "    test_data_selected = test_data[[\"real_gdp\", \"region\", \"year\"] + selected_columns]\n",
    "\n",
    "    if log_transform:\n",
    "        # real_gdp and columns that contain the word\"sum\" are log transformed\n",
    "        train_data_selected[\"real_gdp\"] = np.log(train_data_selected[\"real_gdp\"])\n",
    "        test_data_selected[\"real_gdp\"] = np.log(test_data_selected[\"real_gdp\"])\n",
    "\n",
    "        for column in selected_columns:\n",
    "            if \"sum\" in column:\n",
    "                train_data_selected[column] = np.log(train_data_selected[column])\n",
    "                test_data_selected[column] = np.log(test_data_selected[column])\n",
    "\n",
    "    if scale:\n",
    "        # scale the data\n",
    "        scaler = MinMaxScaler()\n",
    "        train_data_selected[selected_columns] = scaler.fit_transform(train_data_selected[selected_columns])\n",
    "        test_data_selected[selected_columns] = scaler.transform(test_data_selected[selected_columns])\n",
    "\n",
    "        # scale the real_gdp\n",
    "        train_data_selected[\"real_gdp\"] = scaler.fit_transform(train_data_selected[[\"real_gdp\"]])\n",
    "        test_data_selected[\"real_gdp\"] = scaler.transform(test_data_selected[[\"real_gdp\"]])\n",
    "\n",
    "    # one hot encode region\n",
    "    train_data_selected = pd.get_dummies(train_data_selected, columns=[\"region\"])\n",
    "    test_data_selected = pd.get_dummies(test_data_selected, columns=[\"region\"])\n",
    "\n",
    "    return train_data_selected, test_data_selected\n",
    "\n",
    "def build_model(train_data, test_data, selected_columns, model_type, param_grid, log_transform = False, scale = False):\n",
    "\n",
    "    # build train and test sets\n",
    "    train_data_selected, test_data_selected = build_train_test_sets(selected_columns, train_data, test_data, log_transform, scale)\n",
    "\n",
    "    # get input and output data\n",
    "    X_train = train_data_selected.drop(columns=[\"real_gdp\", \"year\"])\n",
    "    y_train = train_data_selected[\"real_gdp\"]\n",
    "\n",
    "    X_test = test_data_selected.drop(columns=[\"real_gdp\", \"year\"])\n",
    "    y_test = test_data_selected[\"real_gdp\"]\n",
    "\n",
    "    # build model\n",
    "    if model_type == \"xgboost\":\n",
    "        model_test = xgb.XGBRegressor()\n",
    "    elif model_type == \"random_forest\":\n",
    "        model_test = RandomForestRegressor()\n",
    "    elif model_type == \"lasso\":\n",
    "        model_test = Lasso()\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    grid_search = GridSearchCV(estimator=model_test, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = best_model.get_params()\n",
    "\n",
    "    # random_search = RandomizedSearchCV(estimator=model_test, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    # random_search.fit(X_train, y_train)\n",
    "    # best_model = random_search.best_estimator_\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # calculate mse and mpe\n",
    "    mae = np.mean(abs(y_pred - y_test))\n",
    "    mpe = abs(np.mean(100*(y_pred - y_test) / y_test))\n",
    "\n",
    "    return mae, mpe, best_params\n",
    "\n",
    "\n",
    "def predict_with_model(pre_war_data, prediction_data, selected_columns, model_type, param_grid, log_transform = False, scale = False):\n",
    "\n",
    "    # build pre war and prediction sets\n",
    "    pre_war_data_selected, prediction_data_selected = build_train_test_sets(selected_columns, pre_war_data, prediction_data, log_transform, scale)\n",
    "\n",
    "    # get input and output data\n",
    "    X_pre_war = pre_war_data_selected.drop(columns=[\"real_gdp\", \"year\"])\n",
    "    y_pre_war = pre_war_data_selected[\"real_gdp\"]\n",
    "    data_2021 = pre_war_data_selected[pre_war_data_selected[\"year\"] == 2021]\n",
    "\n",
    "    X_prediction = prediction_data_selected.drop(columns=[\"real_gdp\", \"year\"])\n",
    "\n",
    "    # build model, objective: absolute error\n",
    "    if model_type == \"xgboost\":\n",
    "        model_pred = xgb.XGBRegressor()\n",
    "    elif model_type == \"random_forest\":\n",
    "        model_pred = RandomForestRegressor()\n",
    "    elif model_type == \"lasso\":\n",
    "        model_pred = Lasso()\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    grid_search = GridSearchCV(estimator=model_pred, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_pre_war, y_pre_war)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = best_model.get_params()\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = best_model.predict(X_prediction)\n",
    "\n",
    "    # calculate the predicted change in the real gdp on the national level\n",
    "    # if log_transform:\n",
    "    #     y_pred = np.exp(y_pred)\n",
    "    pred_gdp_change = 100*(np.sum(y_pred) - np.sum(data_2021[\"real_gdp\"])) / np.sum(data_2021[\"real_gdp\"])\n",
    "\n",
    "    return pred_gdp_change, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_names(prefix, general_characteristics):\n",
    "    general_columns = [prefix + \"_\" + char for char in general_characteristics]\n",
    "    log_bin_columns = [prefix + \"_log_\" + str(i) for i in range(1, 11)] + general_columns\n",
    "    idr_bin_columns = [prefix + \"_idr_\" + str(i) for i in range(1, 11)] + general_columns\n",
    "    \n",
    "    return general_columns, log_bin_columns, idr_bin_columns\n",
    "\n",
    "def build_model_and_predict(pre_war_data, prediction_data, selected_columns, model_type, param_grid, log_transform, scale = False, total_metrics = False):\n",
    "\n",
    "    if total_metrics:\n",
    "        total_mae = 0\n",
    "        total_mpe = 0\n",
    "        \n",
    "        for year in range(2012, 2022):\n",
    "\n",
    "            train_data = pre_war_data[pre_war_data['year'] != year]\n",
    "            test_data = pre_war_data[pre_war_data['year'] == year]     \n",
    "            mae, mpe, best_params = build_model(train_data, test_data, selected_columns, model_type, param_grid, log_transform, scale)\n",
    "\n",
    "            total_mae += mae/10\n",
    "            total_mpe += mpe/10\n",
    "\n",
    "        gdp_change, best_params = predict_with_model(pre_war_data, prediction_data, selected_columns, model_type, param_grid, log_transform, scale)\n",
    "        \n",
    "        return total_mae, total_mpe, gdp_change, best_params\n",
    "\n",
    "    else:\n",
    "\n",
    "        train_data = pre_war_data[pre_war_data['year'] != 2021]\n",
    "        test_data = pre_war_data[pre_war_data['year'] == 2021]\n",
    "        mae, mpe, _ = build_model(train_data, test_data, selected_columns, model_type, param_grid, log_transform, scale)\n",
    "        gdp_change, best_params = predict_with_model(pre_war_data, prediction_data, selected_columns, model_type, param_grid, log_transform, scale)\n",
    "\n",
    "        return mae, mpe, gdp_change, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for XGBoost\n",
    "# param_grid_xgb = {\n",
    "#     'max_depth': [5, 4, 6],\n",
    "#     'min_child_weight': [6, 4, 5],\n",
    "#     'random_state': [0] \n",
    "# }\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'eta': [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "    'gamma': [100, 1000, 10000],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_child_weight': [1, 2, 5],\n",
    "    'random_state': [0] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23684/3297674820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountry_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcountry_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountry_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcountry_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_transform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mgdp_change\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_with_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_war_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_transform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23684/2652454787.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(train_data, test_data, selected_columns, model_type, param_grid, log_transform, scale)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# hyperparameter tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakub\\anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "country_data = pre_war_data\n",
    "prefix = \"allangle_snow_free_hq\"\n",
    "selected_columns =  [prefix + \"_\" + char for char in general_characteristics] + [prefix + \"_log_\" + str(i) for i in range(1, 11)]\n",
    "model_type = \"xgboost\"\n",
    "log_transform = False\n",
    "scale = False\n",
    "\n",
    "train_data = country_data[country_data['year'] != year]\n",
    "test_data = country_data[country_data['year'] == year]     \n",
    "mae, mpe, _ = build_model(train_data, test_data, selected_columns, model_type, param_grid_xgb, log_transform, scale)\n",
    "gdp_change, best_params = predict_with_model(pre_war_data, prediction_data, selected_columns, model_type, param_grid_xgb, log_transform, scale)\n",
    "\n",
    "\n",
    "print(gdp_change, best_params)\n",
    "print(mae, mpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished nearnad_snow_free_hq\n",
      "Finished offnad_snow_free_hq\n",
      "Finished allangle_snow_free_hq\n",
      "                  prefix  columns          mae        mpe  national_gdp_change\n",
      "1    offnad_snow_free_hq  log_bin  3704.532385   5.695044           -40.886053\n",
      "2  allangle_snow_free_hq  log_bin  4197.752625   5.017379           -32.501726\n",
      "0   nearnad_snow_free_hq  log_bin  5857.776513  12.238803           121.917465\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 100, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 6, 'max_leaves': None, 'min_child_weight': 5, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 0, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'eta': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# very promising results with nearnad_snow_free_hq, idr_bin_columns + general_columns (mean, median, sd, sum) with log transform and scale\n",
    "\n",
    "# initialise a df to store the results\n",
    "xgb_results = pd.DataFrame(columns=[\"prefix\", \"columns\", \"mae\", \"mpe\", \"national_gdp_change\"])\n",
    "\n",
    "for prefix in column_prefixes:\n",
    "    # create general column names\n",
    "    general_columns, log_bin_columns, idr_bin_columns = create_column_names(prefix, general_characteristics)\n",
    "    \n",
    "    # build xgb models for each year, calculate average mpe and mse, predict the national gdp change, add the results to the df\n",
    "    for selected_columns, columns_category in zip([log_bin_columns], [\"log_bin\"]):\n",
    "        mae, mpe, gdp_change, best_params = build_model_and_predict(pre_war_data, prediction_data, selected_columns, \"xgboost\", param_grid_xgb, log_transform = False, scale = False, total_metrics = True)\n",
    "        new_results = pd.DataFrame([{\"prefix\": prefix, \"columns\": columns_category, \"mae\": mae, \"mpe\": mpe, \"national_gdp_change\": gdp_change}])\n",
    "        xgb_results = pd.concat([xgb_results, new_results], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished {prefix}\")\n",
    "\n",
    "# sort by mae, print the results\n",
    "xgb_results = xgb_results.sort_values(by=\"mae\")\n",
    "print(xgb_results)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'random_state': [0],  # Ensures reproducibility\n",
    "    'max_depth': [10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished nearnad_snow_free_hq\n",
      "Finished offnad_snow_free_hq\n",
      "Finished allangle_snow_free_hq\n",
      "                  prefix  columns          mae       mpe  national_gdp_change\n",
      "2  allangle_snow_free_hq  log_bin  3694.764568  3.246507           -31.886836\n",
      "1    offnad_snow_free_hq  log_bin  3807.619965  2.319833           -42.694637\n",
      "0   nearnad_snow_free_hq  log_bin  3809.765291  3.103696            -2.157626\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 20, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# initialise a df to store the results\n",
    "rf_results = pd.DataFrame(columns=[\"prefix\", \"columns\", \"mae\", \"mpe\", \"national_gdp_change\"])\n",
    "\n",
    "for prefix in column_prefixes:\n",
    "    # create general column names\n",
    "    general_columns, log_bin_columns, idr_bin_columns = create_column_names(prefix, general_characteristics)\n",
    "    \n",
    "    # build xgb models and predict the national gdp change, add the results to the df\n",
    "    for selected_columns, columns_category in zip([log_bin_columns], [\"log_bin\"]):\n",
    "        mae, mpe, gdp_change, best_params = build_model_and_predict(pre_war_data, prediction_data, selected_columns, \"random_forest\", param_grid_rf, log_transform = False, scale = False, total_metrics = True)\n",
    "        new_results = pd.DataFrame([{\"prefix\": prefix, \"columns\": columns_category, \"mae\": mae, \"mpe\": mpe, \"national_gdp_change\": gdp_change}])\n",
    "        rf_results = pd.concat([rf_results, new_results], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished {prefix}\")\n",
    "\n",
    "# sort by mae, print the results\n",
    "rf_results = rf_results.sort_values(by=\"mae\")\n",
    "print(rf_results)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Lasso\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 0.5, 1]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished nearnad_snow_free_hq\n",
      "Finished offnad_snow_free_hq\n",
      "Finished allangle_snow_free_hq\n",
      "                  prefix  columns       mae       mpe  national_gdp_change\n",
      "7  allangle_snow_free_hq  log_bin  1.995504  2.485594           -49.219083\n",
      "1   nearnad_snow_free_hq  log_bin  2.018039  3.405903           -45.145320\n",
      "8  allangle_snow_free_hq  idr_bin  2.033258  3.242828           -50.658702\n",
      "6  allangle_snow_free_hq  general  2.046027  2.207463           -57.345137\n",
      "2   nearnad_snow_free_hq  idr_bin  2.068528  4.930689           -45.672186\n",
      "4    offnad_snow_free_hq  log_bin  2.087120  2.039300           -44.180048\n",
      "0   nearnad_snow_free_hq  general  2.146417  3.630255           -47.425399\n",
      "5    offnad_snow_free_hq  idr_bin  2.160240  2.726171           -51.422675\n",
      "3    offnad_snow_free_hq  general  2.227228  4.855434           -42.026040\n"
     ]
    }
   ],
   "source": [
    "# initialise a df to store the results\n",
    "lasso_results = pd.DataFrame(columns=[\"prefix\", \"columns\", \"mae\", \"mpe\", \"national_gdp_change\"])\n",
    "\n",
    "for prefix in column_prefixes:\n",
    "    # create general column names\n",
    "    general_columns, log_bin_columns, idr_bin_columns = create_column_names(prefix, general_characteristics)\n",
    "    \n",
    "    # build xgb models and predict the national gdp change, add the results to the df\n",
    "    for selected_columns, columns_category in zip([general_columns, log_bin_columns, idr_bin_columns], [\"general\", \"log_bin\", \"idr_bin\"]):\n",
    "        mae, mpe, gdp_change = build_model_and_predict(pre_war_data, prediction_data, selected_columns, \"lasso\", param_grid_lasso, log_transform = True, scale = True, total_metrics = True)\n",
    "        new_results = pd.DataFrame([{\"prefix\": prefix, \"columns\": columns_category, \"mae\": mae, \"mpe\": mpe, \"national_gdp_change\": gdp_change}])\n",
    "        lasso_results = pd.concat([lasso_results, new_results], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished {prefix}\")\n",
    "\n",
    "# sort by mae, print the results\n",
    "lasso_results = lasso_results.sort_values(by=\"mae\")\n",
    "print(lasso_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
