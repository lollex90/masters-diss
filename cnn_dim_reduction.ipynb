{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Resizing, Dropout, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Input, Reshape, Conv2DTranspose, Cropping2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from tools import define_cnn, extract_features, build_model, predict_with_model, set_seed, build_model_and_predict, extract_features_2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal CNN 10-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean gdp data, keep only year, region and real_gdp columns\n",
    "ukraine = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "log_bin_columns = [\"allangle_snow_free\" + \"_log_\" + str(i) for i in range(1, 11)]\n",
    "\n",
    "# delete Kyiv and Kyiv_Oblast\n",
    "# ukraine = ukraine[ukraine[\"region\"] != \"Kyiv\"]\n",
    "# ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast\"]\n",
    "ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "\n",
    "# get the data for 2021, 2022 and before 2022\n",
    "ukraine_2022 = ukraine[ukraine[\"year\"] == 2022]\n",
    "ukraine = ukraine[ukraine[\"year\"] < 2022]\n",
    "ukraine_2021 = ukraine[ukraine[\"year\"] == 2021]\n",
    "ukraine_2021.reset_index(drop=True, inplace=True)\n",
    "ukraine_2022.reset_index(drop=True, inplace=True)\n",
    "ukraine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialise a three dimensional array to store the images with the shape (number of images, height, width, channels)\n",
    "X = np.zeros((len(ukraine), 765, 1076, 1))\n",
    "y = np.zeros(len(ukraine))\n",
    "\n",
    "# load the images\n",
    "for i in range(len(ukraine)):\n",
    "\n",
    "    # get year, region, and gdp\n",
    "    year = ukraine[\"year\"][i]\n",
    "    region = ukraine[\"region\"][i]\n",
    "    gdp_value = ukraine[\"real_gdp\"][i]\n",
    "\n",
    "    # load the image\n",
    "    file_name = f\"{year}_{region}_hq.h5\"\n",
    "    file_path = f\"data/annual_region_images/{file_name}\"\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as annual_region:\n",
    "        allangle_snow_free = annual_region[\"AllAngle_Composite_Snow_Free\"][:]\n",
    "\n",
    "    # add the values\n",
    "    y[i] = gdp_value\n",
    "    X[i, :, :, 0] = allangle_snow_free\n",
    "\n",
    "# normalise the images and gdp data\n",
    "maximum_x = X.max()\n",
    "X = X / maximum_x\n",
    "\n",
    "maximum_y = y.max()\n",
    "y = y / maximum_y\n",
    "\n",
    "# get indices for observations in the test and train sets\n",
    "test_year = int(2017)\n",
    "test_indices = np.where(ukraine[\"year\"] == test_year)[0]\n",
    "train_indices = np.where(ukraine[\"year\"] != test_year)[0]\n",
    "\n",
    "# get the train and test sets\n",
    "X_train, y_train, X_test, y_test = X[train_indices], y[train_indices], X[test_indices], y[test_indices]\n",
    "\n",
    "# get the prediction data\n",
    "X_pred = np.zeros((len(ukraine_2022), 765, 1076, 1))\n",
    "for i in range(len(ukraine_2022)):\n",
    "\n",
    "    year = ukraine_2022[\"year\"][i]\n",
    "    region = ukraine_2022[\"region\"][i]\n",
    "\n",
    "    file_name = f\"{year}_{region}_hq.h5\"\n",
    "    file_path = f\"data/annual_region_images/{file_name}\"\n",
    "\n",
    "    with h5py.File(file_path, 'r') as annual_region:\n",
    "        allangle_snow_free = annual_region[\"AllAngle_Composite_Snow_Free\"][:]\n",
    "    \n",
    "    X_pred[i, :, :, 0] = allangle_snow_free\n",
    "\n",
    "X_pred = X_pred / maximum_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 4s 757ms/step - loss: 0.0252 - mae: 0.1237 - val_loss: 0.1268 - val_mae: 0.2861\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 1s 507ms/step - loss: 0.0231 - mae: 0.1142 - val_loss: 0.1411 - val_mae: 0.1956\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 1s 497ms/step - loss: 0.0130 - mae: 0.0792 - val_loss: 0.1317 - val_mae: 0.2108\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 1s 504ms/step - loss: 0.0116 - mae: 0.0779 - val_loss: 0.1266 - val_mae: 0.2165\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 1s 510ms/step - loss: 0.0105 - mae: 0.0782 - val_loss: 0.1327 - val_mae: 0.1958\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 2s 534ms/step - loss: 0.0096 - mae: 0.0700 - val_loss: 0.1171 - val_mae: 0.2554\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.0115 - mae: 0.0844 - val_loss: 0.1376 - val_mae: 0.1867\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 1s 480ms/step - loss: 0.0098 - mae: 0.0701 - val_loss: 0.1200 - val_mae: 0.2363\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 1s 484ms/step - loss: 0.0100 - mae: 0.0793 - val_loss: 0.1337 - val_mae: 0.1932\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 0.0096 - mae: 0.0674 - val_loss: 0.1286 - val_mae: 0.2045\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 1s 482ms/step - loss: 0.0084 - mae: 0.0714 - val_loss: 0.1236 - val_mae: 0.2189\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 1s 531ms/step - loss: 0.0082 - mae: 0.0702 - val_loss: 0.1316 - val_mae: 0.1957\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 1s 491ms/step - loss: 0.0078 - mae: 0.0657 - val_loss: 0.1273 - val_mae: 0.2076\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 1s 497ms/step - loss: 0.0076 - mae: 0.0659 - val_loss: 0.1331 - val_mae: 0.1919\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 2s 553ms/step - loss: 0.0074 - mae: 0.0623 - val_loss: 0.1270 - val_mae: 0.2055\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.0069 - mae: 0.0634 - val_loss: 0.1310 - val_mae: 0.1928\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 0.0064 - mae: 0.0597 - val_loss: 0.1253 - val_mae: 0.2041\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 2s 546ms/step - loss: 0.0059 - mae: 0.0587 - val_loss: 0.1280 - val_mae: 0.1929\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.0055 - mae: 0.0561 - val_loss: 0.1257 - val_mae: 0.1928\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 1s 478ms/step - loss: 0.0052 - mae: 0.0512 - val_loss: 0.1265 - val_mae: 0.1860\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 1s 478ms/step - loss: 0.0044 - mae: 0.0514 - val_loss: 0.1177 - val_mae: 0.1999\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.1239 - val_mae: 0.1781\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 1s 462ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.1232 - val_mae: 0.1748\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 0.0035 - mae: 0.0416 - val_loss: 0.1128 - val_mae: 0.1917\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 1s 501ms/step - loss: 0.0034 - mae: 0.0438 - val_loss: 0.1208 - val_mae: 0.1733\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.1143 - val_mae: 0.1718\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 0.0026 - mae: 0.0358 - val_loss: 0.1097 - val_mae: 0.1704\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 1s 469ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.1110 - val_mae: 0.1661\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.1050 - val_mae: 0.1675\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 1s 484ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 0.1068 - val_mae: 0.1647\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 1s 528ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.1079 - val_mae: 0.1628\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.1037 - val_mae: 0.1620\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.1028 - val_mae: 0.1616\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.1049 - val_mae: 0.1606\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 1s 479ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 0.1035 - val_mae: 0.1604\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 1s 474ms/step - loss: 9.2418e-04 - mae: 0.0190 - val_loss: 0.1008 - val_mae: 0.1601\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 1s 531ms/step - loss: 8.8367e-04 - mae: 0.0185 - val_loss: 0.1011 - val_mae: 0.1591\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 7.8323e-04 - mae: 0.0172 - val_loss: 0.1021 - val_mae: 0.1591\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 1s 483ms/step - loss: 7.3443e-04 - mae: 0.0168 - val_loss: 0.1020 - val_mae: 0.1590\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 1s 488ms/step - loss: 6.8305e-04 - mae: 0.0162 - val_loss: 0.1007 - val_mae: 0.1583\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 6.3759e-04 - mae: 0.0156 - val_loss: 0.1004 - val_mae: 0.1579\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 1s 478ms/step - loss: 6.4493e-04 - mae: 0.0158 - val_loss: 0.1015 - val_mae: 0.1577\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 5.8078e-04 - mae: 0.0152 - val_loss: 0.1005 - val_mae: 0.1573\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 1s 477ms/step - loss: 5.3564e-04 - mae: 0.0145 - val_loss: 0.0987 - val_mae: 0.1569\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 5.0770e-04 - mae: 0.0141 - val_loss: 0.0978 - val_mae: 0.1561\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 1s 457ms/step - loss: 5.8303e-04 - mae: 0.0151 - val_loss: 0.1012 - val_mae: 0.1562\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 5.2738e-04 - mae: 0.0150 - val_loss: 0.0993 - val_mae: 0.1563\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 1s 467ms/step - loss: 4.2860e-04 - mae: 0.0128 - val_loss: 0.0968 - val_mae: 0.1561\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 1s 469ms/step - loss: 4.0615e-04 - mae: 0.0125 - val_loss: 0.0967 - val_mae: 0.1560\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 3.8626e-04 - mae: 0.0122 - val_loss: 0.0969 - val_mae: 0.1553\n",
      "8/8 [==============================] - 2s 54ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Results for n_features =  4 n_conv =  2 n_dense =  4\n"
     ]
    }
   ],
   "source": [
    "# define the grid of parameters: network architecture and number of features\n",
    "param_grid_cnn = {\n",
    "    'n_features': [4],\n",
    "    'n_conv': [2],\n",
    "    'n_dense': [4],\n",
    "}\n",
    "\n",
    "# df to store the results\n",
    "cnn_results = pd.DataFrame(columns = [\"n_features\", \"n_conv\", \"n_dense\", \"mae\", \"mpe\", \"gdp_change\"])\n",
    "\n",
    "# train first stage, neural network\n",
    "for n_features in param_grid_cnn['n_features']:\n",
    "    for n_conv in param_grid_cnn['n_conv']:\n",
    "        for n_dense in param_grid_cnn['n_dense']:\n",
    "            set_seed(0)\n",
    "            model = define_cnn(n_features = n_features, n_conv = n_conv, n_dense = n_dense)\n",
    "            model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
    "            model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)\n",
    "\n",
    "            # extract features\n",
    "            # ukraine_stage_2, ukraine_2021_fea, ukraine_2022_fea = extract_features(model, ukraine, ukraine_2021, ukraine_2022, X_train, X_pred, X_test, n_features)\n",
    "            ukraine_stage_2, ukraine_test = extract_features_2(model, ukraine, test_year, X_train, X_test, n_features)\n",
    "            # del model\n",
    "\n",
    "            # train second stage, rf\n",
    "            train_data = ukraine_stage_2\n",
    "            test_data = ukraine_test\n",
    "            # test_data = ukraine_2021_fea\n",
    "            # prediction_data = ukraine_2022_fea\n",
    "            # pre_war_data = pd.concat([train_data, test_data])\n",
    "            selected_columns =  [\"feature_\" + str(i) for i in range(1, n_features+1)] + [\"allangle_snow_free_hq_sum\", \"allangle_snow_free_hq_mean\"] + log_bin_columns\n",
    "\n",
    "            # param_grid_xgb = {\n",
    "            #     'eta': [0.01, 0.1, 0.2, 0.3],\n",
    "            #     'gamma': [10, 20, 50, 100],\n",
    "            #     'max_depth': [4, 6, 8, 10],\n",
    "            #     'min_child_weight': [3, 4, 5, 6],\n",
    "            #     'random_state': [0] \n",
    "            # }\n",
    "\n",
    "            # param_grid_xgb = {\n",
    "            #     'eta': [0.01, 0.1, 0.2, 0.3],\n",
    "            #     'gamma': [10, 20, 50, 100],\n",
    "            #     'max_depth': [4, 6, 8, 10],\n",
    "            #     'min_child_weight': [3, 4, 5, 6],\n",
    "            #     'random_state': [0] \n",
    "            # }\n",
    "\n",
    "            param_grid_rf = {\n",
    "                    'n_estimators': [50, 100, 200, 300],\n",
    "                    'max_depth': [5, 10, 15, 20],  # Maximum depth of the tree\n",
    "                    'min_samples_split': [2, 4, 6, 8],  # Minimum number of samples required to split an internal node\n",
    "                    'min_samples_leaf': [2, 4, 6, 8],  # Minimum number of samples required to be at a leaf node\n",
    "                    'random_state': [0],  # Ensures reproducibility\n",
    "            }\n",
    "\n",
    "            # mae, mpe, _, pred = build_model(train_data, test_data, selected_columns, model_type, param_grid_xgb, log_transform, scale)\n",
    "            # gdp_change, best_params = predict_with_model(pre_war_data, prediction_data, selected_columns, model_type, param_grid_xgb, log_transform, scale)\n",
    "\n",
    "            # mae, mpe, gdp_change, gdp_predictions = build_model_and_predict(pre_war_data, prediction_data, selected_columns, \"xgboost\", param_grid_xgb, log_transform = False, scale = False, total_metrics = True)\n",
    "            # calculate differences\n",
    "            ukraine = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "            ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "            ukraine_sum = ukraine[['year', 'region', 'allangle_snow_free_hq_sum', 'allangle_snow_free_hq_mean'] + log_bin_columns]\n",
    "            ukraine = ukraine[ukraine[\"year\"] < 2022]\n",
    "\n",
    "            full_data = pd.concat([train_data, test_data])\n",
    "            full_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "            full_data = pd.merge(full_data, ukraine_sum, on=['year', 'region'])\n",
    "            full_data_diff = full_data.groupby('region').diff()\n",
    "            full_data_diff['region'] = full_data['region']\n",
    "            full_data_diff['year'] = full_data['year']\n",
    "            full_data_diff.reset_index(drop=True, inplace=True)\n",
    "            full_data_diff.dropna(inplace=True)\n",
    "\n",
    "            train_data_diff = full_data_diff[full_data_diff[\"year\"] != test_year]\n",
    "            test_data_diff = full_data_diff[full_data_diff[\"year\"] == test_year]\n",
    "            test_data_diff.reset_index(drop=True, inplace=True)\n",
    "            train_data_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # pre_war_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "            # pre_war_data = pd.merge(pre_war_data, ukraine_sum, on=['year', 'region'])\n",
    "            # pre_war_data_diff = pre_war_data.groupby('region').diff()\n",
    "            # pre_war_data_diff['region'] = pre_war_data['region']\n",
    "            # pre_war_data_diff['year'] = pre_war_data['year']\n",
    "            # pre_war_data_diff.reset_index(drop=True, inplace=True)\n",
    "            # pre_war_data_diff.dropna(inplace=True)\n",
    "            \n",
    "            # prediction_data = pd.concat([ukraine_2021_fea, ukraine_2022_fea])\n",
    "            # prediction_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "            # prediction_data['real_gdp'] = 0\n",
    "            # prediction_data = pd.merge(prediction_data, ukraine_sum, on=['year', 'region'])\n",
    "            # prediction_data_diff = prediction_data.groupby('region').diff()\n",
    "            # prediction_data_diff['region'] = prediction_data['region']\n",
    "            # prediction_data_diff['year'] = prediction_data['year']\n",
    "            # prediction_data_diff.reset_index(drop=True, inplace=True)\n",
    "            # prediction_data_diff.dropna(inplace=True)\n",
    "\n",
    "            # mae, mpe, gdp_change, gdp_predictions, best_params, metrics = build_model_and_predict(pre_war_data_diff, prediction_data_diff, selected_columns, \"random_forest\", param_grid_rf, \n",
    "            #                                                                                       log_transform = False, scale = False, total_metrics = True, diff = True)\n",
    "            # gdp_per_change = sum(gdp_predictions)/ukraine_2021[\"real_gdp\"].sum()\n",
    "            mae, _, _ = build_model(train_data_diff, test_data_diff, selected_columns, \"random_forest\", param_grid_rf, \n",
    "                                                                                          log_transform = False, scale = False)\n",
    "\n",
    "            # # add the results to the dataframe\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"n_features\": n_features, \n",
    "                \"n_conv\": n_conv, \n",
    "                \"n_dense\": n_dense, \n",
    "                \"mae\": mae\n",
    "                # \"mpe\": mpe, \n",
    "                # \"gdp_change\": gdp_per_change\n",
    "            }])\n",
    "            \n",
    "            cnn_results = pd.concat([cnn_results, new_row], ignore_index=True)\n",
    "\n",
    "            print(\"Results for n_features = \", n_features, \"n_conv = \", n_conv, \"n_dense = \", n_dense)\n",
    "\n",
    "cnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 7s 1s/step - loss: 0.0351 - mae: 0.1525 - val_loss: 0.1645 - val_mae: 0.2200\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 509ms/step - loss: 0.0244 - mae: 0.1199 - val_loss: 0.1634 - val_mae: 0.2186\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 488ms/step - loss: 0.0214 - mae: 0.1085 - val_loss: 0.1485 - val_mae: 0.2285\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.0197 - mae: 0.1036 - val_loss: 0.1483 - val_mae: 0.2034\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0149 - mae: 0.0889 - val_loss: 0.1389 - val_mae: 0.1959\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.0113 - mae: 0.0738 - val_loss: 0.1335 - val_mae: 0.1920\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0094 - mae: 0.0664 - val_loss: 0.1220 - val_mae: 0.2182\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.0090 - mae: 0.0737 - val_loss: 0.1247 - val_mae: 0.1999\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 0.0070 - mae: 0.0639 - val_loss: 0.1208 - val_mae: 0.2011\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 2s 501ms/step - loss: 0.0061 - mae: 0.0577 - val_loss: 0.1242 - val_mae: 0.1801\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 2s 444ms/step - loss: 0.0052 - mae: 0.0510 - val_loss: 0.1203 - val_mae: 0.1796\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.0045 - mae: 0.0455 - val_loss: 0.1133 - val_mae: 0.1850\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.1138 - val_mae: 0.1739\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 2s 494ms/step - loss: 0.0033 - mae: 0.0381 - val_loss: 0.1118 - val_mae: 0.1683\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 2s 450ms/step - loss: 0.0025 - mae: 0.0346 - val_loss: 0.1025 - val_mae: 0.1771\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 2s 450ms/step - loss: 0.0024 - mae: 0.0353 - val_loss: 0.1091 - val_mae: 0.1630\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 2s 457ms/step - loss: 0.0021 - mae: 0.0306 - val_loss: 0.1006 - val_mae: 0.1656\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 2s 444ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.1045 - val_mae: 0.1594\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 2s 453ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0971 - val_mae: 0.1682\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 0.1039 - val_mae: 0.1597\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 0.0958 - val_mae: 0.1586\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 2s 454ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 0.1014 - val_mae: 0.1584\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 2s 452ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0945 - val_mae: 0.1586\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 2s 470ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 0.0991 - val_mae: 0.1574\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.0013 - mae: 0.0228 - val_loss: 0.0943 - val_mae: 0.1561\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 2s 464ms/step - loss: 9.9324e-04 - mae: 0.0202 - val_loss: 0.0951 - val_mae: 0.1542\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 9.3495e-04 - mae: 0.0200 - val_loss: 0.0913 - val_mae: 0.1517\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 2s 454ms/step - loss: 8.8220e-04 - mae: 0.0198 - val_loss: 0.0907 - val_mae: 0.1511\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 2s 452ms/step - loss: 8.3812e-04 - mae: 0.0191 - val_loss: 0.0919 - val_mae: 0.1518\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 2s 455ms/step - loss: 7.3710e-04 - mae: 0.0182 - val_loss: 0.0923 - val_mae: 0.1521\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 2s 450ms/step - loss: 6.8717e-04 - mae: 0.0174 - val_loss: 0.0912 - val_mae: 0.1514\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 2s 495ms/step - loss: 6.9127e-04 - mae: 0.0168 - val_loss: 0.0913 - val_mae: 0.1517\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 2s 449ms/step - loss: 6.2685e-04 - mae: 0.0167 - val_loss: 0.0906 - val_mae: 0.1510\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 5.8380e-04 - mae: 0.0160 - val_loss: 0.0922 - val_mae: 0.1520\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 2s 452ms/step - loss: 5.4128e-04 - mae: 0.0158 - val_loss: 0.0908 - val_mae: 0.1513\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 5.2494e-04 - mae: 0.0157 - val_loss: 0.0891 - val_mae: 0.1497\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 2s 449ms/step - loss: 4.7490e-04 - mae: 0.0145 - val_loss: 0.0914 - val_mae: 0.1515\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 2s 497ms/step - loss: 4.8741e-04 - mae: 0.0150 - val_loss: 0.0881 - val_mae: 0.1487\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 2s 457ms/step - loss: 4.5896e-04 - mae: 0.0149 - val_loss: 0.0895 - val_mae: 0.1496\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 4.6930e-04 - mae: 0.0143 - val_loss: 0.0870 - val_mae: 0.1474\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 2s 453ms/step - loss: 4.4610e-04 - mae: 0.0141 - val_loss: 0.0877 - val_mae: 0.1481\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 2s 479ms/step - loss: 4.4329e-04 - mae: 0.0151 - val_loss: 0.0862 - val_mae: 0.1469\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 4.1706e-04 - mae: 0.0139 - val_loss: 0.0855 - val_mae: 0.1466\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 2s 484ms/step - loss: 4.2454e-04 - mae: 0.0138 - val_loss: 0.0856 - val_mae: 0.1465\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 2s 468ms/step - loss: 3.6901e-04 - mae: 0.0130 - val_loss: 0.0846 - val_mae: 0.1455\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 2s 463ms/step - loss: 3.4592e-04 - mae: 0.0130 - val_loss: 0.0872 - val_mae: 0.1482\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 2s 443ms/step - loss: 3.3077e-04 - mae: 0.0130 - val_loss: 0.0828 - val_mae: 0.1443\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 2s 445ms/step - loss: 3.4334e-04 - mae: 0.0126 - val_loss: 0.0860 - val_mae: 0.1471\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 2s 483ms/step - loss: 3.4661e-04 - mae: 0.0126 - val_loss: 0.0820 - val_mae: 0.1437\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 3.2990e-04 - mae: 0.0126 - val_loss: 0.0851 - val_mae: 0.1464\n",
      "8/8 [==============================] - 2s 62ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    }
   ],
   "source": [
    "ukraine = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "ukraine = ukraine[ukraine[\"year\"] < 2023]\n",
    "ukraine_sum = ukraine[['year', 'region', 'allangle_snow_free_hq_sum', 'allangle_snow_free_hq_mean'] + log_bin_columns]\n",
    "\n",
    "model = define_cnn(n_features = 4, n_conv = 2, n_dense = 4)\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X, y, epochs=50, batch_size=64, validation_split=0.2)\n",
    "\n",
    "ukraine_stage_2, ukraine_pred = extract_features_2(model, ukraine, 2022, X, X_pred, 4)\n",
    "selected_columns =  [\"feature_\" + str(i) for i in range(1, 5)] + [\"allangle_snow_free_hq_sum\", \"allangle_snow_free_hq_mean\"] + log_bin_columns\n",
    "\n",
    "param_grid_rf = {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [5, 10, 15, 20],  # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 4, 6, 8],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [2, 4, 6, 8],  # Minimum number of samples required to be at a leaf node\n",
    "        'random_state': [0],  # Ensures reproducibility\n",
    "}\n",
    "\n",
    "full_data = pd.concat([ukraine_stage_2, ukraine_pred])\n",
    "full_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "full_data = pd.merge(full_data, ukraine_sum, on=['year', 'region'])\n",
    "full_data_diff = full_data.groupby('region').diff()\n",
    "full_data_diff['region'] = full_data['region']\n",
    "full_data_diff['year'] = full_data['year']\n",
    "full_data_diff.reset_index(drop=True, inplace=True)\n",
    "full_data_diff = full_data_diff[full_data_diff[\"year\"] != 2012]\n",
    "\n",
    "train_data_diff = full_data_diff[full_data_diff[\"year\"] != 2022]\n",
    "pred_data_diff = full_data_diff[full_data_diff[\"year\"] == 2022]\n",
    "pred_data_diff.reset_index(drop=True, inplace=True)\n",
    "train_data_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "_, y_pred, best_params = predict_with_model(train_data_diff, pred_data_diff, selected_columns, \"random_forest\", param_grid_rf, log_transform = False, scale = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32132009837230857"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred)/ukraine_2021[\"real_gdp\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the predictions to the dataframe, save\n",
    "ukraine_2022[\"gdp_prediction\"] = gdp_predictions\n",
    "ukraine_2022 = ukraine_2022[[\"region\", \"year\", \"gdp_prediction\"]]\n",
    "ukraine_2022.to_csv(\"data/gdp_predictions_ukraine.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
