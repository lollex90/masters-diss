{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Resizing, Dropout, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Input, Reshape, Conv2DTranspose, Cropping2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from tools import define_cnn, extract_features, build_model, predict_with_model, set_seed, build_model_and_predict, extract_features_2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal CNN 10-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean gdp data, keep only year, region and real_gdp columns\n",
    "ukraine = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "log_bin_columns = [\"allangle_snow_free_hq\" + \"_log_\" + str(i) for i in range(1, 11)]\n",
    "\n",
    "# delete Kyiv and Kyiv_Oblast\n",
    "# ukraine = ukraine[ukraine[\"region\"] != \"Kyiv\"]\n",
    "# ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast\"]\n",
    "ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "\n",
    "# get the data for 2021, 2022 and before 2022\n",
    "ukraine_2022 = ukraine[ukraine[\"year\"] == 2022]\n",
    "ukraine = ukraine[ukraine[\"year\"] < 2022]\n",
    "ukraine_2021 = ukraine[ukraine[\"year\"] == 2021]\n",
    "ukraine_2021.reset_index(drop=True, inplace=True)\n",
    "ukraine_2022.reset_index(drop=True, inplace=True)\n",
    "ukraine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialise a three dimensional array to store the images with the shape (number of images, height, width, channels)\n",
    "X = np.zeros((len(ukraine), 765, 1076, 1))\n",
    "y = np.zeros(len(ukraine))\n",
    "\n",
    "# load the images\n",
    "for i in range(len(ukraine)):\n",
    "\n",
    "    # get year, region, and gdp\n",
    "    year = ukraine[\"year\"][i]\n",
    "    region = ukraine[\"region\"][i]\n",
    "    gdp_value = ukraine[\"real_gdp\"][i]\n",
    "\n",
    "    # load the image\n",
    "    file_name = f\"{year}_{region}_hq.h5\"\n",
    "    file_path = f\"data/annual_region_images/{file_name}\"\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as annual_region:\n",
    "        allangle_snow_free = annual_region[\"AllAngle_Composite_Snow_Free\"][:]\n",
    "\n",
    "    # add the values\n",
    "    y[i] = gdp_value\n",
    "    X[i, :, :, 0] = allangle_snow_free\n",
    "\n",
    "# normalise the images and gdp data\n",
    "maximum_x = X.max()\n",
    "X = X / maximum_x\n",
    "\n",
    "maximum_y = y.max()\n",
    "y = y / maximum_y\n",
    "\n",
    "# df to store the results\n",
    "cnn_results = pd.DataFrame(columns = [\"mae\", \"year\"])\n",
    "\n",
    "# define the grid of parameters: network architecture and number of features\n",
    "param_grid_cnn = {\n",
    "    'n_features': [10],\n",
    "    'n_conv': [3],\n",
    "    'n_dense': [4],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_grid_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6184/1742651157.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparam_grid_cnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'param_grid_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid_cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.9311 - mae: 0.7743 - val_loss: 0.2267 - val_mae: 0.3570\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 1.2168 - mae: 0.5783 - val_loss: 0.5741 - val_mae: 0.6516\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 521ms/step - loss: 0.5070 - mae: 0.3861 - val_loss: 0.8881 - val_mae: 0.8358\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.3769 - mae: 0.3071 - val_loss: 1.0976 - val_mae: 0.9181\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.2309 - mae: 0.2705 - val_loss: 1.2725 - val_mae: 0.9782\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.1107 - mae: 0.2055 - val_loss: 1.5352 - val_mae: 1.0822\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.0740 - mae: 0.1687 - val_loss: 1.6826 - val_mae: 1.1308\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.0774 - mae: 0.1592 - val_loss: 1.7167 - val_mae: 1.1393\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.0632 - mae: 0.1450 - val_loss: 1.6631 - val_mae: 1.1212\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.0391 - mae: 0.1278 - val_loss: 1.5118 - val_mae: 1.0673\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.0441 - mae: 0.1276 - val_loss: 1.3900 - val_mae: 1.0215\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.0425 - mae: 0.1224 - val_loss: 1.2681 - val_mae: 0.9737\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 0.0442 - mae: 0.1199 - val_loss: 1.0711 - val_mae: 0.8938\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.0321 - mae: 0.1136 - val_loss: 0.8297 - val_mae: 0.7889\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 2s 532ms/step - loss: 0.0336 - mae: 0.1179 - val_loss: 0.6550 - val_mae: 0.6997\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0390 - mae: 0.1224 - val_loss: 0.4982 - val_mae: 0.6048\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 2s 521ms/step - loss: 0.0580 - mae: 0.1278 - val_loss: 0.3286 - val_mae: 0.4873\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 2s 520ms/step - loss: 0.0319 - mae: 0.1091 - val_loss: 0.1642 - val_mae: 0.2478\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 2s 536ms/step - loss: 0.0317 - mae: 0.1072 - val_loss: 0.1621 - val_mae: 0.2141\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.0349 - mae: 0.1090 - val_loss: 0.1608 - val_mae: 0.2117\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 2s 522ms/step - loss: 0.0265 - mae: 0.0983 - val_loss: 0.1592 - val_mae: 0.2084\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.0212 - mae: 0.0918 - val_loss: 0.1571 - val_mae: 0.2045\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 2s 513ms/step - loss: 0.0173 - mae: 0.0846 - val_loss: 0.1554 - val_mae: 0.2017\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 2s 513ms/step - loss: 0.0175 - mae: 0.0813 - val_loss: 0.1542 - val_mae: 0.1998\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.0158 - mae: 0.0781 - val_loss: 0.1529 - val_mae: 0.1981\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 2s 528ms/step - loss: 0.0147 - mae: 0.0757 - val_loss: 0.1517 - val_mae: 0.1965\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 2s 526ms/step - loss: 0.0161 - mae: 0.0757 - val_loss: 0.1505 - val_mae: 0.1950\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 2s 508ms/step - loss: 0.0134 - mae: 0.0718 - val_loss: 0.1490 - val_mae: 0.1932\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 2s 516ms/step - loss: 0.0131 - mae: 0.0708 - val_loss: 0.1479 - val_mae: 0.1921\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.0146 - mae: 0.0715 - val_loss: 0.1474 - val_mae: 0.1916\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.0125 - mae: 0.0688 - val_loss: 0.1468 - val_mae: 0.1910\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 2s 529ms/step - loss: 0.0107 - mae: 0.0656 - val_loss: 0.1458 - val_mae: 0.1905\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.0107 - mae: 0.0654 - val_loss: 0.1449 - val_mae: 0.1902\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.0121 - mae: 0.0665 - val_loss: 0.1444 - val_mae: 0.1901\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 0.0108 - mae: 0.0669 - val_loss: 0.1435 - val_mae: 0.1900\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 2s 527ms/step - loss: 0.0102 - mae: 0.0645 - val_loss: 0.1425 - val_mae: 0.1901\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 2s 524ms/step - loss: 0.0167 - mae: 0.0688 - val_loss: 0.1418 - val_mae: 0.1903\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 2s 523ms/step - loss: 0.0123 - mae: 0.0668 - val_loss: 0.1416 - val_mae: 0.1904\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.0110 - mae: 0.0650 - val_loss: 0.1412 - val_mae: 0.1906\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 2s 516ms/step - loss: 0.0096 - mae: 0.0622 - val_loss: 0.1410 - val_mae: 0.1907\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.0100 - mae: 0.0612 - val_loss: 0.1412 - val_mae: 0.1907\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.0081 - mae: 0.0576 - val_loss: 0.1412 - val_mae: 0.1908\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 2s 531ms/step - loss: 0.0087 - mae: 0.0600 - val_loss: 0.1410 - val_mae: 0.1908\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 2s 516ms/step - loss: 0.0078 - mae: 0.0570 - val_loss: 0.1411 - val_mae: 0.1905\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 2s 506ms/step - loss: 0.0097 - mae: 0.0584 - val_loss: 0.1411 - val_mae: 0.1900\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 2s 506ms/step - loss: 0.0086 - mae: 0.0618 - val_loss: 0.1408 - val_mae: 0.1895\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 2s 510ms/step - loss: 0.0101 - mae: 0.0648 - val_loss: 0.1402 - val_mae: 0.1898\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 2s 512ms/step - loss: 0.0096 - mae: 0.0618 - val_loss: 0.1395 - val_mae: 0.1907\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 2s 515ms/step - loss: 0.0088 - mae: 0.0599 - val_loss: 0.1390 - val_mae: 0.1913\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 2s 507ms/step - loss: 0.0092 - mae: 0.0617 - val_loss: 0.1384 - val_mae: 0.1919\n",
      "8/8 [==============================] - 4s 116ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "WARNING:tensorflow:From c:\\Users\\jakub\\anaconda\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 188ms/step - loss: 47124824.0000 - mae: 2917.3513 - val_loss: 2102536.5000 - val_mae: 1221.5950\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 47124544.0000 - mae: 2917.3413 - val_loss: 2102545.0000 - val_mae: 1221.5994\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 47124296.0000 - mae: 2917.3345 - val_loss: 2102552.0000 - val_mae: 1221.6019\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47124060.0000 - mae: 2917.3284 - val_loss: 2102556.7500 - val_mae: 1221.6033\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47123916.0000 - mae: 2917.3230 - val_loss: 2102559.7500 - val_mae: 1221.6030\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 47123708.0000 - mae: 2917.3169 - val_loss: 2102562.7500 - val_mae: 1221.6031\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47123488.0000 - mae: 2917.3115 - val_loss: 2102564.5000 - val_mae: 1221.6028\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47123264.0000 - mae: 2917.3079 - val_loss: 2102570.7500 - val_mae: 1221.6045\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47123080.0000 - mae: 2917.3042 - val_loss: 2102577.5000 - val_mae: 1221.6077\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 47122892.0000 - mae: 2917.2991 - val_loss: 2102583.5000 - val_mae: 1221.6112\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 47122696.0000 - mae: 2917.2944 - val_loss: 2102591.2500 - val_mae: 1221.6165\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Results for year =  2013\n",
      "8/8 [==============================] - 3s 124ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 270ms/step - loss: 28362860.0000 - mae: 2606.9265 - val_loss: 2079823.2500 - val_mae: 1200.6738\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 28362580.0000 - mae: 2606.9077 - val_loss: 2079822.3750 - val_mae: 1200.6740\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 28362240.0000 - mae: 2606.8931 - val_loss: 2079822.7500 - val_mae: 1200.6748\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28361972.0000 - mae: 2606.8787 - val_loss: 2079824.6250 - val_mae: 1200.6768\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28361804.0000 - mae: 2606.8687 - val_loss: 2079827.6250 - val_mae: 1200.6791\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28361546.0000 - mae: 2606.8596 - val_loss: 2079829.0000 - val_mae: 1200.6804\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28361280.0000 - mae: 2606.8450 - val_loss: 2079827.2500 - val_mae: 1200.6804\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28360976.0000 - mae: 2606.8345 - val_loss: 2079822.7500 - val_mae: 1200.6798\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28360794.0000 - mae: 2606.8223 - val_loss: 2079817.0000 - val_mae: 1200.6790\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28360532.0000 - mae: 2606.8081 - val_loss: 2079805.7500 - val_mae: 1200.6761\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28360220.0000 - mae: 2606.7930 - val_loss: 2079791.6250 - val_mae: 1200.6725\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28360004.0000 - mae: 2606.7812 - val_loss: 2079774.0000 - val_mae: 1200.6687\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28359716.0000 - mae: 2606.7661 - val_loss: 2079757.2500 - val_mae: 1200.6648\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28359380.0000 - mae: 2606.7507 - val_loss: 2079742.0000 - val_mae: 1200.6608\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28359152.0000 - mae: 2606.7351 - val_loss: 2079724.0000 - val_mae: 1200.6566\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28358736.0000 - mae: 2606.7183 - val_loss: 2079699.6250 - val_mae: 1200.6501\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28358420.0000 - mae: 2606.6987 - val_loss: 2079672.7500 - val_mae: 1200.6433\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28358166.0000 - mae: 2606.6851 - val_loss: 2079646.0000 - val_mae: 1200.6375\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28357802.0000 - mae: 2606.6658 - val_loss: 2079616.7500 - val_mae: 1200.6310\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28357360.0000 - mae: 2606.6497 - val_loss: 2079589.2500 - val_mae: 1200.6243\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28356922.0000 - mae: 2606.6245 - val_loss: 2079559.6250 - val_mae: 1200.6161\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 28356474.0000 - mae: 2606.5984 - val_loss: 2079527.7500 - val_mae: 1200.6069\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28356122.0000 - mae: 2606.5750 - val_loss: 2079496.7500 - val_mae: 1200.5992\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28355532.0000 - mae: 2606.5464 - val_loss: 2079464.0000 - val_mae: 1200.5912\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28355194.0000 - mae: 2606.5227 - val_loss: 2079423.0000 - val_mae: 1200.5808\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28354524.0000 - mae: 2606.4915 - val_loss: 2079381.0000 - val_mae: 1200.5696\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28354000.0000 - mae: 2606.4556 - val_loss: 2079339.3750 - val_mae: 1200.5580\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28353292.0000 - mae: 2606.4253 - val_loss: 2079293.2500 - val_mae: 1200.5442\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28352716.0000 - mae: 2606.3884 - val_loss: 2079248.6250 - val_mae: 1200.5316\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 28351892.0000 - mae: 2606.3494 - val_loss: 2079199.2500 - val_mae: 1200.5179\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28351050.0000 - mae: 2606.3035 - val_loss: 2079147.6250 - val_mae: 1200.5033\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28350276.0000 - mae: 2606.2590 - val_loss: 2079087.6250 - val_mae: 1200.4860\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 28349472.0000 - mae: 2606.2168 - val_loss: 2079027.2500 - val_mae: 1200.4700\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28348480.0000 - mae: 2606.1621 - val_loss: 2078962.7500 - val_mae: 1200.4524\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28347258.0000 - mae: 2606.0972 - val_loss: 2078891.0000 - val_mae: 1200.4290\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28346176.0000 - mae: 2606.0344 - val_loss: 2078817.2500 - val_mae: 1200.4041\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28344972.0000 - mae: 2605.9634 - val_loss: 2078736.0000 - val_mae: 1200.3755\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28343734.0000 - mae: 2605.8735 - val_loss: 2078652.3750 - val_mae: 1200.3475\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28342556.0000 - mae: 2605.8037 - val_loss: 2078553.6250 - val_mae: 1200.3152\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28340896.0000 - mae: 2605.7166 - val_loss: 2078446.0000 - val_mae: 1200.2810\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28339520.0000 - mae: 2605.6125 - val_loss: 2078330.6250 - val_mae: 1200.2468\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28337508.0000 - mae: 2605.5046 - val_loss: 2078209.6250 - val_mae: 1200.2102\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28336294.0000 - mae: 2605.4155 - val_loss: 2078078.6250 - val_mae: 1200.1729\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28334028.0000 - mae: 2605.2791 - val_loss: 2077947.6250 - val_mae: 1200.1349\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28331980.0000 - mae: 2605.1548 - val_loss: 2077815.6250 - val_mae: 1200.0989\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28329948.0000 - mae: 2605.0354 - val_loss: 2077664.3750 - val_mae: 1200.0544\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 28327868.0000 - mae: 2604.8757 - val_loss: 2077492.0000 - val_mae: 1200.0022\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28325658.0000 - mae: 2604.7192 - val_loss: 2077301.2500 - val_mae: 1199.9436\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28322836.0000 - mae: 2604.5332 - val_loss: 2077110.0000 - val_mae: 1199.8873\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28320332.0000 - mae: 2604.3694 - val_loss: 2076906.0000 - val_mae: 1199.8269\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 28316940.0000 - mae: 2604.1709 - val_loss: 2076697.3750 - val_mae: 1199.7650\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28313962.0000 - mae: 2603.9648 - val_loss: 2076463.6250 - val_mae: 1199.6927\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28310684.0000 - mae: 2603.7410 - val_loss: 2076218.2500 - val_mae: 1199.6169\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28307204.0000 - mae: 2603.4570 - val_loss: 2075959.6250 - val_mae: 1199.5365\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28303772.0000 - mae: 2603.2036 - val_loss: 2075703.2500 - val_mae: 1199.4617\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28298710.0000 - mae: 2602.9053 - val_loss: 2075428.6250 - val_mae: 1199.3787\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28294772.0000 - mae: 2602.6118 - val_loss: 2075128.0000 - val_mae: 1199.2914\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28289676.0000 - mae: 2602.2744 - val_loss: 2074799.6250 - val_mae: 1199.1931\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28285140.0000 - mae: 2601.9458 - val_loss: 2074463.2500 - val_mae: 1199.0951\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 28279376.0000 - mae: 2601.5662 - val_loss: 2074096.3750 - val_mae: 1198.9857\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28272044.0000 - mae: 2601.1367 - val_loss: 2073712.7500 - val_mae: 1198.8694\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28266668.0000 - mae: 2600.7671 - val_loss: 2073292.0000 - val_mae: 1198.7454\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28260762.0000 - mae: 2600.2871 - val_loss: 2072824.7500 - val_mae: 1198.6023\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28252868.0000 - mae: 2599.8403 - val_loss: 2072345.6250 - val_mae: 1198.4534\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28245146.0000 - mae: 2599.2588 - val_loss: 2071844.3750 - val_mae: 1198.2966\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28238086.0000 - mae: 2598.7534 - val_loss: 2071312.3750 - val_mae: 1198.1288\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 28229306.0000 - mae: 2598.1719 - val_loss: 2070786.0000 - val_mae: 1197.9651\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28220282.0000 - mae: 2597.6316 - val_loss: 2070232.0000 - val_mae: 1197.7972\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28213428.0000 - mae: 2597.0393 - val_loss: 2069639.2500 - val_mae: 1197.6215\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28201460.0000 - mae: 2596.2605 - val_loss: 2069032.3750 - val_mae: 1197.4341\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28192508.0000 - mae: 2595.6191 - val_loss: 2068364.0000 - val_mae: 1197.2275\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28181300.0000 - mae: 2594.7981 - val_loss: 2067628.0000 - val_mae: 1196.9894\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 28169926.0000 - mae: 2594.0581 - val_loss: 2066854.0000 - val_mae: 1196.7380\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28159308.0000 - mae: 2593.1704 - val_loss: 2066076.7500 - val_mae: 1196.4941\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 28147024.0000 - mae: 2592.3391 - val_loss: 2065262.0000 - val_mae: 1196.2405\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 28132326.0000 - mae: 2591.4734 - val_loss: 2064501.2500 - val_mae: 1196.0172\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28120044.0000 - mae: 2590.5532 - val_loss: 2063612.3750 - val_mae: 1195.7401\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28105978.0000 - mae: 2589.5210 - val_loss: 2062710.0000 - val_mae: 1195.4636\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28089344.0000 - mae: 2588.4211 - val_loss: 2061779.2500 - val_mae: 1195.1765\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28077584.0000 - mae: 2587.3474 - val_loss: 2060784.7500 - val_mae: 1194.8746\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28059158.0000 - mae: 2586.1458 - val_loss: 2059750.2500 - val_mae: 1194.5576\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28042506.0000 - mae: 2584.8560 - val_loss: 2058644.6250 - val_mae: 1194.2145\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28023850.0000 - mae: 2583.6836 - val_loss: 2057549.6250 - val_mae: 1193.8763\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28005114.0000 - mae: 2582.2070 - val_loss: 2056474.3750 - val_mae: 1193.5502\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27984634.0000 - mae: 2580.9551 - val_loss: 2055404.7500 - val_mae: 1193.2285\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27967044.0000 - mae: 2579.3171 - val_loss: 2054262.7500 - val_mae: 1192.8818\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 27944762.0000 - mae: 2577.6465 - val_loss: 2053026.7500 - val_mae: 1192.4978\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27924144.0000 - mae: 2576.4038 - val_loss: 2051758.0000 - val_mae: 1192.1118\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27898266.0000 - mae: 2574.7690 - val_loss: 2050385.6250 - val_mae: 1191.6735\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 27873772.0000 - mae: 2572.9888 - val_loss: 2048994.0000 - val_mae: 1191.2356\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27851994.0000 - mae: 2571.1011 - val_loss: 2047545.2500 - val_mae: 1190.7885\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27822092.0000 - mae: 2569.2354 - val_loss: 2046097.2500 - val_mae: 1190.3458\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27796900.0000 - mae: 2567.3184 - val_loss: 2044580.0000 - val_mae: 1189.8752\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27766998.0000 - mae: 2565.0793 - val_loss: 2043105.6250 - val_mae: 1189.4224\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27739884.0000 - mae: 2562.8899 - val_loss: 2041578.0000 - val_mae: 1188.9471\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27704860.0000 - mae: 2560.8503 - val_loss: 2039981.2500 - val_mae: 1188.4442\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27677814.0000 - mae: 2558.4814 - val_loss: 2038244.7500 - val_mae: 1187.8965\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27646122.0000 - mae: 2556.2026 - val_loss: 2036448.7500 - val_mae: 1187.3323\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27609466.0000 - mae: 2553.7588 - val_loss: 2034569.3750 - val_mae: 1186.7350\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27574618.0000 - mae: 2551.0762 - val_loss: 2032686.0000 - val_mae: 1186.1316\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27533364.0000 - mae: 2548.5269 - val_loss: 2030818.0000 - val_mae: 1185.5437\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27504272.0000 - mae: 2545.6562 - val_loss: 2028795.3750 - val_mae: 1184.8958\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27467174.0000 - mae: 2542.9114 - val_loss: 2026728.7500 - val_mae: 1184.2224\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27418964.0000 - mae: 2540.1575 - val_loss: 2024708.2500 - val_mae: 1183.5608\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27385236.0000 - mae: 2537.2075 - val_loss: 2022569.0000 - val_mae: 1182.8801\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27343930.0000 - mae: 2534.1304 - val_loss: 2020363.2500 - val_mae: 1182.1729\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27297212.0000 - mae: 2530.9038 - val_loss: 2018145.6250 - val_mae: 1181.4312\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 27252416.0000 - mae: 2527.8542 - val_loss: 2016002.7500 - val_mae: 1180.7195\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27205216.0000 - mae: 2524.4441 - val_loss: 2013837.0000 - val_mae: 1180.0065\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27172652.0000 - mae: 2521.4856 - val_loss: 2011535.3750 - val_mae: 1179.2692\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27122644.0000 - mae: 2517.7419 - val_loss: 2009167.0000 - val_mae: 1178.4902\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27065696.0000 - mae: 2514.4368 - val_loss: 2006753.2500 - val_mae: 1177.6957\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27021132.0000 - mae: 2510.7712 - val_loss: 2004183.2500 - val_mae: 1176.8501\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 26962564.0000 - mae: 2507.0984 - val_loss: 2001712.0000 - val_mae: 1176.0388\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26920726.0000 - mae: 2503.8320 - val_loss: 1999114.0000 - val_mae: 1175.1855\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26860666.0000 - mae: 2499.7239 - val_loss: 1996560.0000 - val_mae: 1174.3445\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 26802400.0000 - mae: 2495.6992 - val_loss: 1993935.7500 - val_mae: 1173.4919\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26762116.0000 - mae: 2492.0151 - val_loss: 1991025.2500 - val_mae: 1172.5265\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 26701386.0000 - mae: 2487.9507 - val_loss: 1988178.3750 - val_mae: 1171.5723\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26634298.0000 - mae: 2483.8384 - val_loss: 1985383.7500 - val_mae: 1170.6267\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26574074.0000 - mae: 2479.7698 - val_loss: 1982555.7500 - val_mae: 1169.6921\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26529892.0000 - mae: 2475.0107 - val_loss: 1979533.2500 - val_mae: 1168.6799\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26463324.0000 - mae: 2470.1011 - val_loss: 1976645.3750 - val_mae: 1167.7096\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26397204.0000 - mae: 2465.6938 - val_loss: 1973751.7500 - val_mae: 1166.7262\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26347082.0000 - mae: 2461.2876 - val_loss: 1970846.0000 - val_mae: 1165.7507\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26275750.0000 - mae: 2456.5154 - val_loss: 1968030.6250 - val_mae: 1164.7917\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 26229190.0000 - mae: 2452.4387 - val_loss: 1965031.7500 - val_mae: 1163.7526\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26163576.0000 - mae: 2447.2026 - val_loss: 1962002.3750 - val_mae: 1162.6989\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26103310.0000 - mae: 2443.3052 - val_loss: 1958823.6250 - val_mae: 1161.5728\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26038618.0000 - mae: 2438.5676 - val_loss: 1955621.3750 - val_mae: 1160.4518\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25971952.0000 - mae: 2433.0051 - val_loss: 1952334.3750 - val_mae: 1159.3262\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25920528.0000 - mae: 2428.9441 - val_loss: 1948895.2500 - val_mae: 1158.1793\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 25837180.0000 - mae: 2424.9106 - val_loss: 1945709.2500 - val_mae: 1157.1267\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25763622.0000 - mae: 2421.0837 - val_loss: 1942350.7500 - val_mae: 1155.9756\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25693018.0000 - mae: 2416.2632 - val_loss: 1938833.2500 - val_mae: 1154.7822\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25638194.0000 - mae: 2413.4087 - val_loss: 1934985.6250 - val_mae: 1153.4617\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25561290.0000 - mae: 2409.1162 - val_loss: 1931259.2500 - val_mae: 1152.1720\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25461196.0000 - mae: 2403.7153 - val_loss: 1927860.0000 - val_mae: 1151.0002\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 25395074.0000 - mae: 2399.4810 - val_loss: 1924194.3750 - val_mae: 1149.7361\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 25327724.0000 - mae: 2394.9258 - val_loss: 1920295.6250 - val_mae: 1148.3489\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 25244188.0000 - mae: 2390.6216 - val_loss: 1916554.2500 - val_mae: 1147.0264\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 25178700.0000 - mae: 2386.2915 - val_loss: 1912827.0000 - val_mae: 1145.7535\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25097814.0000 - mae: 2382.0112 - val_loss: 1909104.7500 - val_mae: 1144.4408\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 25035700.0000 - mae: 2378.1404 - val_loss: 1905281.2500 - val_mae: 1143.0917\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 24959764.0000 - mae: 2373.5669 - val_loss: 1901363.2500 - val_mae: 1141.6731\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24876888.0000 - mae: 2370.0405 - val_loss: 1897494.7500 - val_mae: 1140.2697\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24804998.0000 - mae: 2365.9175 - val_loss: 1893543.2500 - val_mae: 1138.8271\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24729260.0000 - mae: 2361.9165 - val_loss: 1889534.0000 - val_mae: 1137.3953\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24664702.0000 - mae: 2358.0090 - val_loss: 1885409.2500 - val_mae: 1135.9246\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24583296.0000 - mae: 2353.9937 - val_loss: 1881499.7500 - val_mae: 1134.5295\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24515860.0000 - mae: 2349.8198 - val_loss: 1877577.2500 - val_mae: 1133.1101\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 24439092.0000 - mae: 2345.5359 - val_loss: 1873749.3750 - val_mae: 1131.7273\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 24370748.0000 - mae: 2342.6646 - val_loss: 1869966.2500 - val_mae: 1130.3495\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24286604.0000 - mae: 2338.9744 - val_loss: 1866064.0000 - val_mae: 1128.9039\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 24238524.0000 - mae: 2336.2859 - val_loss: 1861827.7500 - val_mae: 1127.3627\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 24145742.0000 - mae: 2332.4797 - val_loss: 1857721.0000 - val_mae: 1125.8450\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24068640.0000 - mae: 2329.5378 - val_loss: 1853688.0000 - val_mae: 1124.3899\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24005896.0000 - mae: 2328.2622 - val_loss: 1849601.3750 - val_mae: 1123.0173\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23925926.0000 - mae: 2325.3010 - val_loss: 1845555.7500 - val_mae: 1121.6721\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 23843444.0000 - mae: 2321.9204 - val_loss: 1841419.0000 - val_mae: 1120.2742\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23786416.0000 - mae: 2317.9941 - val_loss: 1836817.2500 - val_mae: 1118.7133\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 23696972.0000 - mae: 2313.9895 - val_loss: 1832213.6250 - val_mae: 1117.1340\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 23624988.0000 - mae: 2310.3042 - val_loss: 1827732.7500 - val_mae: 1115.5999\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23558950.0000 - mae: 2306.7031 - val_loss: 1823283.7500 - val_mae: 1114.0648\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23481516.0000 - mae: 2302.2856 - val_loss: 1819059.2500 - val_mae: 1112.6096\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 23423180.0000 - mae: 2299.0913 - val_loss: 1814820.7500 - val_mae: 1111.1553\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23337044.0000 - mae: 2295.2651 - val_loss: 1810668.6250 - val_mae: 1109.7273\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23268720.0000 - mae: 2292.3418 - val_loss: 1806338.2500 - val_mae: 1108.2146\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23198838.0000 - mae: 2289.0012 - val_loss: 1802082.7500 - val_mae: 1106.7400\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23141122.0000 - mae: 2286.1680 - val_loss: 1797745.6250 - val_mae: 1105.2291\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23075084.0000 - mae: 2283.1177 - val_loss: 1793556.3750 - val_mae: 1103.7527\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22994406.0000 - mae: 2280.6746 - val_loss: 1789766.0000 - val_mae: 1102.3916\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 22919234.0000 - mae: 2278.8462 - val_loss: 1786030.3750 - val_mae: 1101.0577\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 22876326.0000 - mae: 2275.9863 - val_loss: 1781901.3750 - val_mae: 1099.6072\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 22808092.0000 - mae: 2274.2441 - val_loss: 1777887.7500 - val_mae: 1098.1865\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 22731338.0000 - mae: 2271.9348 - val_loss: 1773849.2500 - val_mae: 1096.7352\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 22682378.0000 - mae: 2269.9976 - val_loss: 1769789.7500 - val_mae: 1095.2755\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 22610750.0000 - mae: 2266.6768 - val_loss: 1766147.6250 - val_mae: 1093.9564\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 22555932.0000 - mae: 2264.3765 - val_loss: 1762612.3750 - val_mae: 1092.6722\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 22495788.0000 - mae: 2262.0293 - val_loss: 1759012.7500 - val_mae: 1091.3513\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22419238.0000 - mae: 2259.0771 - val_loss: 1755472.7500 - val_mae: 1090.0491\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22385056.0000 - mae: 2258.3000 - val_loss: 1751165.7500 - val_mae: 1088.4639\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22315482.0000 - mae: 2255.3691 - val_loss: 1747240.7500 - val_mae: 1087.0012\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 22245180.0000 - mae: 2252.6138 - val_loss: 1743580.7500 - val_mae: 1085.6357\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 22197558.0000 - mae: 2250.7446 - val_loss: 1739916.0000 - val_mae: 1084.2568\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 22155554.0000 - mae: 2247.8765 - val_loss: 1736271.6250 - val_mae: 1082.8934\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 22076232.0000 - mae: 2245.3767 - val_loss: 1732815.2500 - val_mae: 1081.5758\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22023748.0000 - mae: 2244.1670 - val_loss: 1728846.3750 - val_mae: 1080.0779\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21971958.0000 - mae: 2243.3757 - val_loss: 1724977.3750 - val_mae: 1078.6428\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 21911498.0000 - mae: 2241.9331 - val_loss: 1721344.2500 - val_mae: 1077.2949\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 21846396.0000 - mae: 2240.3992 - val_loss: 1717708.0000 - val_mae: 1075.9324\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 21801848.0000 - mae: 2237.8862 - val_loss: 1713649.7500 - val_mae: 1074.4125\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 21751788.0000 - mae: 2236.0767 - val_loss: 1709682.7500 - val_mae: 1072.9115\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 21700294.0000 - mae: 2233.9976 - val_loss: 1705670.7500 - val_mae: 1071.3516\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21630170.0000 - mae: 2231.6851 - val_loss: 1701929.2500 - val_mae: 1069.8636\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 21586080.0000 - mae: 2230.2583 - val_loss: 1698110.3750 - val_mae: 1068.3406\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21532206.0000 - mae: 2228.0422 - val_loss: 1694478.6250 - val_mae: 1066.9000\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 21474752.0000 - mae: 2226.5627 - val_loss: 1690639.0000 - val_mae: 1065.4133\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21441340.0000 - mae: 2225.4136 - val_loss: 1686367.7500 - val_mae: 1063.7700\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 21392888.0000 - mae: 2225.1121 - val_loss: 1682455.6250 - val_mae: 1062.2625\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 21321012.0000 - mae: 2223.0513 - val_loss: 1678956.0000 - val_mae: 1060.8890\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21283760.0000 - mae: 2221.2798 - val_loss: 1675340.2500 - val_mae: 1059.4519\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21238372.0000 - mae: 2218.8247 - val_loss: 1671702.2500 - val_mae: 1057.9791\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 21167404.0000 - mae: 2215.6538 - val_loss: 1668411.2500 - val_mae: 1056.6317\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 21146898.0000 - mae: 2214.4075 - val_loss: 1664550.0000 - val_mae: 1055.0680\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 21082452.0000 - mae: 2212.3484 - val_loss: 1661115.2500 - val_mae: 1053.6602\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21027458.0000 - mae: 2210.8647 - val_loss: 1657866.3750 - val_mae: 1052.3118\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 20987530.0000 - mae: 2208.8882 - val_loss: 1654283.6250 - val_mae: 1050.8246\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20951284.0000 - mae: 2207.5090 - val_loss: 1650575.7500 - val_mae: 1049.2576\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20885002.0000 - mae: 2204.9761 - val_loss: 1647307.7500 - val_mae: 1047.8701\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 20863312.0000 - mae: 2204.0261 - val_loss: 1643588.8750 - val_mae: 1046.3213\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 20799388.0000 - mae: 2202.4622 - val_loss: 1640332.0000 - val_mae: 1044.9366\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20748956.0000 - mae: 2200.9351 - val_loss: 1637085.7500 - val_mae: 1043.5515\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 20728260.0000 - mae: 2200.5327 - val_loss: 1633326.1250 - val_mae: 1041.9785\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 20666724.0000 - mae: 2198.6809 - val_loss: 1629808.6250 - val_mae: 1040.4561\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 20627604.0000 - mae: 2197.5542 - val_loss: 1626405.6250 - val_mae: 1039.0022\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20588452.0000 - mae: 2196.4028 - val_loss: 1623218.2500 - val_mae: 1037.6475\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 20530550.0000 - mae: 2195.3179 - val_loss: 1620425.0000 - val_mae: 1036.4440\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 20508288.0000 - mae: 2195.7083 - val_loss: 1617095.2500 - val_mae: 1035.0906\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 20466276.0000 - mae: 2194.2788 - val_loss: 1613933.8750 - val_mae: 1033.7683\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 20437510.0000 - mae: 2193.2429 - val_loss: 1610847.7500 - val_mae: 1032.4860\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20388524.0000 - mae: 2192.6086 - val_loss: 1607930.1250 - val_mae: 1031.2522\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20349984.0000 - mae: 2191.5364 - val_loss: 1605090.0000 - val_mae: 1030.0306\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 20318260.0000 - mae: 2190.1509 - val_loss: 1602378.0000 - val_mae: 1028.8608\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 20290568.0000 - mae: 2188.6165 - val_loss: 1599559.3750 - val_mae: 1027.6326\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20247172.0000 - mae: 2187.5640 - val_loss: 1596737.2500 - val_mae: 1026.4648\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20227088.0000 - mae: 2186.3279 - val_loss: 1593877.1250 - val_mae: 1025.2454\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 20188940.0000 - mae: 2184.6514 - val_loss: 1591244.8750 - val_mae: 1024.1263\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20151172.0000 - mae: 2182.6372 - val_loss: 1588994.8750 - val_mae: 1023.1014\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20123010.0000 - mae: 2181.0251 - val_loss: 1586157.0000 - val_mae: 1021.9036\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20093546.0000 - mae: 2179.7837 - val_loss: 1583199.3750 - val_mae: 1020.6709\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20061756.0000 - mae: 2178.8633 - val_loss: 1580379.0000 - val_mae: 1019.4924\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 20023642.0000 - mae: 2178.8281 - val_loss: 1577319.2500 - val_mae: 1018.3115\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19991130.0000 - mae: 2178.3496 - val_loss: 1574393.6250 - val_mae: 1017.1502\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 19956896.0000 - mae: 2178.0737 - val_loss: 1571594.2500 - val_mae: 1016.0221\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 19933164.0000 - mae: 2177.9497 - val_loss: 1568636.5000 - val_mae: 1014.8859\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 19893428.0000 - mae: 2177.7571 - val_loss: 1565680.0000 - val_mae: 1013.7373\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 19864096.0000 - mae: 2178.2673 - val_loss: 1562884.2500 - val_mae: 1012.7004\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 19820980.0000 - mae: 2176.5542 - val_loss: 1560474.8750 - val_mae: 1011.9076\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 19806932.0000 - mae: 2176.9761 - val_loss: 1558071.2500 - val_mae: 1011.0874\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 19770452.0000 - mae: 2176.6528 - val_loss: 1555883.2500 - val_mae: 1010.2760\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19744462.0000 - mae: 2175.8188 - val_loss: 1553683.1250 - val_mae: 1009.4943\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19727062.0000 - mae: 2174.9805 - val_loss: 1551524.2500 - val_mae: 1008.6903\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19693196.0000 - mae: 2173.6487 - val_loss: 1549716.5000 - val_mae: 1008.0109\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 19679726.0000 - mae: 2172.2949 - val_loss: 1547503.2500 - val_mae: 1007.1746\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 19655058.0000 - mae: 2171.1948 - val_loss: 1545307.7500 - val_mae: 1006.3884\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 19634244.0000 - mae: 2170.5481 - val_loss: 1543169.5000 - val_mae: 1005.5959\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19607062.0000 - mae: 2169.1023 - val_loss: 1541191.2500 - val_mae: 1004.8478\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 19589156.0000 - mae: 2167.8425 - val_loss: 1539057.5000 - val_mae: 1004.0826\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 19565680.0000 - mae: 2166.7949 - val_loss: 1537051.6250 - val_mae: 1003.3799\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19549646.0000 - mae: 2166.1299 - val_loss: 1534643.7500 - val_mae: 1002.5319\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 19526468.0000 - mae: 2165.0798 - val_loss: 1532360.7500 - val_mae: 1001.6627\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 19499174.0000 - mae: 2163.6179 - val_loss: 1530260.7500 - val_mae: 1000.8600\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19472058.0000 - mae: 2162.2554 - val_loss: 1527818.3750 - val_mae: 999.9681\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19450834.0000 - mae: 2161.7771 - val_loss: 1525225.7500 - val_mae: 999.0475\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 19433928.0000 - mae: 2161.7402 - val_loss: 1522608.3750 - val_mae: 998.0840\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19396686.0000 - mae: 2160.6599 - val_loss: 1520211.2500 - val_mae: 997.1783\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19380908.0000 - mae: 2160.3186 - val_loss: 1517374.2500 - val_mae: 996.1766\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 19352556.0000 - mae: 2159.8301 - val_loss: 1514594.0000 - val_mae: 995.1415\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19317324.0000 - mae: 2158.9524 - val_loss: 1512086.2500 - val_mae: 994.1154\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19297604.0000 - mae: 2157.2104 - val_loss: 1509649.2500 - val_mae: 993.1266\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19275524.0000 - mae: 2156.1038 - val_loss: 1507240.0000 - val_mae: 992.2397\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19247202.0000 - mae: 2154.6323 - val_loss: 1505049.8750 - val_mae: 991.4574\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 19238012.0000 - mae: 2153.8706 - val_loss: 1502502.0000 - val_mae: 990.5530\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 19201780.0000 - mae: 2152.1101 - val_loss: 1500361.8750 - val_mae: 989.7067\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19190522.0000 - mae: 2150.9478 - val_loss: 1497952.7500 - val_mae: 988.7645\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19157582.0000 - mae: 2149.3242 - val_loss: 1495721.5000 - val_mae: 987.9535\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19144352.0000 - mae: 2148.7434 - val_loss: 1493389.0000 - val_mae: 987.1078\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 19115648.0000 - mae: 2148.0740 - val_loss: 1491366.8750 - val_mae: 986.3660\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 19112006.0000 - mae: 2148.1724 - val_loss: 1489084.6250 - val_mae: 985.5513\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19079602.0000 - mae: 2146.8794 - val_loss: 1487117.2500 - val_mae: 984.7599\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19063284.0000 - mae: 2145.5220 - val_loss: 1485335.3750 - val_mae: 984.0109\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 19053838.0000 - mae: 2144.2622 - val_loss: 1483004.2500 - val_mae: 983.1569\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 19022890.0000 - mae: 2142.8281 - val_loss: 1481135.0000 - val_mae: 982.4559\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 19001544.0000 - mae: 2142.0398 - val_loss: 1479265.3750 - val_mae: 981.8210\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 18988100.0000 - mae: 2141.7566 - val_loss: 1477255.3750 - val_mae: 981.1258\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18974490.0000 - mae: 2141.5535 - val_loss: 1475255.2500 - val_mae: 980.3981\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18952748.0000 - mae: 2140.5137 - val_loss: 1473467.3750 - val_mae: 979.6797\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18931920.0000 - mae: 2139.1160 - val_loss: 1471452.8750 - val_mae: 978.9229\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18920020.0000 - mae: 2138.4839 - val_loss: 1469395.1250 - val_mae: 978.1832\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18905778.0000 - mae: 2138.2930 - val_loss: 1467558.7500 - val_mae: 977.5463\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 18879906.0000 - mae: 2137.6616 - val_loss: 1465913.6250 - val_mae: 976.9141\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18871532.0000 - mae: 2137.4233 - val_loss: 1464032.2500 - val_mae: 976.1914\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 18859366.0000 - mae: 2136.9629 - val_loss: 1462366.5000 - val_mae: 975.5095\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 18826228.0000 - mae: 2135.7866 - val_loss: 1460432.3750 - val_mae: 974.8470\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 18828794.0000 - mae: 2136.9019 - val_loss: 1458343.7500 - val_mae: 974.1400\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 18807892.0000 - mae: 2137.5239 - val_loss: 1456425.2500 - val_mae: 973.4354\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18791412.0000 - mae: 2136.6836 - val_loss: 1454671.2500 - val_mae: 972.7390\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18762090.0000 - mae: 2135.9473 - val_loss: 1452586.7500 - val_mae: 972.0106\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18761876.0000 - mae: 2136.6919 - val_loss: 1450251.0000 - val_mae: 971.1512\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 18732330.0000 - mae: 2135.7109 - val_loss: 1448285.3750 - val_mae: 970.3912\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 18717142.0000 - mae: 2134.4292 - val_loss: 1446458.3750 - val_mae: 969.6260\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18707974.0000 - mae: 2133.0474 - val_loss: 1444828.0000 - val_mae: 968.9131\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 18684928.0000 - mae: 2131.1606 - val_loss: 1443220.3750 - val_mae: 968.2983\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 18667544.0000 - mae: 2129.3140 - val_loss: 1441711.0000 - val_mae: 967.6508\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18651470.0000 - mae: 2127.3635 - val_loss: 1439976.3750 - val_mae: 966.9973\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18635326.0000 - mae: 2125.9102 - val_loss: 1438245.7500 - val_mae: 966.3529\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18616098.0000 - mae: 2124.4458 - val_loss: 1436714.7500 - val_mae: 965.7809\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 18604586.0000 - mae: 2122.9683 - val_loss: 1435479.3750 - val_mae: 965.2924\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18584052.0000 - mae: 2121.7742 - val_loss: 1434288.2500 - val_mae: 964.8098\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18572950.0000 - mae: 2120.4226 - val_loss: 1432919.0000 - val_mae: 964.2867\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 18557434.0000 - mae: 2119.3726 - val_loss: 1431279.2500 - val_mae: 963.6768\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 18536872.0000 - mae: 2118.5327 - val_loss: 1429827.0000 - val_mae: 963.1279\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18509160.0000 - mae: 2117.0864 - val_loss: 1428683.5000 - val_mae: 962.7035\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 18490662.0000 - mae: 2115.3613 - val_loss: 1427613.2500 - val_mae: 962.2705\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 18478434.0000 - mae: 2114.3032 - val_loss: 1426621.1250 - val_mae: 961.8413\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18454646.0000 - mae: 2112.1470 - val_loss: 1425740.2500 - val_mae: 961.4875\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18440492.0000 - mae: 2111.0989 - val_loss: 1424280.2500 - val_mae: 960.9324\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18417080.0000 - mae: 2110.0625 - val_loss: 1423101.5000 - val_mae: 960.4658\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18401472.0000 - mae: 2108.7437 - val_loss: 1421874.7500 - val_mae: 960.0051\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 18378688.0000 - mae: 2106.9158 - val_loss: 1420739.0000 - val_mae: 959.5814\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 18369094.0000 - mae: 2105.9771 - val_loss: 1419279.7500 - val_mae: 959.0602\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 18343102.0000 - mae: 2104.0972 - val_loss: 1417999.7500 - val_mae: 958.5309\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18319962.0000 - mae: 2102.3674 - val_loss: 1416798.5000 - val_mae: 958.0336\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18292900.0000 - mae: 2100.0176 - val_loss: 1415694.0000 - val_mae: 957.5941\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18288332.0000 - mae: 2099.2024 - val_loss: 1414659.2500 - val_mae: 957.1004\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18262302.0000 - mae: 2097.4397 - val_loss: 1413442.2500 - val_mae: 956.5944\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 18232898.0000 - mae: 2095.4863 - val_loss: 1412543.7500 - val_mae: 956.1898\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 18218162.0000 - mae: 2093.6462 - val_loss: 1411641.3750 - val_mae: 955.7551\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18198040.0000 - mae: 2091.7629 - val_loss: 1410960.0000 - val_mae: 955.3948\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18184256.0000 - mae: 2090.2056 - val_loss: 1409936.7500 - val_mae: 954.9196\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18157166.0000 - mae: 2088.3406 - val_loss: 1408998.0000 - val_mae: 954.4994\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18146724.0000 - mae: 2087.6694 - val_loss: 1407996.7500 - val_mae: 954.0773\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 18123508.0000 - mae: 2085.8845 - val_loss: 1407642.7500 - val_mae: 953.8516\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18106772.0000 - mae: 2084.1809 - val_loss: 1407158.2500 - val_mae: 953.5978\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18089882.0000 - mae: 2082.5713 - val_loss: 1406747.0000 - val_mae: 953.3929\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 18068076.0000 - mae: 2081.0542 - val_loss: 1405911.7500 - val_mae: 953.0386\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 18054172.0000 - mae: 2079.7278 - val_loss: 1405185.7500 - val_mae: 952.7077\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 18036048.0000 - mae: 2078.1082 - val_loss: 1404444.2500 - val_mae: 952.3426\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 18019162.0000 - mae: 2076.4265 - val_loss: 1403735.7500 - val_mae: 952.0088\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 17999350.0000 - mae: 2075.0549 - val_loss: 1402997.2500 - val_mae: 951.7111\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17984180.0000 - mae: 2073.9858 - val_loss: 1402094.0000 - val_mae: 951.3519\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 17962292.0000 - mae: 2073.0247 - val_loss: 1401039.3750 - val_mae: 950.9435\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17941020.0000 - mae: 2071.6465 - val_loss: 1399045.7500 - val_mae: 950.2450\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17923860.0000 - mae: 2070.9243 - val_loss: 1397798.2500 - val_mae: 949.7754\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17907426.0000 - mae: 2070.2222 - val_loss: 1396902.3750 - val_mae: 949.4347\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17884832.0000 - mae: 2069.2075 - val_loss: 1396337.1250 - val_mae: 949.1756\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 17871788.0000 - mae: 2068.5222 - val_loss: 1395752.2500 - val_mae: 948.9362\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17853724.0000 - mae: 2067.4658 - val_loss: 1394929.2500 - val_mae: 948.5905\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 17841426.0000 - mae: 2066.7556 - val_loss: 1394272.1250 - val_mae: 948.2887\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17821172.0000 - mae: 2065.7148 - val_loss: 1393648.0000 - val_mae: 947.9819\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 17805382.0000 - mae: 2064.5581 - val_loss: 1393170.6250 - val_mae: 947.7068\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 17793804.0000 - mae: 2063.2039 - val_loss: 1392642.6250 - val_mae: 947.4230\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 17777172.0000 - mae: 2061.4792 - val_loss: 1391860.1250 - val_mae: 947.0865\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17759852.0000 - mae: 2059.6411 - val_loss: 1391190.6250 - val_mae: 946.7752\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17742408.0000 - mae: 2058.5317 - val_loss: 1389924.3750 - val_mae: 946.2609\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17719962.0000 - mae: 2057.7798 - val_loss: 1388745.6250 - val_mae: 945.7375\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 17702158.0000 - mae: 2057.3401 - val_loss: 1387620.7500 - val_mae: 945.2015\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 17693340.0000 - mae: 2057.2961 - val_loss: 1386445.7500 - val_mae: 944.6545\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 17661664.0000 - mae: 2056.6284 - val_loss: 1385608.6250 - val_mae: 944.2389\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17648192.0000 - mae: 2056.0254 - val_loss: 1384901.2500 - val_mae: 943.8116\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17627410.0000 - mae: 2055.0190 - val_loss: 1384287.5000 - val_mae: 943.4551\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17611508.0000 - mae: 2054.2769 - val_loss: 1383473.5000 - val_mae: 943.0231\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 17605206.0000 - mae: 2054.3750 - val_loss: 1381886.2500 - val_mae: 942.3635\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17570746.0000 - mae: 2052.8337 - val_loss: 1380994.2500 - val_mae: 941.9196\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17554700.0000 - mae: 2052.3425 - val_loss: 1379946.7500 - val_mae: 941.3709\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17531204.0000 - mae: 2051.7578 - val_loss: 1379129.7500 - val_mae: 940.9396\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17504528.0000 - mae: 2051.1746 - val_loss: 1378036.5000 - val_mae: 940.4323\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17488352.0000 - mae: 2051.0430 - val_loss: 1376929.6250 - val_mae: 939.8866\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17476012.0000 - mae: 2051.5476 - val_loss: 1375813.6250 - val_mae: 939.3890\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17448520.0000 - mae: 2051.2358 - val_loss: 1374849.3750 - val_mae: 938.9020\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 17433026.0000 - mae: 2050.8101 - val_loss: 1373845.7500 - val_mae: 938.4199\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17410566.0000 - mae: 2050.3279 - val_loss: 1373102.7500 - val_mae: 937.9502\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 17389474.0000 - mae: 2048.8594 - val_loss: 1372702.7500 - val_mae: 937.6623\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17378524.0000 - mae: 2048.3472 - val_loss: 1371780.3750 - val_mae: 937.1288\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17353034.0000 - mae: 2046.6035 - val_loss: 1371186.2500 - val_mae: 936.7278\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17334112.0000 - mae: 2045.4154 - val_loss: 1370364.7500 - val_mae: 936.3034\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 17316384.0000 - mae: 2044.6648 - val_loss: 1369565.6250 - val_mae: 935.8505\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17303112.0000 - mae: 2043.8145 - val_loss: 1368892.0000 - val_mae: 935.4215\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17286812.0000 - mae: 2042.4672 - val_loss: 1368315.8750 - val_mae: 935.0681\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17278110.0000 - mae: 2042.5974 - val_loss: 1366731.0000 - val_mae: 934.4174\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17249158.0000 - mae: 2042.6301 - val_loss: 1365757.3750 - val_mae: 933.9922\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17244612.0000 - mae: 2042.8910 - val_loss: 1364394.3750 - val_mae: 933.3766\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 17213544.0000 - mae: 2042.3379 - val_loss: 1363765.1250 - val_mae: 932.8957\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17194600.0000 - mae: 2041.0328 - val_loss: 1363285.6250 - val_mae: 932.4674\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 17173664.0000 - mae: 2038.8506 - val_loss: 1362826.6250 - val_mae: 932.1082\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 17156406.0000 - mae: 2037.0299 - val_loss: 1361779.6250 - val_mae: 931.6085\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17142232.0000 - mae: 2036.8367 - val_loss: 1360289.2500 - val_mae: 931.0049\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17113562.0000 - mae: 2037.2083 - val_loss: 1359297.7500 - val_mae: 930.5648\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 17103746.0000 - mae: 2037.1078 - val_loss: 1358365.7500 - val_mae: 930.0918\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 17074260.0000 - mae: 2035.5312 - val_loss: 1357987.0000 - val_mae: 929.7927\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17055688.0000 - mae: 2035.0254 - val_loss: 1356970.7500 - val_mae: 929.2360\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 17027008.0000 - mae: 2034.1707 - val_loss: 1356194.6250 - val_mae: 928.7440\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 17017194.0000 - mae: 2033.9880 - val_loss: 1355371.7500 - val_mae: 928.2653\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 16989964.0000 - mae: 2033.3754 - val_loss: 1354713.0000 - val_mae: 927.9247\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 16972748.0000 - mae: 2032.9368 - val_loss: 1353781.8750 - val_mae: 927.4655\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16942464.0000 - mae: 2032.4336 - val_loss: 1353182.7500 - val_mae: 927.1712\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16926000.0000 - mae: 2031.8851 - val_loss: 1352642.1250 - val_mae: 926.8875\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16901180.0000 - mae: 2031.1520 - val_loss: 1352077.2500 - val_mae: 926.5963\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 16885408.0000 - mae: 2030.7572 - val_loss: 1351356.3750 - val_mae: 926.2951\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 16862870.0000 - mae: 2030.6602 - val_loss: 1350226.1250 - val_mae: 925.8387\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 16855124.0000 - mae: 2031.6555 - val_loss: 1349251.6250 - val_mae: 925.3693\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16828800.0000 - mae: 2031.8059 - val_loss: 1348703.3750 - val_mae: 925.0501\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16809644.0000 - mae: 2031.3025 - val_loss: 1348543.7500 - val_mae: 924.8660\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 16789652.0000 - mae: 2029.6116 - val_loss: 1348404.2500 - val_mae: 924.6416\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 16765914.0000 - mae: 2028.2812 - val_loss: 1348109.6250 - val_mae: 924.3177\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16748133.0000 - mae: 2026.9225 - val_loss: 1347084.3750 - val_mae: 923.7653\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16717174.0000 - mae: 2026.6536 - val_loss: 1346310.7500 - val_mae: 923.2918\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16695450.0000 - mae: 2025.8148 - val_loss: 1345235.5000 - val_mae: 922.7474\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16681205.0000 - mae: 2025.9758 - val_loss: 1343839.0000 - val_mae: 922.1113\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 16644586.0000 - mae: 2026.1267 - val_loss: 1343049.2500 - val_mae: 921.6691\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 16619930.0000 - mae: 2026.1777 - val_loss: 1342601.7500 - val_mae: 921.3307\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 16601779.0000 - mae: 2026.4701 - val_loss: 1342307.3750 - val_mae: 921.0406\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16573310.0000 - mae: 2025.7152 - val_loss: 1341989.8750 - val_mae: 920.6916\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16553642.0000 - mae: 2024.8494 - val_loss: 1341707.1250 - val_mae: 920.3757\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16526274.0000 - mae: 2023.5098 - val_loss: 1341523.2500 - val_mae: 920.1818\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 16519723.0000 - mae: 2023.6830 - val_loss: 1340430.6250 - val_mae: 919.6654\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16479224.0000 - mae: 2022.1458 - val_loss: 1340132.6250 - val_mae: 919.3766\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 16461730.0000 - mae: 2020.6656 - val_loss: 1339929.2500 - val_mae: 919.1375\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16433677.0000 - mae: 2019.2820 - val_loss: 1339648.0000 - val_mae: 918.9064\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16422483.0000 - mae: 2018.2786 - val_loss: 1338698.5000 - val_mae: 918.4156\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16395947.0000 - mae: 2017.6002 - val_loss: 1338070.7500 - val_mae: 918.0707\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16375427.0000 - mae: 2016.6859 - val_loss: 1336655.2500 - val_mae: 917.4772\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16352698.0000 - mae: 2017.5664 - val_loss: 1335894.0000 - val_mae: 917.0729\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 16346478.0000 - mae: 2018.1260 - val_loss: 1335166.5000 - val_mae: 916.5957\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16307347.0000 - mae: 2017.0244 - val_loss: 1334849.5000 - val_mae: 916.3094\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 16281110.0000 - mae: 2015.9528 - val_loss: 1334461.7500 - val_mae: 915.9705\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16265136.0000 - mae: 2015.8424 - val_loss: 1333530.8750 - val_mae: 915.4609\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16255698.0000 - mae: 2016.4430 - val_loss: 1332505.7500 - val_mae: 914.9183\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 16227203.0000 - mae: 2016.1003 - val_loss: 1331963.2500 - val_mae: 914.5360\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16201115.0000 - mae: 2015.1002 - val_loss: 1331494.2500 - val_mae: 914.1827\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16183181.0000 - mae: 2014.5602 - val_loss: 1330727.0000 - val_mae: 913.6534\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16161704.0000 - mae: 2013.7998 - val_loss: 1330367.8750 - val_mae: 913.2969\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16134666.0000 - mae: 2012.0195 - val_loss: 1330237.0000 - val_mae: 912.9857\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 16141917.0000 - mae: 2010.7234 - val_loss: 1329984.8750 - val_mae: 912.5492\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16110178.0000 - mae: 2009.3031 - val_loss: 1329377.8750 - val_mae: 912.1577\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16082861.0000 - mae: 2008.3242 - val_loss: 1329032.8750 - val_mae: 911.8237\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 16063875.0000 - mae: 2007.2551 - val_loss: 1328819.2500 - val_mae: 911.4996\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 16054856.0000 - mae: 2005.7061 - val_loss: 1328800.2500 - val_mae: 911.2632\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16022595.0000 - mae: 2004.8226 - val_loss: 1327708.7500 - val_mae: 910.6537\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 16017027.0000 - mae: 2005.5625 - val_loss: 1326498.7500 - val_mae: 909.9893\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 15992813.0000 - mae: 2005.5452 - val_loss: 1326061.2500 - val_mae: 909.5779\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15968171.0000 - mae: 2004.7360 - val_loss: 1325923.1250 - val_mae: 909.3249\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15940541.0000 - mae: 2004.6705 - val_loss: 1325201.5000 - val_mae: 908.8763\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 15926390.0000 - mae: 2005.4838 - val_loss: 1324416.0000 - val_mae: 908.3842\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15899325.0000 - mae: 2005.1780 - val_loss: 1323943.0000 - val_mae: 907.9734\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15887776.0000 - mae: 2005.5701 - val_loss: 1322938.1250 - val_mae: 907.3580\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15861038.0000 - mae: 2005.1771 - val_loss: 1322595.8750 - val_mae: 906.9958\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15847954.0000 - mae: 2005.3658 - val_loss: 1321974.3750 - val_mae: 906.5945\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 15825115.0000 - mae: 2004.9846 - val_loss: 1321965.2500 - val_mae: 906.3024\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15807923.0000 - mae: 2003.3242 - val_loss: 1321760.0000 - val_mae: 905.9974\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 15792986.0000 - mae: 2003.0217 - val_loss: 1321116.3750 - val_mae: 905.5762\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15774362.0000 - mae: 2003.0424 - val_loss: 1320755.6250 - val_mae: 905.2135\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15762656.0000 - mae: 2003.3464 - val_loss: 1320191.6250 - val_mae: 904.8030\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15745574.0000 - mae: 2003.4631 - val_loss: 1319691.7500 - val_mae: 904.3622\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15729154.0000 - mae: 2003.4596 - val_loss: 1319459.6250 - val_mae: 903.9871\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15720349.0000 - mae: 2002.4004 - val_loss: 1319650.7500 - val_mae: 903.7014\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15707850.0000 - mae: 2000.9254 - val_loss: 1318959.2500 - val_mae: 903.3068\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15678717.0000 - mae: 1999.6877 - val_loss: 1318720.7500 - val_mae: 903.0731\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15672205.0000 - mae: 1998.7145 - val_loss: 1318668.2500 - val_mae: 903.0369\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15649853.0000 - mae: 1996.8770 - val_loss: 1318501.7500 - val_mae: 903.0339\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 15641894.0000 - mae: 1995.5934 - val_loss: 1318422.2500 - val_mae: 903.0720\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 15630762.0000 - mae: 1995.3209 - val_loss: 1317199.7500 - val_mae: 902.5765\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15600597.0000 - mae: 1995.2084 - val_loss: 1316818.0000 - val_mae: 902.4513\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15589174.0000 - mae: 1994.7649 - val_loss: 1316691.3750 - val_mae: 902.4207\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15571048.0000 - mae: 1994.4408 - val_loss: 1316641.7500 - val_mae: 902.4294\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15560381.0000 - mae: 1995.2920 - val_loss: 1316398.3750 - val_mae: 902.3387\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15542166.0000 - mae: 1994.5615 - val_loss: 1316484.3750 - val_mae: 902.3856\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15527942.0000 - mae: 1993.8301 - val_loss: 1316320.8750 - val_mae: 902.3275\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15516824.0000 - mae: 1992.9827 - val_loss: 1316176.7500 - val_mae: 902.2531\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15502909.0000 - mae: 1991.7644 - val_loss: 1316498.7500 - val_mae: 902.3846\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15484587.0000 - mae: 1989.7327 - val_loss: 1316514.7500 - val_mae: 902.3763\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15469794.0000 - mae: 1988.5580 - val_loss: 1316706.6250 - val_mae: 902.4476\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 15457243.0000 - mae: 1987.1467 - val_loss: 1316795.6250 - val_mae: 902.4974\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 15448394.0000 - mae: 1986.1227 - val_loss: 1316684.7500 - val_mae: 902.4334\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15422824.0000 - mae: 1985.0248 - val_loss: 1315883.2500 - val_mae: 902.0662\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15422656.0000 - mae: 1985.8990 - val_loss: 1315252.6250 - val_mae: 901.7246\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15396814.0000 - mae: 1985.4020 - val_loss: 1315386.2500 - val_mae: 901.7497\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15377869.0000 - mae: 1984.4348 - val_loss: 1315591.3750 - val_mae: 901.8057\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15366192.0000 - mae: 1983.6931 - val_loss: 1315076.7500 - val_mae: 901.5057\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15342454.0000 - mae: 1983.7311 - val_loss: 1314939.6250 - val_mae: 901.3753\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15323120.0000 - mae: 1982.8513 - val_loss: 1314301.5000 - val_mae: 901.0007\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15306554.0000 - mae: 1983.2253 - val_loss: 1313772.0000 - val_mae: 900.6595\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15293971.0000 - mae: 1983.8473 - val_loss: 1313505.2500 - val_mae: 900.4191\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 15282195.0000 - mae: 1984.4320 - val_loss: 1313374.3750 - val_mae: 900.2492\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 15274960.0000 - mae: 1984.6215 - val_loss: 1313118.7500 - val_mae: 900.0568\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15243312.0000 - mae: 1985.1504 - val_loss: 1312236.0000 - val_mae: 899.5328\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15257056.0000 - mae: 1988.1615 - val_loss: 1311483.2500 - val_mae: 899.0846\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 15234446.0000 - mae: 1988.8347 - val_loss: 1311508.2500 - val_mae: 899.0114\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 15210062.0000 - mae: 1987.5690 - val_loss: 1311966.2500 - val_mae: 899.1287\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15204013.0000 - mae: 1985.5886 - val_loss: 1312567.0000 - val_mae: 899.3187\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15189773.0000 - mae: 1984.1570 - val_loss: 1312623.0000 - val_mae: 899.2430\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15180707.0000 - mae: 1982.9899 - val_loss: 1313224.0000 - val_mae: 899.4074\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15170651.0000 - mae: 1980.6891 - val_loss: 1313831.2500 - val_mae: 899.5612\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15157533.0000 - mae: 1979.6426 - val_loss: 1314001.3750 - val_mae: 899.5252\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 15149290.0000 - mae: 1979.4664 - val_loss: 1313193.1250 - val_mae: 898.9967\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15125312.0000 - mae: 1978.9583 - val_loss: 1312637.6250 - val_mae: 898.5866\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 15106211.0000 - mae: 1979.0365 - val_loss: 1312311.7500 - val_mae: 898.3066\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Results for year =  2014\n",
      "8/8 [==============================] - 3s 117ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 181ms/step - loss: 33052666.0000 - mae: 2459.8296 - val_loss: 1857736.0000 - val_mae: 1118.4662\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 33052266.0000 - mae: 2459.7886 - val_loss: 1857688.7500 - val_mae: 1118.4464\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33051828.0000 - mae: 2459.7463 - val_loss: 1857638.7500 - val_mae: 1118.4244\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 33051450.0000 - mae: 2459.7112 - val_loss: 1857590.2500 - val_mae: 1118.4021\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33051146.0000 - mae: 2459.6689 - val_loss: 1857547.0000 - val_mae: 1118.3812\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 33050644.0000 - mae: 2459.6272 - val_loss: 1857508.7500 - val_mae: 1118.3627\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 33050300.0000 - mae: 2459.5884 - val_loss: 1857464.3750 - val_mae: 1118.3412\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 33049904.0000 - mae: 2459.5435 - val_loss: 1857419.2500 - val_mae: 1118.3191\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33049488.0000 - mae: 2459.4988 - val_loss: 1857379.0000 - val_mae: 1118.2991\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33049008.0000 - mae: 2459.4526 - val_loss: 1857338.3750 - val_mae: 1118.2789\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33048586.0000 - mae: 2459.4053 - val_loss: 1857296.2500 - val_mae: 1118.2581\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 33048102.0000 - mae: 2459.3481 - val_loss: 1857250.3750 - val_mae: 1118.2362\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 33047604.0000 - mae: 2459.2913 - val_loss: 1857196.0000 - val_mae: 1118.2117\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33047120.0000 - mae: 2459.2356 - val_loss: 1857128.7500 - val_mae: 1118.1826\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 33046436.0000 - mae: 2459.1665 - val_loss: 1857052.3750 - val_mae: 1118.1516\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33045786.0000 - mae: 2459.0984 - val_loss: 1856965.3750 - val_mae: 1118.1165\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33045184.0000 - mae: 2459.0181 - val_loss: 1856875.3750 - val_mae: 1118.0798\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33044436.0000 - mae: 2458.9380 - val_loss: 1856791.6250 - val_mae: 1118.0449\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33043686.0000 - mae: 2458.8618 - val_loss: 1856710.3750 - val_mae: 1118.0107\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33042806.0000 - mae: 2458.7708 - val_loss: 1856618.7500 - val_mae: 1117.9720\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 33041884.0000 - mae: 2458.6714 - val_loss: 1856511.6250 - val_mae: 1117.9271\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33041130.0000 - mae: 2458.5864 - val_loss: 1856394.0000 - val_mae: 1117.8774\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33040010.0000 - mae: 2458.4548 - val_loss: 1856292.0000 - val_mae: 1117.8328\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33038804.0000 - mae: 2458.3391 - val_loss: 1856172.0000 - val_mae: 1117.7820\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 33037702.0000 - mae: 2458.2158 - val_loss: 1856022.0000 - val_mae: 1117.7209\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33036652.0000 - mae: 2458.0630 - val_loss: 1855851.6250 - val_mae: 1117.6521\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33035120.0000 - mae: 2457.8877 - val_loss: 1855696.7500 - val_mae: 1117.5891\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33033882.0000 - mae: 2457.7493 - val_loss: 1855524.2500 - val_mae: 1117.5193\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33032294.0000 - mae: 2457.5776 - val_loss: 1855367.2500 - val_mae: 1117.4548\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33030948.0000 - mae: 2457.4124 - val_loss: 1855214.0000 - val_mae: 1117.3904\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33029466.0000 - mae: 2457.2407 - val_loss: 1855044.3750 - val_mae: 1117.3201\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33027892.0000 - mae: 2457.0647 - val_loss: 1854862.6250 - val_mae: 1117.2449\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33025924.0000 - mae: 2456.8413 - val_loss: 1854697.2500 - val_mae: 1117.1750\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 33023914.0000 - mae: 2456.6279 - val_loss: 1854511.2500 - val_mae: 1117.0973\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 33022038.0000 - mae: 2456.3970 - val_loss: 1854270.7500 - val_mae: 1116.9990\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33019700.0000 - mae: 2456.1372 - val_loss: 1854010.2500 - val_mae: 1116.8929\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33017840.0000 - mae: 2455.9131 - val_loss: 1853725.6250 - val_mae: 1116.7776\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 33014516.0000 - mae: 2455.5586 - val_loss: 1853491.0000 - val_mae: 1116.6803\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 33012134.0000 - mae: 2455.2529 - val_loss: 1853218.7500 - val_mae: 1116.5677\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33009292.0000 - mae: 2454.9673 - val_loss: 1852934.2500 - val_mae: 1116.4504\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33006448.0000 - mae: 2454.5852 - val_loss: 1852624.3750 - val_mae: 1116.3223\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33002810.0000 - mae: 2454.1929 - val_loss: 1852314.0000 - val_mae: 1116.1930\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33000176.0000 - mae: 2453.8325 - val_loss: 1852010.6250 - val_mae: 1116.0653\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 32996518.0000 - mae: 2453.4185 - val_loss: 1851697.0000 - val_mae: 1115.9342\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 32992268.0000 - mae: 2452.9517 - val_loss: 1851390.2500 - val_mae: 1115.8059\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32988534.0000 - mae: 2452.5261 - val_loss: 1851038.0000 - val_mae: 1115.6599\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32984272.0000 - mae: 2452.0586 - val_loss: 1850639.0000 - val_mae: 1115.4957\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 32980538.0000 - mae: 2451.5747 - val_loss: 1850222.7500 - val_mae: 1115.3218\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 32975024.0000 - mae: 2450.9670 - val_loss: 1849813.6250 - val_mae: 1115.1501\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32970042.0000 - mae: 2450.3362 - val_loss: 1849382.6250 - val_mae: 1114.9709\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32964220.0000 - mae: 2449.7107 - val_loss: 1848947.6250 - val_mae: 1114.7897\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 32958292.0000 - mae: 2449.0413 - val_loss: 1848471.2500 - val_mae: 1114.5916\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32952102.0000 - mae: 2448.3372 - val_loss: 1847942.6250 - val_mae: 1114.3723\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 32946118.0000 - mae: 2447.5952 - val_loss: 1847384.0000 - val_mae: 1114.1407\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32938064.0000 - mae: 2446.6675 - val_loss: 1846883.7500 - val_mae: 1113.9299\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32930708.0000 - mae: 2445.8176 - val_loss: 1846337.0000 - val_mae: 1113.7012\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32921978.0000 - mae: 2444.9304 - val_loss: 1845789.3750 - val_mae: 1113.4677\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32915228.0000 - mae: 2443.9912 - val_loss: 1845177.2500 - val_mae: 1113.2058\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 32904388.0000 - mae: 2442.7593 - val_loss: 1844630.7500 - val_mae: 1112.9691\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32895408.0000 - mae: 2441.8530 - val_loss: 1844010.7500 - val_mae: 1112.7037\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32885530.0000 - mae: 2440.6572 - val_loss: 1843360.0000 - val_mae: 1112.4250\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32874224.0000 - mae: 2439.4475 - val_loss: 1842704.3750 - val_mae: 1112.1453\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32864774.0000 - mae: 2438.1750 - val_loss: 1841970.0000 - val_mae: 1111.8311\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 32851670.0000 - mae: 2436.7271 - val_loss: 1841266.6250 - val_mae: 1111.5281\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 32839060.0000 - mae: 2435.2166 - val_loss: 1840547.3750 - val_mae: 1111.2184\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32826972.0000 - mae: 2433.7402 - val_loss: 1839809.3750 - val_mae: 1110.8994\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32813484.0000 - mae: 2432.2537 - val_loss: 1839078.7500 - val_mae: 1110.5834\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32799162.0000 - mae: 2430.5879 - val_loss: 1838377.2500 - val_mae: 1110.2771\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32784780.0000 - mae: 2428.8406 - val_loss: 1837642.3750 - val_mae: 1109.9587\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 32769892.0000 - mae: 2427.2856 - val_loss: 1836854.7500 - val_mae: 1109.6174\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32753732.0000 - mae: 2425.2996 - val_loss: 1836076.7500 - val_mae: 1109.2771\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32739184.0000 - mae: 2423.3892 - val_loss: 1835186.0000 - val_mae: 1108.8906\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32721670.0000 - mae: 2421.4221 - val_loss: 1834260.6250 - val_mae: 1108.4890\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32703754.0000 - mae: 2419.2573 - val_loss: 1833366.3750 - val_mae: 1108.0979\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32686716.0000 - mae: 2417.0894 - val_loss: 1832490.7500 - val_mae: 1107.7157\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32662784.0000 - mae: 2414.7085 - val_loss: 1831751.0000 - val_mae: 1107.3929\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32646860.0000 - mae: 2412.6929 - val_loss: 1830834.7500 - val_mae: 1106.9987\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32627082.0000 - mae: 2410.6140 - val_loss: 1829918.0000 - val_mae: 1106.6025\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32606124.0000 - mae: 2407.8003 - val_loss: 1828973.2500 - val_mae: 1106.1958\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32585364.0000 - mae: 2405.0034 - val_loss: 1828011.3750 - val_mae: 1105.7786\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 32559974.0000 - mae: 2402.7441 - val_loss: 1827013.7500 - val_mae: 1105.3441\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32537904.0000 - mae: 2400.2058 - val_loss: 1825964.7500 - val_mae: 1104.8909\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32518832.0000 - mae: 2398.0144 - val_loss: 1824913.2500 - val_mae: 1104.4336\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32492588.0000 - mae: 2394.9993 - val_loss: 1823876.3750 - val_mae: 1103.9792\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32467356.0000 - mae: 2392.1362 - val_loss: 1822887.2500 - val_mae: 1103.5416\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32441520.0000 - mae: 2389.3875 - val_loss: 1821920.2500 - val_mae: 1103.1138\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32415692.0000 - mae: 2386.1248 - val_loss: 1820885.6250 - val_mae: 1102.6576\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 32386748.0000 - mae: 2382.8333 - val_loss: 1819875.2500 - val_mae: 1102.2112\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32362390.0000 - mae: 2380.1995 - val_loss: 1818690.7500 - val_mae: 1101.6953\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 32335722.0000 - mae: 2376.6648 - val_loss: 1817486.7500 - val_mae: 1101.1725\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32305788.0000 - mae: 2373.4067 - val_loss: 1816272.0000 - val_mae: 1100.6459\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 32271980.0000 - mae: 2370.1433 - val_loss: 1815140.7500 - val_mae: 1100.1537\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32249220.0000 - mae: 2367.6372 - val_loss: 1813873.0000 - val_mae: 1099.6031\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 32212700.0000 - mae: 2363.7954 - val_loss: 1812664.7500 - val_mae: 1099.0787\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 32181814.0000 - mae: 2360.5471 - val_loss: 1811406.0000 - val_mae: 1098.5322\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32148000.0000 - mae: 2357.5024 - val_loss: 1810033.3750 - val_mae: 1097.9392\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32121702.0000 - mae: 2354.2493 - val_loss: 1808641.2500 - val_mae: 1097.3376\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32086650.0000 - mae: 2350.7043 - val_loss: 1807279.6250 - val_mae: 1096.7504\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32052956.0000 - mae: 2347.6069 - val_loss: 1805924.2500 - val_mae: 1096.1620\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32023504.0000 - mae: 2343.7566 - val_loss: 1804423.0000 - val_mae: 1095.5129\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 31982214.0000 - mae: 2340.0125 - val_loss: 1803109.0000 - val_mae: 1094.9402\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 31954102.0000 - mae: 2336.6426 - val_loss: 1801666.2500 - val_mae: 1094.3124\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 31923216.0000 - mae: 2332.9707 - val_loss: 1800223.3750 - val_mae: 1093.6854\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31886240.0000 - mae: 2329.1499 - val_loss: 1798875.3750 - val_mae: 1093.0968\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 31854912.0000 - mae: 2325.0159 - val_loss: 1797485.6250 - val_mae: 1092.4886\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 31820988.0000 - mae: 2321.5479 - val_loss: 1796137.0000 - val_mae: 1091.8903\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 31790810.0000 - mae: 2318.3867 - val_loss: 1794757.3750 - val_mae: 1091.2786\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 31755360.0000 - mae: 2315.0276 - val_loss: 1793375.2500 - val_mae: 1090.6649\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31720074.0000 - mae: 2311.2808 - val_loss: 1792000.7500 - val_mae: 1090.0576\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 31690956.0000 - mae: 2308.0469 - val_loss: 1790636.7500 - val_mae: 1089.4539\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31663510.0000 - mae: 2305.1023 - val_loss: 1789127.7500 - val_mae: 1088.7864\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31626890.0000 - mae: 2301.2583 - val_loss: 1787733.6250 - val_mae: 1088.1638\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 31598252.0000 - mae: 2298.6570 - val_loss: 1786261.3750 - val_mae: 1087.5045\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 31557652.0000 - mae: 2294.6038 - val_loss: 1785051.6250 - val_mae: 1086.9602\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31532180.0000 - mae: 2291.8828 - val_loss: 1783685.6250 - val_mae: 1086.3516\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31500912.0000 - mae: 2288.4302 - val_loss: 1782317.3750 - val_mae: 1085.7380\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 31461036.0000 - mae: 2284.4575 - val_loss: 1781042.0000 - val_mae: 1085.1703\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31439466.0000 - mae: 2281.6995 - val_loss: 1779492.0000 - val_mae: 1084.4822\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31401968.0000 - mae: 2278.1414 - val_loss: 1778012.0000 - val_mae: 1083.8275\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 31372380.0000 - mae: 2274.6404 - val_loss: 1776518.0000 - val_mae: 1083.1672\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 31330784.0000 - mae: 2270.9182 - val_loss: 1775091.0000 - val_mae: 1082.5408\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 31310580.0000 - mae: 2268.1665 - val_loss: 1773389.0000 - val_mae: 1081.7952\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 31274438.0000 - mae: 2264.7886 - val_loss: 1771777.6250 - val_mae: 1081.0820\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 31242160.0000 - mae: 2262.2014 - val_loss: 1770130.0000 - val_mae: 1080.3579\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 31217812.0000 - mae: 2259.2483 - val_loss: 1768347.3750 - val_mae: 1079.5724\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 31177366.0000 - mae: 2255.9375 - val_loss: 1766820.7500 - val_mae: 1078.8923\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 31152710.0000 - mae: 2253.2966 - val_loss: 1765274.3750 - val_mae: 1078.2056\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 31120876.0000 - mae: 2250.4102 - val_loss: 1763900.6250 - val_mae: 1077.6046\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 31094310.0000 - mae: 2248.0439 - val_loss: 1762358.0000 - val_mae: 1076.9229\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31067444.0000 - mae: 2245.3420 - val_loss: 1760840.0000 - val_mae: 1076.2651\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 31037664.0000 - mae: 2242.3235 - val_loss: 1759294.3750 - val_mae: 1075.6006\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31012368.0000 - mae: 2239.7874 - val_loss: 1757620.2500 - val_mae: 1074.8816\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 30969142.0000 - mae: 2236.3374 - val_loss: 1756233.6250 - val_mae: 1074.2822\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 30942058.0000 - mae: 2234.0208 - val_loss: 1754583.6250 - val_mae: 1073.5779\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30913958.0000 - mae: 2231.0691 - val_loss: 1752842.7500 - val_mae: 1072.8296\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30879348.0000 - mae: 2228.4370 - val_loss: 1750963.2500 - val_mae: 1072.0170\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 30853994.0000 - mae: 2225.8999 - val_loss: 1748862.0000 - val_mae: 1071.1068\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30808806.0000 - mae: 2222.4038 - val_loss: 1747142.3750 - val_mae: 1070.3674\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30776884.0000 - mae: 2219.8938 - val_loss: 1745185.2500 - val_mae: 1069.5245\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30758356.0000 - mae: 2217.4814 - val_loss: 1742888.3750 - val_mae: 1068.5348\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30721108.0000 - mae: 2214.7314 - val_loss: 1741015.6250 - val_mae: 1067.7328\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30689114.0000 - mae: 2212.1824 - val_loss: 1739420.6250 - val_mae: 1067.0687\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 30655226.0000 - mae: 2209.2141 - val_loss: 1737611.6250 - val_mae: 1066.3021\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 30628054.0000 - mae: 2207.2664 - val_loss: 1735579.6250 - val_mae: 1065.4390\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 30598012.0000 - mae: 2204.5103 - val_loss: 1733368.0000 - val_mae: 1064.4948\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30562378.0000 - mae: 2201.5901 - val_loss: 1731173.2500 - val_mae: 1063.5593\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 30537856.0000 - mae: 2198.9243 - val_loss: 1728764.7500 - val_mae: 1062.5271\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 30496804.0000 - mae: 2195.6252 - val_loss: 1726660.2500 - val_mae: 1061.6379\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 30474726.0000 - mae: 2193.1169 - val_loss: 1724490.3750 - val_mae: 1060.7239\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30437052.0000 - mae: 2190.3562 - val_loss: 1722452.7500 - val_mae: 1059.8621\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 30412380.0000 - mae: 2187.8533 - val_loss: 1720167.6250 - val_mae: 1058.8911\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 30377606.0000 - mae: 2184.8660 - val_loss: 1718220.3750 - val_mae: 1058.0840\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 30340676.0000 - mae: 2182.1768 - val_loss: 1716365.6250 - val_mae: 1057.3217\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30312300.0000 - mae: 2179.7961 - val_loss: 1713908.0000 - val_mae: 1056.2927\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 30284374.0000 - mae: 2176.9209 - val_loss: 1711708.0000 - val_mae: 1055.3832\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 30256436.0000 - mae: 2174.7083 - val_loss: 1709578.3750 - val_mae: 1054.5098\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30222004.0000 - mae: 2172.1509 - val_loss: 1707684.2500 - val_mae: 1053.7324\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30191620.0000 - mae: 2169.9861 - val_loss: 1705755.6250 - val_mae: 1052.9412\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30160452.0000 - mae: 2167.8118 - val_loss: 1703647.6250 - val_mae: 1052.0663\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 30126932.0000 - mae: 2165.0759 - val_loss: 1701187.3750 - val_mae: 1051.0269\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30099594.0000 - mae: 2162.3555 - val_loss: 1698510.7500 - val_mae: 1049.8936\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 30061014.0000 - mae: 2159.4214 - val_loss: 1695891.2500 - val_mae: 1048.7722\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 30031242.0000 - mae: 2156.4543 - val_loss: 1693455.2500 - val_mae: 1047.7350\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 29998964.0000 - mae: 2153.2180 - val_loss: 1691060.0000 - val_mae: 1046.7164\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29963812.0000 - mae: 2150.6355 - val_loss: 1688589.0000 - val_mae: 1045.6692\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 29930844.0000 - mae: 2147.7380 - val_loss: 1686171.6250 - val_mae: 1044.6516\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29894292.0000 - mae: 2144.6653 - val_loss: 1683549.2500 - val_mae: 1043.5333\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29865322.0000 - mae: 2141.8438 - val_loss: 1681003.0000 - val_mae: 1042.4655\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29825332.0000 - mae: 2138.5833 - val_loss: 1678358.0000 - val_mae: 1041.3549\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29802010.0000 - mae: 2135.9641 - val_loss: 1674986.6250 - val_mae: 1039.9102\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29779044.0000 - mae: 2133.0039 - val_loss: 1672069.2500 - val_mae: 1038.6660\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29729908.0000 - mae: 2129.5425 - val_loss: 1669992.7500 - val_mae: 1037.8284\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 29697484.0000 - mae: 2127.8582 - val_loss: 1667822.7500 - val_mae: 1036.9473\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 29677146.0000 - mae: 2125.8042 - val_loss: 1665149.7500 - val_mae: 1035.8263\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29642822.0000 - mae: 2122.8013 - val_loss: 1662481.0000 - val_mae: 1034.7000\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29611072.0000 - mae: 2120.3755 - val_loss: 1659452.7500 - val_mae: 1033.5223\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29586176.0000 - mae: 2117.8003 - val_loss: 1656782.8750 - val_mae: 1032.4965\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 29555034.0000 - mae: 2115.1714 - val_loss: 1654551.2500 - val_mae: 1031.6459\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29520724.0000 - mae: 2112.6340 - val_loss: 1652787.2500 - val_mae: 1031.0052\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29494688.0000 - mae: 2111.2761 - val_loss: 1650411.2500 - val_mae: 1030.1091\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 29457030.0000 - mae: 2108.8657 - val_loss: 1647935.1250 - val_mae: 1029.1570\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29434086.0000 - mae: 2106.5862 - val_loss: 1645181.6250 - val_mae: 1028.0906\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29409562.0000 - mae: 2104.3225 - val_loss: 1642414.7500 - val_mae: 1027.0082\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 29367462.0000 - mae: 2101.1697 - val_loss: 1640144.0000 - val_mae: 1026.1365\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29342202.0000 - mae: 2098.9624 - val_loss: 1637753.2500 - val_mae: 1025.1978\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29324164.0000 - mae: 2096.8438 - val_loss: 1635475.2500 - val_mae: 1024.3085\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 29276368.0000 - mae: 2093.9243 - val_loss: 1633758.3750 - val_mae: 1023.6674\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29254310.0000 - mae: 2092.3857 - val_loss: 1631612.2500 - val_mae: 1022.8751\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29223424.0000 - mae: 2090.5493 - val_loss: 1629755.7500 - val_mae: 1022.2068\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29190236.0000 - mae: 2088.9644 - val_loss: 1627961.0000 - val_mae: 1021.5509\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 29157012.0000 - mae: 2086.9785 - val_loss: 1625620.2500 - val_mae: 1020.6639\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29132012.0000 - mae: 2084.7363 - val_loss: 1623107.2500 - val_mae: 1019.6918\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 29099932.0000 - mae: 2082.4580 - val_loss: 1620787.0000 - val_mae: 1018.7897\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29075268.0000 - mae: 2080.5642 - val_loss: 1618343.7500 - val_mae: 1017.8314\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29034182.0000 - mae: 2078.2090 - val_loss: 1616511.7500 - val_mae: 1017.1232\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 29007508.0000 - mae: 2076.3340 - val_loss: 1614484.3750 - val_mae: 1016.3356\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28978422.0000 - mae: 2074.7571 - val_loss: 1612321.1250 - val_mae: 1015.4988\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28943308.0000 - mae: 2072.8083 - val_loss: 1610042.3750 - val_mae: 1014.6125\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28925722.0000 - mae: 2071.0249 - val_loss: 1607248.2500 - val_mae: 1013.5015\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28885172.0000 - mae: 2068.2969 - val_loss: 1604903.3750 - val_mae: 1012.5861\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 28848010.0000 - mae: 2066.3425 - val_loss: 1602547.2500 - val_mae: 1011.6680\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28820246.0000 - mae: 2064.2446 - val_loss: 1600497.6250 - val_mae: 1010.8822\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28797126.0000 - mae: 2062.3960 - val_loss: 1597883.7500 - val_mae: 1009.8529\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28751584.0000 - mae: 2059.8384 - val_loss: 1595904.8750 - val_mae: 1009.0744\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 28733158.0000 - mae: 2058.4863 - val_loss: 1593784.0000 - val_mae: 1008.2365\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28690624.0000 - mae: 2056.2812 - val_loss: 1591938.8750 - val_mae: 1007.5250\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28657498.0000 - mae: 2054.7310 - val_loss: 1589798.6250 - val_mae: 1006.6869\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28629028.0000 - mae: 2052.7300 - val_loss: 1587262.6250 - val_mae: 1005.6729\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28602140.0000 - mae: 2050.5522 - val_loss: 1584866.3750 - val_mae: 1004.7070\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28558592.0000 - mae: 2048.3618 - val_loss: 1583351.0000 - val_mae: 1004.1096\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 28537716.0000 - mae: 2046.8685 - val_loss: 1581692.6250 - val_mae: 1003.4659\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28499360.0000 - mae: 2045.1049 - val_loss: 1580115.6250 - val_mae: 1002.8553\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28463158.0000 - mae: 2043.6227 - val_loss: 1578462.8750 - val_mae: 1002.2082\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28441120.0000 - mae: 2041.9508 - val_loss: 1576431.1250 - val_mae: 1001.3967\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28404102.0000 - mae: 2040.2623 - val_loss: 1574453.2500 - val_mae: 1000.6188\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28374998.0000 - mae: 2038.9918 - val_loss: 1572846.6250 - val_mae: 999.9893\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 28343540.0000 - mae: 2037.5641 - val_loss: 1571660.2500 - val_mae: 999.5267\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28302538.0000 - mae: 2037.2379 - val_loss: 1571065.7500 - val_mae: 999.3141\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28278378.0000 - mae: 2037.6680 - val_loss: 1569759.3750 - val_mae: 998.8009\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28246614.0000 - mae: 2036.5537 - val_loss: 1568017.6250 - val_mae: 998.0969\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 28217846.0000 - mae: 2035.1022 - val_loss: 1566389.7500 - val_mae: 997.4455\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28177260.0000 - mae: 2034.1951 - val_loss: 1565243.5000 - val_mae: 996.9997\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28144832.0000 - mae: 2033.1058 - val_loss: 1563567.0000 - val_mae: 996.3185\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28116502.0000 - mae: 2031.2637 - val_loss: 1561707.6250 - val_mae: 995.6110\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28087664.0000 - mae: 2029.4987 - val_loss: 1560052.7500 - val_mae: 994.9813\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28045530.0000 - mae: 2028.4095 - val_loss: 1558855.2500 - val_mae: 994.5184\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28026090.0000 - mae: 2027.3997 - val_loss: 1557006.3750 - val_mae: 993.7969\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 27988490.0000 - mae: 2026.2670 - val_loss: 1555553.0000 - val_mae: 993.2180\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27946774.0000 - mae: 2025.0551 - val_loss: 1554202.5000 - val_mae: 992.6919\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27917444.0000 - mae: 2023.4391 - val_loss: 1552411.6250 - val_mae: 992.0012\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 27884732.0000 - mae: 2021.8137 - val_loss: 1550637.2500 - val_mae: 991.3156\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27851728.0000 - mae: 2020.0359 - val_loss: 1549039.8750 - val_mae: 990.7093\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27810688.0000 - mae: 2019.0312 - val_loss: 1548043.3750 - val_mae: 990.3342\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27776964.0000 - mae: 2018.4055 - val_loss: 1546922.0000 - val_mae: 989.9180\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27739002.0000 - mae: 2017.4075 - val_loss: 1545554.7500 - val_mae: 989.4012\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27707364.0000 - mae: 2016.1816 - val_loss: 1544522.2500 - val_mae: 989.0162\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27667622.0000 - mae: 2015.4583 - val_loss: 1543279.3750 - val_mae: 988.5501\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27631324.0000 - mae: 2014.8054 - val_loss: 1541573.2500 - val_mae: 987.9026\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 27583380.0000 - mae: 2013.4480 - val_loss: 1541038.6250 - val_mae: 987.7196\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 27557444.0000 - mae: 2014.1315 - val_loss: 1540009.1250 - val_mae: 987.3478\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27515292.0000 - mae: 2014.4147 - val_loss: 1538755.0000 - val_mae: 986.8699\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27480764.0000 - mae: 2014.2415 - val_loss: 1537912.3750 - val_mae: 986.5460\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27454150.0000 - mae: 2014.2406 - val_loss: 1536711.0000 - val_mae: 986.0751\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27414900.0000 - mae: 2014.2939 - val_loss: 1536095.5000 - val_mae: 985.8410\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27386342.0000 - mae: 2014.1165 - val_loss: 1534679.3750 - val_mae: 985.3021\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27354644.0000 - mae: 2014.1781 - val_loss: 1533894.7500 - val_mae: 985.0237\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 27324272.0000 - mae: 2014.4250 - val_loss: 1532796.3750 - val_mae: 984.6349\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27284458.0000 - mae: 2014.2285 - val_loss: 1531547.7500 - val_mae: 984.1929\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27259732.0000 - mae: 2014.5574 - val_loss: 1530608.6250 - val_mae: 983.8612\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 27222042.0000 - mae: 2014.5719 - val_loss: 1529778.3750 - val_mae: 983.5739\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27194052.0000 - mae: 2014.4089 - val_loss: 1528439.7500 - val_mae: 983.1111\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27162998.0000 - mae: 2013.6907 - val_loss: 1526962.3750 - val_mae: 982.6010\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27116086.0000 - mae: 2013.2633 - val_loss: 1525797.6250 - val_mae: 982.1927\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27075840.0000 - mae: 2012.4160 - val_loss: 1524798.5000 - val_mae: 981.8486\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 27044560.0000 - mae: 2012.3147 - val_loss: 1523925.5000 - val_mae: 981.5458\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27013338.0000 - mae: 2012.1780 - val_loss: 1522704.6250 - val_mae: 981.1152\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26956116.0000 - mae: 2011.2129 - val_loss: 1521301.7500 - val_mae: 980.6268\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26927590.0000 - mae: 2010.5504 - val_loss: 1520031.8750 - val_mae: 980.1862\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26885596.0000 - mae: 2010.0042 - val_loss: 1518558.6250 - val_mae: 979.6673\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26832080.0000 - mae: 2008.9762 - val_loss: 1516998.0000 - val_mae: 979.1092\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 26799440.0000 - mae: 2007.3990 - val_loss: 1515343.0000 - val_mae: 978.5201\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 26759652.0000 - mae: 2006.4160 - val_loss: 1513706.5000 - val_mae: 977.9227\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 26709804.0000 - mae: 2005.0463 - val_loss: 1511966.7500 - val_mae: 977.2877\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 26687638.0000 - mae: 2004.6094 - val_loss: 1510171.2500 - val_mae: 976.6263\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26629660.0000 - mae: 2003.3438 - val_loss: 1508267.2500 - val_mae: 975.9268\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26606604.0000 - mae: 2002.5837 - val_loss: 1505998.7500 - val_mae: 975.1087\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26557308.0000 - mae: 2001.2819 - val_loss: 1504520.6250 - val_mae: 974.5594\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26526698.0000 - mae: 2000.9056 - val_loss: 1502979.6250 - val_mae: 973.9922\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 26467940.0000 - mae: 2000.6937 - val_loss: 1502134.5000 - val_mae: 973.6603\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26449180.0000 - mae: 2001.3014 - val_loss: 1501261.2500 - val_mae: 973.3236\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26400058.0000 - mae: 2001.5664 - val_loss: 1499980.2500 - val_mae: 972.8418\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 26350548.0000 - mae: 2001.5332 - val_loss: 1498673.3750 - val_mae: 972.3732\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 26339348.0000 - mae: 2002.0740 - val_loss: 1497322.6250 - val_mae: 971.8797\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 26276324.0000 - mae: 2001.6390 - val_loss: 1496645.2500 - val_mae: 971.6057\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26240402.0000 - mae: 2002.2571 - val_loss: 1496299.7500 - val_mae: 971.4362\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 26210846.0000 - mae: 2003.1746 - val_loss: 1495600.3750 - val_mae: 971.1511\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26176256.0000 - mae: 2004.8668 - val_loss: 1494456.0000 - val_mae: 970.7159\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26120764.0000 - mae: 2004.3336 - val_loss: 1492972.5000 - val_mae: 970.1855\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26087852.0000 - mae: 2004.4402 - val_loss: 1491537.6250 - val_mae: 969.6600\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26055654.0000 - mae: 2004.7155 - val_loss: 1490093.2500 - val_mae: 969.1310\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 26020980.0000 - mae: 2005.3070 - val_loss: 1489581.7500 - val_mae: 968.8914\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25967454.0000 - mae: 2006.0697 - val_loss: 1488708.7500 - val_mae: 968.5375\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 25946664.0000 - mae: 2007.0596 - val_loss: 1487532.8750 - val_mae: 968.0783\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25898454.0000 - mae: 2007.2438 - val_loss: 1486028.7500 - val_mae: 967.5253\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25848742.0000 - mae: 2007.4381 - val_loss: 1485529.7500 - val_mae: 967.2804\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 25832604.0000 - mae: 2009.5895 - val_loss: 1485197.2500 - val_mae: 967.0775\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 25785188.0000 - mae: 2010.3645 - val_loss: 1484598.7500 - val_mae: 966.8011\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25727744.0000 - mae: 2011.1602 - val_loss: 1483482.7500 - val_mae: 966.3674\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25686202.0000 - mae: 2011.3766 - val_loss: 1482846.0000 - val_mae: 966.0750\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25667712.0000 - mae: 2012.6422 - val_loss: 1481671.2500 - val_mae: 965.6041\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25602448.0000 - mae: 2012.4486 - val_loss: 1480430.0000 - val_mae: 965.1288\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25567450.0000 - mae: 2012.3997 - val_loss: 1478916.7500 - val_mae: 964.5809\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25529582.0000 - mae: 2011.3733 - val_loss: 1477303.0000 - val_mae: 964.0004\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 25493882.0000 - mae: 2011.5000 - val_loss: 1476472.7500 - val_mae: 963.6705\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25451360.0000 - mae: 2010.7914 - val_loss: 1474911.7500 - val_mae: 963.1053\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 25419034.0000 - mae: 2010.3044 - val_loss: 1473151.2500 - val_mae: 962.5205\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25395476.0000 - mae: 2010.2643 - val_loss: 1471474.6250 - val_mae: 961.9677\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25351452.0000 - mae: 2009.9773 - val_loss: 1470175.3750 - val_mae: 961.5217\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25317136.0000 - mae: 2009.7532 - val_loss: 1468960.3750 - val_mae: 961.1128\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25283616.0000 - mae: 2009.4047 - val_loss: 1467781.3750 - val_mae: 960.7078\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25249960.0000 - mae: 2008.9978 - val_loss: 1465969.6250 - val_mae: 960.1238\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25228624.0000 - mae: 2009.9758 - val_loss: 1464975.2500 - val_mae: 959.7385\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 25191922.0000 - mae: 2010.5078 - val_loss: 1463554.3750 - val_mae: 959.2560\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25140140.0000 - mae: 2010.8434 - val_loss: 1463029.7500 - val_mae: 959.0330\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 25105844.0000 - mae: 2010.9426 - val_loss: 1462226.1250 - val_mae: 958.7260\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25071182.0000 - mae: 2011.2708 - val_loss: 1461418.5000 - val_mae: 958.4050\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 25030278.0000 - mae: 2011.7272 - val_loss: 1460876.0000 - val_mae: 958.1599\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 25018576.0000 - mae: 2013.0599 - val_loss: 1459767.2500 - val_mae: 957.7292\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24969402.0000 - mae: 2014.0824 - val_loss: 1458798.7500 - val_mae: 957.3573\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24943934.0000 - mae: 2014.8235 - val_loss: 1457837.2500 - val_mae: 956.9882\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24890656.0000 - mae: 2015.1901 - val_loss: 1457189.2500 - val_mae: 956.7012\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24878098.0000 - mae: 2016.2441 - val_loss: 1456092.2500 - val_mae: 956.2686\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 24829788.0000 - mae: 2015.9834 - val_loss: 1454203.2500 - val_mae: 955.6265\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24789694.0000 - mae: 2014.8998 - val_loss: 1452735.3750 - val_mae: 955.1051\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 24745436.0000 - mae: 2014.0305 - val_loss: 1451452.0000 - val_mae: 954.6463\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24730448.0000 - mae: 2013.6121 - val_loss: 1449799.6250 - val_mae: 954.0598\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24696532.0000 - mae: 2013.6599 - val_loss: 1448163.7500 - val_mae: 953.4881\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24645200.0000 - mae: 2012.7623 - val_loss: 1446695.0000 - val_mae: 952.9906\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24622838.0000 - mae: 2012.6523 - val_loss: 1445253.8750 - val_mae: 952.4990\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24573856.0000 - mae: 2011.7269 - val_loss: 1443856.7500 - val_mae: 952.0295\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 24559484.0000 - mae: 2012.0320 - val_loss: 1442054.3750 - val_mae: 951.4284\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24514268.0000 - mae: 2011.9658 - val_loss: 1441199.7500 - val_mae: 951.1006\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24497478.0000 - mae: 2013.0299 - val_loss: 1440250.0000 - val_mae: 950.7468\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 24450716.0000 - mae: 2013.0277 - val_loss: 1439743.7500 - val_mae: 950.5237\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24422382.0000 - mae: 2013.4781 - val_loss: 1439047.0000 - val_mae: 950.2402\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 24392118.0000 - mae: 2013.7920 - val_loss: 1437955.2500 - val_mae: 949.8451\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24366294.0000 - mae: 2014.0427 - val_loss: 1436842.3750 - val_mae: 949.4403\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24345062.0000 - mae: 2014.2141 - val_loss: 1435589.6250 - val_mae: 948.9959\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24304292.0000 - mae: 2014.0111 - val_loss: 1434438.7500 - val_mae: 948.5863\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 24278044.0000 - mae: 2014.0895 - val_loss: 1433466.2500 - val_mae: 948.2272\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24246428.0000 - mae: 2014.0134 - val_loss: 1432965.3750 - val_mae: 948.0217\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24223088.0000 - mae: 2014.2738 - val_loss: 1432374.7500 - val_mae: 947.7789\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24181114.0000 - mae: 2015.0906 - val_loss: 1431839.0000 - val_mae: 947.5469\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24156740.0000 - mae: 2015.8844 - val_loss: 1430760.6250 - val_mae: 947.1525\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24129710.0000 - mae: 2016.3601 - val_loss: 1429525.0000 - val_mae: 946.7116\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 24094810.0000 - mae: 2016.6406 - val_loss: 1428171.3750 - val_mae: 946.2393\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 24051666.0000 - mae: 2016.8549 - val_loss: 1427190.6250 - val_mae: 945.8810\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24032880.0000 - mae: 2019.1149 - val_loss: 1426728.7500 - val_mae: 945.6613\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24005148.0000 - mae: 2018.4226 - val_loss: 1425516.2500 - val_mae: 945.2274\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23977900.0000 - mae: 2019.1080 - val_loss: 1424695.3750 - val_mae: 944.9131\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23949732.0000 - mae: 2019.5211 - val_loss: 1423559.8750 - val_mae: 944.5240\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 23912556.0000 - mae: 2019.1416 - val_loss: 1422371.3750 - val_mae: 944.1224\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23886164.0000 - mae: 2017.9873 - val_loss: 1420979.7500 - val_mae: 943.6660\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23864520.0000 - mae: 2017.2483 - val_loss: 1419372.7500 - val_mae: 943.1309\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23831528.0000 - mae: 2016.4086 - val_loss: 1418288.2500 - val_mae: 942.7332\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23802560.0000 - mae: 2016.4095 - val_loss: 1417497.2500 - val_mae: 942.3973\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23765504.0000 - mae: 2016.5598 - val_loss: 1416322.0000 - val_mae: 941.9420\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23730362.0000 - mae: 2016.8080 - val_loss: 1415037.0000 - val_mae: 941.4384\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 23708804.0000 - mae: 2017.5586 - val_loss: 1413914.7500 - val_mae: 940.9990\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23657790.0000 - mae: 2018.6367 - val_loss: 1413198.6250 - val_mae: 940.6989\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23628832.0000 - mae: 2019.9773 - val_loss: 1411776.2500 - val_mae: 940.1918\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23593316.0000 - mae: 2020.0452 - val_loss: 1410970.2500 - val_mae: 939.8957\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 23556712.0000 - mae: 2019.8962 - val_loss: 1410131.7500 - val_mae: 939.5688\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 23552190.0000 - mae: 2020.9346 - val_loss: 1408906.0000 - val_mae: 939.1089\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23494834.0000 - mae: 2020.7424 - val_loss: 1408317.0000 - val_mae: 938.8455\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23467932.0000 - mae: 2021.3317 - val_loss: 1407989.7500 - val_mae: 938.6395\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23428476.0000 - mae: 2022.7048 - val_loss: 1407554.3750 - val_mae: 938.4098\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23391532.0000 - mae: 2023.9469 - val_loss: 1407335.2500 - val_mae: 938.2284\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23359532.0000 - mae: 2025.4457 - val_loss: 1407221.8750 - val_mae: 938.0771\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23337076.0000 - mae: 2028.1178 - val_loss: 1407709.3750 - val_mae: 938.2808\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 23296240.0000 - mae: 2029.8809 - val_loss: 1407103.6250 - val_mae: 938.2252\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 23273470.0000 - mae: 2030.8398 - val_loss: 1406012.1250 - val_mae: 938.0129\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23234750.0000 - mae: 2030.8359 - val_loss: 1404626.3750 - val_mae: 937.6875\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23201332.0000 - mae: 2030.1478 - val_loss: 1403650.3750 - val_mae: 937.4945\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23185774.0000 - mae: 2029.4974 - val_loss: 1402363.5000 - val_mae: 937.2216\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23144160.0000 - mae: 2028.7855 - val_loss: 1401484.7500 - val_mae: 937.0746\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23121812.0000 - mae: 2028.3053 - val_loss: 1401103.5000 - val_mae: 937.0817\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23092896.0000 - mae: 2028.8357 - val_loss: 1400699.0000 - val_mae: 937.0669\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23063160.0000 - mae: 2028.9840 - val_loss: 1399896.7500 - val_mae: 936.9348\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 23030252.0000 - mae: 2028.9851 - val_loss: 1399917.2500 - val_mae: 937.0637\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 23025956.0000 - mae: 2030.3777 - val_loss: 1399469.7500 - val_mae: 937.0815\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22965482.0000 - mae: 2029.2786 - val_loss: 1399278.2500 - val_mae: 937.1590\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22963530.0000 - mae: 2030.4563 - val_loss: 1398537.7500 - val_mae: 937.0615\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22915258.0000 - mae: 2030.4449 - val_loss: 1397643.2500 - val_mae: 936.9045\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22876934.0000 - mae: 2030.2314 - val_loss: 1396648.1250 - val_mae: 936.7090\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 22839252.0000 - mae: 2029.3160 - val_loss: 1395976.7500 - val_mae: 936.6072\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22815422.0000 - mae: 2028.6481 - val_loss: 1395339.6250 - val_mae: 936.5258\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 22797122.0000 - mae: 2028.9750 - val_loss: 1395150.3750 - val_mae: 936.5812\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 22743820.0000 - mae: 2028.7986 - val_loss: 1395120.3750 - val_mae: 936.6631\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22727640.0000 - mae: 2028.2474 - val_loss: 1395196.8750 - val_mae: 936.7881\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22670938.0000 - mae: 2028.7640 - val_loss: 1395211.2500 - val_mae: 936.8776\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22644716.0000 - mae: 2029.2363 - val_loss: 1394757.0000 - val_mae: 936.8201\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22596724.0000 - mae: 2028.7426 - val_loss: 1394025.3750 - val_mae: 936.6574\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22580926.0000 - mae: 2028.5642 - val_loss: 1393506.6250 - val_mae: 936.5656\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 22522856.0000 - mae: 2027.8281 - val_loss: 1393108.6250 - val_mae: 936.4924\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22497272.0000 - mae: 2027.9137 - val_loss: 1392982.8750 - val_mae: 936.5068\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22443586.0000 - mae: 2026.7100 - val_loss: 1393337.7500 - val_mae: 936.6622\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 22409434.0000 - mae: 2025.9080 - val_loss: 1393447.7500 - val_mae: 936.7378\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 22371266.0000 - mae: 2024.5300 - val_loss: 1393846.3750 - val_mae: 936.9017\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 22336044.0000 - mae: 2023.8906 - val_loss: 1394491.3750 - val_mae: 937.1867\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 22304800.0000 - mae: 2023.4186 - val_loss: 1394624.1250 - val_mae: 937.3730\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22287156.0000 - mae: 2024.0883 - val_loss: 1394333.1250 - val_mae: 937.4258\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22235952.0000 - mae: 2023.1625 - val_loss: 1394331.7500 - val_mae: 937.5735\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 22205468.0000 - mae: 2023.2125 - val_loss: 1394268.2500 - val_mae: 937.6567\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22168284.0000 - mae: 2021.4811 - val_loss: 1393519.7500 - val_mae: 937.4689\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 22132852.0000 - mae: 2020.0808 - val_loss: 1392464.0000 - val_mae: 937.1761\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22109628.0000 - mae: 2018.0447 - val_loss: 1391131.1250 - val_mae: 936.8287\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22059496.0000 - mae: 2016.6726 - val_loss: 1389798.3750 - val_mae: 936.5154\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22027564.0000 - mae: 2015.7654 - val_loss: 1389185.2500 - val_mae: 936.5236\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 22004342.0000 - mae: 2015.7396 - val_loss: 1389310.3750 - val_mae: 936.8749\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21945460.0000 - mae: 2017.9714 - val_loss: 1389292.2500 - val_mae: 937.1959\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21918060.0000 - mae: 2020.9430 - val_loss: 1389815.2500 - val_mae: 937.7225\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 21904446.0000 - mae: 2025.0046 - val_loss: 1390174.2500 - val_mae: 938.1194\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 21860916.0000 - mae: 2025.8717 - val_loss: 1389638.6250 - val_mae: 938.1412\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 21823558.0000 - mae: 2025.8636 - val_loss: 1388855.7500 - val_mae: 937.9684\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21787898.0000 - mae: 2025.1667 - val_loss: 1388264.1250 - val_mae: 937.8582\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21782332.0000 - mae: 2025.1599 - val_loss: 1387369.3750 - val_mae: 937.6800\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 21734740.0000 - mae: 2023.8235 - val_loss: 1386564.2500 - val_mae: 937.4908\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21713250.0000 - mae: 2022.7758 - val_loss: 1385650.7500 - val_mae: 937.2484\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21677004.0000 - mae: 2020.4531 - val_loss: 1385161.5000 - val_mae: 937.1656\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 21667498.0000 - mae: 2019.9574 - val_loss: 1384855.6250 - val_mae: 937.2219\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21628986.0000 - mae: 2019.1396 - val_loss: 1384374.7500 - val_mae: 937.2255\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21611548.0000 - mae: 2018.9045 - val_loss: 1384396.7500 - val_mae: 937.4758\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21564350.0000 - mae: 2020.5922 - val_loss: 1384010.2500 - val_mae: 937.5685\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21555252.0000 - mae: 2021.9324 - val_loss: 1383157.1250 - val_mae: 937.4836\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21505324.0000 - mae: 2023.1293 - val_loss: 1382791.2500 - val_mae: 937.5065\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21471308.0000 - mae: 2023.6094 - val_loss: 1382399.7500 - val_mae: 937.4821\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21447704.0000 - mae: 2023.8649 - val_loss: 1381943.0000 - val_mae: 937.4308\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21436500.0000 - mae: 2025.3887 - val_loss: 1381788.3750 - val_mae: 937.4960\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21400720.0000 - mae: 2025.2906 - val_loss: 1381245.7500 - val_mae: 937.3820\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21359014.0000 - mae: 2024.3959 - val_loss: 1380530.7500 - val_mae: 937.2510\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21338708.0000 - mae: 2024.2506 - val_loss: 1379290.1250 - val_mae: 936.9992\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 21314852.0000 - mae: 2024.4115 - val_loss: 1378138.3750 - val_mae: 936.7200\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21273404.0000 - mae: 2023.3711 - val_loss: 1376659.6250 - val_mae: 936.2438\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 21277708.0000 - mae: 2023.1715 - val_loss: 1374833.3750 - val_mae: 935.6393\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21242662.0000 - mae: 2021.9832 - val_loss: 1374625.8750 - val_mae: 935.6899\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21206144.0000 - mae: 2021.4631 - val_loss: 1373832.2500 - val_mae: 935.4469\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21187126.0000 - mae: 2020.8958 - val_loss: 1372760.1250 - val_mae: 935.1125\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21156476.0000 - mae: 2019.0022 - val_loss: 1372085.3750 - val_mae: 934.8934\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 21128752.0000 - mae: 2018.0287 - val_loss: 1371659.7500 - val_mae: 934.8715\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21117814.0000 - mae: 2018.2629 - val_loss: 1371438.0000 - val_mae: 934.9619\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21080582.0000 - mae: 2018.7562 - val_loss: 1371030.2500 - val_mae: 934.9379\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21042236.0000 - mae: 2019.0430 - val_loss: 1371205.0000 - val_mae: 935.1251\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21013188.0000 - mae: 2019.9150 - val_loss: 1371462.0000 - val_mae: 935.3415\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20994450.0000 - mae: 2022.2410 - val_loss: 1371752.7500 - val_mae: 935.5771\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 20957308.0000 - mae: 2024.0159 - val_loss: 1371897.2500 - val_mae: 935.7666\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20942272.0000 - mae: 2026.1732 - val_loss: 1371915.0000 - val_mae: 935.8818\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20913830.0000 - mae: 2027.1973 - val_loss: 1371653.0000 - val_mae: 935.8586\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 20897050.0000 - mae: 2027.4707 - val_loss: 1371602.6250 - val_mae: 935.8826\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 20871420.0000 - mae: 2027.3047 - val_loss: 1371376.3750 - val_mae: 935.8361\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20854476.0000 - mae: 2025.7576 - val_loss: 1371266.5000 - val_mae: 935.8533\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 20831880.0000 - mae: 2025.5784 - val_loss: 1371685.7500 - val_mae: 936.1115\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Results for year =  2015\n",
      "8/8 [==============================] - 3s 115ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 187ms/step - loss: 48501908.0000 - mae: 3032.4939 - val_loss: 1930040.7500 - val_mae: 1141.5122\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48501664.0000 - mae: 3032.4819 - val_loss: 1930032.0000 - val_mae: 1141.5120\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48501440.0000 - mae: 3032.4719 - val_loss: 1930023.6250 - val_mae: 1141.5111\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48501248.0000 - mae: 3032.4631 - val_loss: 1930015.2500 - val_mae: 1141.5100\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48501124.0000 - mae: 3032.4558 - val_loss: 1930008.0000 - val_mae: 1141.5092\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 48500984.0000 - mae: 3032.4485 - val_loss: 1930001.6250 - val_mae: 1141.5085\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48500856.0000 - mae: 3032.4404 - val_loss: 1929994.7500 - val_mae: 1141.5072\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48500756.0000 - mae: 3032.4343 - val_loss: 1929988.0000 - val_mae: 1141.5056\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48500672.0000 - mae: 3032.4272 - val_loss: 1929980.0000 - val_mae: 1141.5035\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48500592.0000 - mae: 3032.4214 - val_loss: 1929970.7500 - val_mae: 1141.5010\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48500508.0000 - mae: 3032.4133 - val_loss: 1929962.0000 - val_mae: 1141.4982\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48500420.0000 - mae: 3032.4062 - val_loss: 1929951.2500 - val_mae: 1141.4949\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48500320.0000 - mae: 3032.3984 - val_loss: 1929940.0000 - val_mae: 1141.4919\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 48500232.0000 - mae: 3032.3911 - val_loss: 1929927.6250 - val_mae: 1141.4877\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 48500136.0000 - mae: 3032.3826 - val_loss: 1929915.2500 - val_mae: 1141.4835\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48500036.0000 - mae: 3032.3743 - val_loss: 1929902.3750 - val_mae: 1141.4792\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48499944.0000 - mae: 3032.3657 - val_loss: 1929888.3750 - val_mae: 1141.4744\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48499840.0000 - mae: 3032.3569 - val_loss: 1929875.7500 - val_mae: 1141.4705\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48499756.0000 - mae: 3032.3486 - val_loss: 1929862.6250 - val_mae: 1141.4664\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48499632.0000 - mae: 3032.3398 - val_loss: 1929848.7500 - val_mae: 1141.4617\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48499532.0000 - mae: 3032.3308 - val_loss: 1929832.0000 - val_mae: 1141.4556\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48499404.0000 - mae: 3032.3186 - val_loss: 1929812.6250 - val_mae: 1141.4475\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48499284.0000 - mae: 3032.3059 - val_loss: 1929794.3750 - val_mae: 1141.4402\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48499128.0000 - mae: 3032.2925 - val_loss: 1929776.6250 - val_mae: 1141.4332\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 48499012.0000 - mae: 3032.2805 - val_loss: 1929755.2500 - val_mae: 1141.4244\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48498856.0000 - mae: 3032.2659 - val_loss: 1929731.2500 - val_mae: 1141.4147\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48498672.0000 - mae: 3032.2473 - val_loss: 1929712.6250 - val_mae: 1141.4080\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48498504.0000 - mae: 3032.2344 - val_loss: 1929691.3750 - val_mae: 1141.3998\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48498304.0000 - mae: 3032.2168 - val_loss: 1929668.7500 - val_mae: 1141.3912\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48498112.0000 - mae: 3032.2000 - val_loss: 1929644.7500 - val_mae: 1141.3818\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48497896.0000 - mae: 3032.1797 - val_loss: 1929620.6250 - val_mae: 1141.3727\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48497684.0000 - mae: 3032.1631 - val_loss: 1929598.3750 - val_mae: 1141.3643\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48497456.0000 - mae: 3032.1414 - val_loss: 1929573.7500 - val_mae: 1141.3555\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 48497208.0000 - mae: 3032.1206 - val_loss: 1929546.7500 - val_mae: 1141.3450\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48496948.0000 - mae: 3032.0972 - val_loss: 1929508.7500 - val_mae: 1141.3291\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48496632.0000 - mae: 3032.0679 - val_loss: 1929470.3750 - val_mae: 1141.3135\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48496312.0000 - mae: 3032.0415 - val_loss: 1929431.0000 - val_mae: 1141.2975\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48495956.0000 - mae: 3032.0061 - val_loss: 1929392.7500 - val_mae: 1141.2826\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48495620.0000 - mae: 3031.9685 - val_loss: 1929349.0000 - val_mae: 1141.2659\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48495200.0000 - mae: 3031.9370 - val_loss: 1929300.3750 - val_mae: 1141.2460\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48494752.0000 - mae: 3031.8894 - val_loss: 1929250.0000 - val_mae: 1141.2258\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 48494240.0000 - mae: 3031.8445 - val_loss: 1929197.2500 - val_mae: 1141.2053\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48493800.0000 - mae: 3031.8013 - val_loss: 1929140.0000 - val_mae: 1141.1820\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48493296.0000 - mae: 3031.7554 - val_loss: 1929079.7500 - val_mae: 1141.1570\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48492648.0000 - mae: 3031.6895 - val_loss: 1929025.0000 - val_mae: 1141.1348\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48492064.0000 - mae: 3031.6440 - val_loss: 1928961.7500 - val_mae: 1141.1080\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48491336.0000 - mae: 3031.5791 - val_loss: 1928899.2500 - val_mae: 1141.0823\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48490816.0000 - mae: 3031.5208 - val_loss: 1928822.2500 - val_mae: 1141.0499\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48489988.0000 - mae: 3031.4446 - val_loss: 1928752.6250 - val_mae: 1141.0225\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48489224.0000 - mae: 3031.3726 - val_loss: 1928677.6250 - val_mae: 1140.9921\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48488272.0000 - mae: 3031.2944 - val_loss: 1928597.6250 - val_mae: 1140.9589\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48487284.0000 - mae: 3031.2051 - val_loss: 1928512.3750 - val_mae: 1140.9235\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48486412.0000 - mae: 3031.1165 - val_loss: 1928418.6250 - val_mae: 1140.8840\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 48485232.0000 - mae: 3031.0125 - val_loss: 1928328.3750 - val_mae: 1140.8479\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48484104.0000 - mae: 3030.9133 - val_loss: 1928234.2500 - val_mae: 1140.8098\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48482760.0000 - mae: 3030.7942 - val_loss: 1928134.3750 - val_mae: 1140.7686\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48481324.0000 - mae: 3030.6763 - val_loss: 1928019.2500 - val_mae: 1140.7209\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48479892.0000 - mae: 3030.5449 - val_loss: 1927885.7500 - val_mae: 1140.6658\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48478312.0000 - mae: 3030.3921 - val_loss: 1927761.2500 - val_mae: 1140.6154\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48476696.0000 - mae: 3030.2693 - val_loss: 1927610.0000 - val_mae: 1140.5537\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48474356.0000 - mae: 3030.0952 - val_loss: 1927466.0000 - val_mae: 1140.4965\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48472296.0000 - mae: 3029.9331 - val_loss: 1927303.6250 - val_mae: 1140.4313\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48470308.0000 - mae: 3029.7500 - val_loss: 1927112.7500 - val_mae: 1140.3525\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48467764.0000 - mae: 3029.5625 - val_loss: 1926920.3750 - val_mae: 1140.2740\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48465256.0000 - mae: 3029.3384 - val_loss: 1926721.0000 - val_mae: 1140.1927\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48462292.0000 - mae: 3029.1035 - val_loss: 1926502.3750 - val_mae: 1140.1016\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48459464.0000 - mae: 3028.8657 - val_loss: 1926278.2500 - val_mae: 1140.0076\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 48455652.0000 - mae: 3028.6038 - val_loss: 1926029.2500 - val_mae: 1139.9055\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 48452900.0000 - mae: 3028.3364 - val_loss: 1925770.3750 - val_mae: 1139.7997\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48448692.0000 - mae: 3028.0242 - val_loss: 1925511.2500 - val_mae: 1139.6978\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48444724.0000 - mae: 3027.6892 - val_loss: 1925223.6250 - val_mae: 1139.5857\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48440112.0000 - mae: 3027.3367 - val_loss: 1924901.6250 - val_mae: 1139.4574\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48435600.0000 - mae: 3026.9636 - val_loss: 1924539.0000 - val_mae: 1139.3119\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48431288.0000 - mae: 3026.5742 - val_loss: 1924175.6250 - val_mae: 1139.1693\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48424724.0000 - mae: 3026.1267 - val_loss: 1923831.3750 - val_mae: 1139.0409\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48417916.0000 - mae: 3025.7034 - val_loss: 1923498.0000 - val_mae: 1138.9229\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48411784.0000 - mae: 3025.2278 - val_loss: 1923090.7500 - val_mae: 1138.7644\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48404244.0000 - mae: 3024.7473 - val_loss: 1922661.3750 - val_mae: 1138.5980\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48395596.0000 - mae: 3024.1663 - val_loss: 1922212.0000 - val_mae: 1138.4280\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48387176.0000 - mae: 3023.5757 - val_loss: 1921730.2500 - val_mae: 1138.2516\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48378988.0000 - mae: 3023.0312 - val_loss: 1921220.0000 - val_mae: 1138.0623\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 48367640.0000 - mae: 3022.3071 - val_loss: 1920683.3750 - val_mae: 1137.8604\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 48356320.0000 - mae: 3021.7134 - val_loss: 1920121.2500 - val_mae: 1137.6488\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48344468.0000 - mae: 3020.8574 - val_loss: 1919541.0000 - val_mae: 1137.4401\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48332488.0000 - mae: 3020.2427 - val_loss: 1918929.7500 - val_mae: 1137.2212\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48320508.0000 - mae: 3019.3323 - val_loss: 1918316.3750 - val_mae: 1137.0028\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 48305784.0000 - mae: 3018.3645 - val_loss: 1917638.3750 - val_mae: 1136.7605\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48291304.0000 - mae: 3017.5498 - val_loss: 1916930.3750 - val_mae: 1136.5028\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48273928.0000 - mae: 3016.5510 - val_loss: 1916179.0000 - val_mae: 1136.2211\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48256660.0000 - mae: 3015.5315 - val_loss: 1915405.6250 - val_mae: 1135.9420\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48240072.0000 - mae: 3014.4653 - val_loss: 1914642.7500 - val_mae: 1135.6790\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48220672.0000 - mae: 3013.2910 - val_loss: 1913855.6250 - val_mae: 1135.4104\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48200520.0000 - mae: 3012.2051 - val_loss: 1913034.0000 - val_mae: 1135.1262\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48178676.0000 - mae: 3010.8237 - val_loss: 1912195.6250 - val_mae: 1134.8352\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 48156568.0000 - mae: 3009.4985 - val_loss: 1911338.7500 - val_mae: 1134.5463\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48132168.0000 - mae: 3008.2964 - val_loss: 1910367.2500 - val_mae: 1134.2028\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 48109140.0000 - mae: 3006.7317 - val_loss: 1909311.7500 - val_mae: 1133.8363\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 48083796.0000 - mae: 3005.0649 - val_loss: 1908231.2500 - val_mae: 1133.4565\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48051128.0000 - mae: 3003.5356 - val_loss: 1907115.7500 - val_mae: 1133.0565\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48026444.0000 - mae: 3001.8086 - val_loss: 1905940.6250 - val_mae: 1132.6335\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 47988380.0000 - mae: 3000.0308 - val_loss: 1904743.7500 - val_mae: 1132.2067\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47960992.0000 - mae: 2998.0349 - val_loss: 1903466.7500 - val_mae: 1131.7581\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47929560.0000 - mae: 2996.0547 - val_loss: 1902154.7500 - val_mae: 1131.3083\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47889660.0000 - mae: 2994.1660 - val_loss: 1900859.2500 - val_mae: 1130.8660\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47859352.0000 - mae: 2991.9370 - val_loss: 1899507.0000 - val_mae: 1130.3948\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 47818492.0000 - mae: 2989.7358 - val_loss: 1898167.0000 - val_mae: 1129.9274\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 47777256.0000 - mae: 2987.4817 - val_loss: 1896840.3750 - val_mae: 1129.4733\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 47737368.0000 - mae: 2985.1980 - val_loss: 1895475.2500 - val_mae: 1129.0015\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47693496.0000 - mae: 2982.6887 - val_loss: 1894082.0000 - val_mae: 1128.5142\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47656232.0000 - mae: 2980.2976 - val_loss: 1892566.7500 - val_mae: 1127.9852\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47610536.0000 - mae: 2977.9700 - val_loss: 1890992.7500 - val_mae: 1127.4270\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47553464.0000 - mae: 2975.4495 - val_loss: 1889382.2500 - val_mae: 1126.8599\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47513760.0000 - mae: 2973.0229 - val_loss: 1887642.3750 - val_mae: 1126.2617\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 47454848.0000 - mae: 2970.4023 - val_loss: 1885919.0000 - val_mae: 1125.6702\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47406208.0000 - mae: 2967.7725 - val_loss: 1884172.3750 - val_mae: 1125.0690\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47344116.0000 - mae: 2964.7456 - val_loss: 1882436.7500 - val_mae: 1124.4734\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47282372.0000 - mae: 2961.8774 - val_loss: 1880644.0000 - val_mae: 1123.8733\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47234136.0000 - mae: 2959.3928 - val_loss: 1878659.2500 - val_mae: 1123.1736\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47170176.0000 - mae: 2956.2852 - val_loss: 1876764.3750 - val_mae: 1122.5593\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47099264.0000 - mae: 2953.4875 - val_loss: 1874824.7500 - val_mae: 1121.9136\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47030668.0000 - mae: 2950.6851 - val_loss: 1872802.0000 - val_mae: 1121.2330\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 46973328.0000 - mae: 2947.6440 - val_loss: 1870655.2500 - val_mae: 1120.4858\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 46898848.0000 - mae: 2944.7241 - val_loss: 1868561.2500 - val_mae: 1119.7594\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 46819704.0000 - mae: 2941.7104 - val_loss: 1866449.3750 - val_mae: 1119.0051\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 46766616.0000 - mae: 2939.1399 - val_loss: 1864221.3750 - val_mae: 1118.2200\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46680408.0000 - mae: 2935.5723 - val_loss: 1862016.6250 - val_mae: 1117.4509\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46615796.0000 - mae: 2932.6750 - val_loss: 1859794.7500 - val_mae: 1116.6648\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 46544760.0000 - mae: 2929.3462 - val_loss: 1857522.3750 - val_mae: 1115.8695\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 46462476.0000 - mae: 2926.6218 - val_loss: 1855203.6250 - val_mae: 1115.0222\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 46380728.0000 - mae: 2923.2402 - val_loss: 1852847.2500 - val_mae: 1114.1584\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 46297352.0000 - mae: 2919.2534 - val_loss: 1850478.0000 - val_mae: 1113.3549\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 46233816.0000 - mae: 2915.8284 - val_loss: 1847927.7500 - val_mae: 1112.4607\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46129340.0000 - mae: 2912.1133 - val_loss: 1845514.2500 - val_mae: 1111.6233\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46025064.0000 - mae: 2908.2751 - val_loss: 1843060.3750 - val_mae: 1110.7400\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45943592.0000 - mae: 2904.1584 - val_loss: 1840395.3750 - val_mae: 1109.7976\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 45854304.0000 - mae: 2900.8586 - val_loss: 1837527.2500 - val_mae: 1108.8022\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 45770280.0000 - mae: 2896.9314 - val_loss: 1834652.2500 - val_mae: 1107.7767\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 45640412.0000 - mae: 2892.3169 - val_loss: 1831994.0000 - val_mae: 1106.8212\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 45553196.0000 - mae: 2888.0581 - val_loss: 1829212.7500 - val_mae: 1105.8318\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45445176.0000 - mae: 2884.1040 - val_loss: 1826311.6250 - val_mae: 1104.7577\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45329536.0000 - mae: 2880.1682 - val_loss: 1823466.2500 - val_mae: 1103.7216\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 45249856.0000 - mae: 2876.7400 - val_loss: 1820545.2500 - val_mae: 1102.6863\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 45123080.0000 - mae: 2871.2505 - val_loss: 1817656.6250 - val_mae: 1101.6251\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45040620.0000 - mae: 2868.1577 - val_loss: 1814555.3750 - val_mae: 1100.4899\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 44927620.0000 - mae: 2863.1309 - val_loss: 1811420.7500 - val_mae: 1099.3053\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 44810600.0000 - mae: 2858.9883 - val_loss: 1808385.3750 - val_mae: 1098.1858\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 44679468.0000 - mae: 2854.0415 - val_loss: 1805372.0000 - val_mae: 1097.0490\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 44572024.0000 - mae: 2849.2524 - val_loss: 1802289.2500 - val_mae: 1095.9102\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 44464520.0000 - mae: 2845.1226 - val_loss: 1799097.6250 - val_mae: 1094.7385\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 44335852.0000 - mae: 2841.0220 - val_loss: 1795983.2500 - val_mae: 1093.5944\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 44234560.0000 - mae: 2837.5063 - val_loss: 1792820.7500 - val_mae: 1092.4165\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 44101432.0000 - mae: 2832.8625 - val_loss: 1789682.3750 - val_mae: 1091.2494\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 43993284.0000 - mae: 2829.9744 - val_loss: 1786527.2500 - val_mae: 1090.0752\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 43847132.0000 - mae: 2826.5913 - val_loss: 1783318.2500 - val_mae: 1088.8630\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 43744180.0000 - mae: 2823.5247 - val_loss: 1779850.6250 - val_mae: 1087.5800\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 43583944.0000 - mae: 2819.5981 - val_loss: 1776394.7500 - val_mae: 1086.3038\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 43455920.0000 - mae: 2816.6177 - val_loss: 1772989.2500 - val_mae: 1085.0614\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 43332952.0000 - mae: 2813.7412 - val_loss: 1769547.6250 - val_mae: 1083.8225\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 43195780.0000 - mae: 2810.9551 - val_loss: 1766141.6250 - val_mae: 1082.5870\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 43032648.0000 - mae: 2807.2407 - val_loss: 1762794.2500 - val_mae: 1081.3453\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 42957572.0000 - mae: 2805.3762 - val_loss: 1759042.0000 - val_mae: 1079.9827\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 42788280.0000 - mae: 2802.4951 - val_loss: 1755309.0000 - val_mae: 1078.5515\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 42645788.0000 - mae: 2800.2195 - val_loss: 1751829.2500 - val_mae: 1077.1721\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 42516172.0000 - mae: 2797.1064 - val_loss: 1748448.3750 - val_mae: 1075.8405\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 42385472.0000 - mae: 2793.2766 - val_loss: 1745087.0000 - val_mae: 1074.5010\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 42270152.0000 - mae: 2791.2644 - val_loss: 1741732.3750 - val_mae: 1073.1793\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 42119892.0000 - mae: 2788.7642 - val_loss: 1738380.0000 - val_mae: 1071.8190\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 41981608.0000 - mae: 2786.3931 - val_loss: 1734972.7500 - val_mae: 1070.4475\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 41870696.0000 - mae: 2783.8374 - val_loss: 1731405.6250 - val_mae: 1069.0851\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 41734248.0000 - mae: 2782.1123 - val_loss: 1727900.3750 - val_mae: 1067.7177\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 41614108.0000 - mae: 2780.3621 - val_loss: 1724545.2500 - val_mae: 1066.3883\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 41448720.0000 - mae: 2777.2603 - val_loss: 1721422.7500 - val_mae: 1065.2021\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 41278776.0000 - mae: 2774.8208 - val_loss: 1718188.7500 - val_mae: 1063.9609\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 41198560.0000 - mae: 2773.3816 - val_loss: 1714494.3750 - val_mae: 1062.5533\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 41048004.0000 - mae: 2772.3977 - val_loss: 1711026.7500 - val_mae: 1061.2391\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 40847104.0000 - mae: 2770.1458 - val_loss: 1707684.3750 - val_mae: 1060.0291\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 40747256.0000 - mae: 2768.9980 - val_loss: 1704171.3750 - val_mae: 1058.7688\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 40575172.0000 - mae: 2767.1160 - val_loss: 1700878.0000 - val_mae: 1057.6226\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 40457600.0000 - mae: 2766.4519 - val_loss: 1697445.3750 - val_mae: 1056.4622\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 40311440.0000 - mae: 2765.4639 - val_loss: 1694087.6250 - val_mae: 1055.2488\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 40119912.0000 - mae: 2762.6941 - val_loss: 1690983.2500 - val_mae: 1054.0326\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 40027624.0000 - mae: 2761.2339 - val_loss: 1687437.3750 - val_mae: 1052.7255\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 39852216.0000 - mae: 2758.0693 - val_loss: 1684196.0000 - val_mae: 1051.5123\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39707436.0000 - mae: 2756.7319 - val_loss: 1680954.2500 - val_mae: 1050.3035\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 39586176.0000 - mae: 2755.5444 - val_loss: 1677672.3750 - val_mae: 1049.0548\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 39428600.0000 - mae: 2752.1980 - val_loss: 1674547.3750 - val_mae: 1047.8342\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 39265080.0000 - mae: 2750.1091 - val_loss: 1671139.6250 - val_mae: 1046.6000\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 39132692.0000 - mae: 2748.7280 - val_loss: 1667273.0000 - val_mae: 1045.2272\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39002128.0000 - mae: 2749.2097 - val_loss: 1663402.7500 - val_mae: 1043.8942\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 38825236.0000 - mae: 2747.7427 - val_loss: 1659939.0000 - val_mae: 1042.6360\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 38665784.0000 - mae: 2745.3040 - val_loss: 1656650.5000 - val_mae: 1041.4910\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 38522140.0000 - mae: 2742.1060 - val_loss: 1653212.6250 - val_mae: 1040.3109\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 38408888.0000 - mae: 2739.6582 - val_loss: 1649694.7500 - val_mae: 1039.1029\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 38251980.0000 - mae: 2737.4067 - val_loss: 1646165.0000 - val_mae: 1037.8627\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 38077624.0000 - mae: 2733.7434 - val_loss: 1642885.7500 - val_mae: 1036.6907\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 37978056.0000 - mae: 2731.3599 - val_loss: 1639509.6250 - val_mae: 1035.4709\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 37794524.0000 - mae: 2726.4575 - val_loss: 1636281.7500 - val_mae: 1034.3344\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 37654056.0000 - mae: 2724.0247 - val_loss: 1632602.3750 - val_mae: 1033.0602\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 37571408.0000 - mae: 2722.5957 - val_loss: 1628399.7500 - val_mae: 1031.5974\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 37405756.0000 - mae: 2721.0742 - val_loss: 1624651.3750 - val_mae: 1030.2830\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 37219780.0000 - mae: 2717.9939 - val_loss: 1621415.2500 - val_mae: 1029.1237\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 37105288.0000 - mae: 2716.2720 - val_loss: 1617977.6250 - val_mae: 1027.9021\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 36949568.0000 - mae: 2713.3564 - val_loss: 1614563.6250 - val_mae: 1026.7001\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 36782968.0000 - mae: 2711.7876 - val_loss: 1611391.3750 - val_mae: 1025.5781\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 36691448.0000 - mae: 2711.1902 - val_loss: 1608036.8750 - val_mae: 1024.3802\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 36530944.0000 - mae: 2709.6047 - val_loss: 1605154.7500 - val_mae: 1023.3593\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 36381688.0000 - mae: 2708.1902 - val_loss: 1602411.0000 - val_mae: 1022.3509\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 36274984.0000 - mae: 2705.9058 - val_loss: 1599244.6250 - val_mae: 1021.2180\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 36145776.0000 - mae: 2704.9995 - val_loss: 1595991.2500 - val_mae: 1020.0197\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 35985324.0000 - mae: 2702.2266 - val_loss: 1592978.2500 - val_mae: 1018.9430\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 35887384.0000 - mae: 2701.7378 - val_loss: 1589645.0000 - val_mae: 1017.7377\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 35700572.0000 - mae: 2698.9802 - val_loss: 1586863.0000 - val_mae: 1016.6952\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 35572200.0000 - mae: 2697.5952 - val_loss: 1583764.3750 - val_mae: 1015.5295\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 35446128.0000 - mae: 2696.7017 - val_loss: 1579991.7500 - val_mae: 1014.1777\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 35263816.0000 - mae: 2697.9146 - val_loss: 1576218.0000 - val_mae: 1012.8475\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 35172920.0000 - mae: 2699.6421 - val_loss: 1572601.2500 - val_mae: 1011.6330\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 35036680.0000 - mae: 2701.3594 - val_loss: 1569396.6250 - val_mae: 1010.5696\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 34814356.0000 - mae: 2700.0972 - val_loss: 1566656.3750 - val_mae: 1009.6442\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 34713496.0000 - mae: 2701.2800 - val_loss: 1563600.3750 - val_mae: 1008.6277\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 34570496.0000 - mae: 2702.0493 - val_loss: 1560659.0000 - val_mae: 1007.6398\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 34434616.0000 - mae: 2699.9614 - val_loss: 1558187.1250 - val_mae: 1006.7770\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 34289200.0000 - mae: 2698.8535 - val_loss: 1555138.6250 - val_mae: 1005.7455\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 34142592.0000 - mae: 2698.4441 - val_loss: 1552101.7500 - val_mae: 1004.6813\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 34021656.0000 - mae: 2697.3403 - val_loss: 1549174.8750 - val_mae: 1003.6268\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33889768.0000 - mae: 2696.2683 - val_loss: 1545789.2500 - val_mae: 1002.4077\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 33755772.0000 - mae: 2697.3074 - val_loss: 1542372.7500 - val_mae: 1001.3737\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33636268.0000 - mae: 2697.1226 - val_loss: 1538895.7500 - val_mae: 1000.3773\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33509750.0000 - mae: 2696.4490 - val_loss: 1535485.0000 - val_mae: 999.3942\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33351700.0000 - mae: 2696.5596 - val_loss: 1531940.0000 - val_mae: 998.4525\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33218240.0000 - mae: 2696.1230 - val_loss: 1528228.3750 - val_mae: 997.4650\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33112780.0000 - mae: 2697.8022 - val_loss: 1524619.3750 - val_mae: 996.4473\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 32949376.0000 - mae: 2696.2439 - val_loss: 1520834.3750 - val_mae: 995.3988\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 32787248.0000 - mae: 2696.9141 - val_loss: 1516495.1250 - val_mae: 994.2285\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32682714.0000 - mae: 2697.7114 - val_loss: 1512432.0000 - val_mae: 993.1183\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32496708.0000 - mae: 2696.2944 - val_loss: 1508860.5000 - val_mae: 992.1219\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32427178.0000 - mae: 2697.5918 - val_loss: 1505065.8750 - val_mae: 991.0800\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32271116.0000 - mae: 2696.5034 - val_loss: 1501536.7500 - val_mae: 990.1268\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32085968.0000 - mae: 2696.5469 - val_loss: 1498298.7500 - val_mae: 989.1630\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31966740.0000 - mae: 2695.1860 - val_loss: 1494948.7500 - val_mae: 988.1979\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 31896634.0000 - mae: 2697.5815 - val_loss: 1491413.1250 - val_mae: 987.2033\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 31744828.0000 - mae: 2697.7734 - val_loss: 1488598.2500 - val_mae: 986.3151\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 31628598.0000 - mae: 2694.7515 - val_loss: 1485808.6250 - val_mae: 985.4641\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31525212.0000 - mae: 2694.0469 - val_loss: 1482029.3750 - val_mae: 984.3879\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31407844.0000 - mae: 2694.2769 - val_loss: 1478702.2500 - val_mae: 983.4594\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 31322052.0000 - mae: 2695.5767 - val_loss: 1475525.0000 - val_mae: 982.4818\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31209044.0000 - mae: 2694.1084 - val_loss: 1473064.3750 - val_mae: 981.6887\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 31108672.0000 - mae: 2692.7332 - val_loss: 1470533.2500 - val_mae: 980.8105\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 31027898.0000 - mae: 2690.3394 - val_loss: 1467941.2500 - val_mae: 979.9281\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 30945100.0000 - mae: 2689.3662 - val_loss: 1464435.2500 - val_mae: 978.8890\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30813946.0000 - mae: 2687.5715 - val_loss: 1461492.3750 - val_mae: 977.9951\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 30724186.0000 - mae: 2686.4524 - val_loss: 1458146.1250 - val_mae: 976.9763\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30654196.0000 - mae: 2686.3115 - val_loss: 1454856.0000 - val_mae: 975.9786\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 30491956.0000 - mae: 2684.1934 - val_loss: 1451999.7500 - val_mae: 975.0668\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30381958.0000 - mae: 2686.0171 - val_loss: 1448035.6250 - val_mae: 973.9371\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 30296940.0000 - mae: 2687.1572 - val_loss: 1444422.6250 - val_mae: 972.8375\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30175190.0000 - mae: 2688.1233 - val_loss: 1441128.2500 - val_mae: 971.8011\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 30033590.0000 - mae: 2687.3425 - val_loss: 1438168.5000 - val_mae: 970.8414\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 29979878.0000 - mae: 2690.2883 - val_loss: 1434217.2500 - val_mae: 969.7025\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 29821004.0000 - mae: 2689.4922 - val_loss: 1431149.2500 - val_mae: 968.7360\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29708460.0000 - mae: 2689.5210 - val_loss: 1428560.3750 - val_mae: 967.8796\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 29610582.0000 - mae: 2688.4565 - val_loss: 1425843.6250 - val_mae: 967.0197\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29515216.0000 - mae: 2689.1118 - val_loss: 1422813.2500 - val_mae: 966.0457\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29409562.0000 - mae: 2688.3169 - val_loss: 1420173.7500 - val_mae: 965.1395\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29358748.0000 - mae: 2690.0266 - val_loss: 1416190.2500 - val_mae: 963.8967\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 29206714.0000 - mae: 2689.9746 - val_loss: 1413570.1250 - val_mae: 963.0179\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 29132602.0000 - mae: 2689.2002 - val_loss: 1411290.3750 - val_mae: 962.1688\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29018234.0000 - mae: 2685.4360 - val_loss: 1409256.6250 - val_mae: 961.4213\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28965718.0000 - mae: 2684.4153 - val_loss: 1406405.7500 - val_mae: 960.3704\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28822394.0000 - mae: 2682.7371 - val_loss: 1403650.7500 - val_mae: 959.3885\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 28758010.0000 - mae: 2684.3599 - val_loss: 1399574.3750 - val_mae: 958.1156\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28667452.0000 - mae: 2686.7883 - val_loss: 1396265.0000 - val_mae: 957.0334\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28547222.0000 - mae: 2686.2144 - val_loss: 1393747.2500 - val_mae: 956.1063\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28465354.0000 - mae: 2684.4702 - val_loss: 1391302.5000 - val_mae: 955.2020\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28344596.0000 - mae: 2681.9856 - val_loss: 1389138.3750 - val_mae: 954.4142\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28256822.0000 - mae: 2679.7908 - val_loss: 1386257.3750 - val_mae: 953.3904\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28170672.0000 - mae: 2680.8789 - val_loss: 1382805.6250 - val_mae: 952.1644\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28104708.0000 - mae: 2684.4282 - val_loss: 1379469.8750 - val_mae: 950.9695\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27972198.0000 - mae: 2683.7253 - val_loss: 1377190.2500 - val_mae: 950.0676\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27891868.0000 - mae: 2682.2593 - val_loss: 1374730.2500 - val_mae: 949.1185\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27824276.0000 - mae: 2682.2642 - val_loss: 1372010.6250 - val_mae: 948.0568\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27748490.0000 - mae: 2681.9507 - val_loss: 1369266.0000 - val_mae: 947.0156\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 27642912.0000 - mae: 2680.0352 - val_loss: 1366935.5000 - val_mae: 946.1198\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 27576774.0000 - mae: 2679.5510 - val_loss: 1364083.3750 - val_mae: 944.9889\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27490998.0000 - mae: 2677.8420 - val_loss: 1361530.2500 - val_mae: 943.9590\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27391444.0000 - mae: 2677.0483 - val_loss: 1358009.2500 - val_mae: 942.5949\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 27351414.0000 - mae: 2680.0796 - val_loss: 1354520.2500 - val_mae: 941.2736\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 27280794.0000 - mae: 2681.1772 - val_loss: 1351934.1250 - val_mae: 940.2026\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27138822.0000 - mae: 2678.0723 - val_loss: 1349793.7500 - val_mae: 939.2850\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27056560.0000 - mae: 2676.9761 - val_loss: 1346967.0000 - val_mae: 938.1295\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26992960.0000 - mae: 2678.0161 - val_loss: 1343497.1250 - val_mae: 936.6888\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 26890394.0000 - mae: 2677.0610 - val_loss: 1340824.7500 - val_mae: 935.5590\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26829284.0000 - mae: 2676.3293 - val_loss: 1338457.6250 - val_mae: 934.5182\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26741316.0000 - mae: 2673.0051 - val_loss: 1336128.7500 - val_mae: 933.4719\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26670604.0000 - mae: 2671.8589 - val_loss: 1333356.8750 - val_mae: 932.2996\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26583552.0000 - mae: 2671.2603 - val_loss: 1330724.7500 - val_mae: 931.1488\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26517712.0000 - mae: 2671.8567 - val_loss: 1327982.6250 - val_mae: 929.9141\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26438074.0000 - mae: 2671.3811 - val_loss: 1325569.0000 - val_mae: 928.7565\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 26360908.0000 - mae: 2669.9556 - val_loss: 1323219.7500 - val_mae: 927.6080\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26297068.0000 - mae: 2668.5012 - val_loss: 1320838.8750 - val_mae: 926.4826\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 26217324.0000 - mae: 2667.1738 - val_loss: 1318461.6250 - val_mae: 925.3557\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 26157034.0000 - mae: 2666.9329 - val_loss: 1315633.7500 - val_mae: 924.0164\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26083076.0000 - mae: 2669.1011 - val_loss: 1311915.7500 - val_mae: 922.3801\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26018074.0000 - mae: 2672.9133 - val_loss: 1309065.3750 - val_mae: 921.0189\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 25927460.0000 - mae: 2674.7087 - val_loss: 1307197.2500 - val_mae: 920.0682\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 25836316.0000 - mae: 2672.3433 - val_loss: 1305825.2500 - val_mae: 919.3175\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 25785254.0000 - mae: 2670.6411 - val_loss: 1304100.2500 - val_mae: 918.3955\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 25727836.0000 - mae: 2667.7234 - val_loss: 1302586.6250 - val_mae: 917.5404\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25658370.0000 - mae: 2665.3481 - val_loss: 1299715.2500 - val_mae: 916.1242\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25571634.0000 - mae: 2666.7476 - val_loss: 1297278.3750 - val_mae: 914.8529\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25513276.0000 - mae: 2667.2642 - val_loss: 1295172.7500 - val_mae: 913.7554\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25437814.0000 - mae: 2666.3853 - val_loss: 1293411.7500 - val_mae: 912.8246\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25435732.0000 - mae: 2669.3433 - val_loss: 1290259.1250 - val_mae: 911.2555\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 25326396.0000 - mae: 2671.0320 - val_loss: 1288090.2500 - val_mae: 910.0099\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25260576.0000 - mae: 2669.1597 - val_loss: 1286535.6250 - val_mae: 909.0309\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25177452.0000 - mae: 2664.5269 - val_loss: 1285472.8750 - val_mae: 908.2733\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25137540.0000 - mae: 2663.7781 - val_loss: 1283273.2500 - val_mae: 907.0332\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25055392.0000 - mae: 2663.3860 - val_loss: 1281333.0000 - val_mae: 905.8939\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 24972690.0000 - mae: 2660.6279 - val_loss: 1280067.3750 - val_mae: 905.0031\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24926188.0000 - mae: 2659.1099 - val_loss: 1278653.7500 - val_mae: 904.0187\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24863348.0000 - mae: 2655.6724 - val_loss: 1277516.7500 - val_mae: 903.1504\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24815652.0000 - mae: 2653.7261 - val_loss: 1275801.6250 - val_mae: 901.9525\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 24751088.0000 - mae: 2651.4675 - val_loss: 1274223.6250 - val_mae: 900.8535\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24713784.0000 - mae: 2651.2163 - val_loss: 1272114.1250 - val_mae: 899.6166\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24640524.0000 - mae: 2650.6328 - val_loss: 1270571.7500 - val_mae: 898.6504\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24583576.0000 - mae: 2649.5552 - val_loss: 1268498.7500 - val_mae: 897.3864\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24516468.0000 - mae: 2649.1050 - val_loss: 1266867.2500 - val_mae: 896.2791\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24477754.0000 - mae: 2650.3113 - val_loss: 1264956.2500 - val_mae: 894.9886\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24431326.0000 - mae: 2651.2778 - val_loss: 1263036.8750 - val_mae: 893.6840\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 24366268.0000 - mae: 2650.2834 - val_loss: 1261376.2500 - val_mae: 892.4996\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 24310196.0000 - mae: 2648.6582 - val_loss: 1259941.0000 - val_mae: 891.4476\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24258362.0000 - mae: 2646.1909 - val_loss: 1258803.0000 - val_mae: 890.5554\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 24212820.0000 - mae: 2645.3257 - val_loss: 1256997.2500 - val_mae: 889.6061\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 24153668.0000 - mae: 2644.2319 - val_loss: 1255629.6250 - val_mae: 888.9857\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24114608.0000 - mae: 2645.1606 - val_loss: 1253873.6250 - val_mae: 888.2424\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24061058.0000 - mae: 2645.7378 - val_loss: 1252478.0000 - val_mae: 887.6217\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 23997808.0000 - mae: 2644.4402 - val_loss: 1251144.7500 - val_mae: 886.9909\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 23943660.0000 - mae: 2642.4243 - val_loss: 1250095.5000 - val_mae: 886.4645\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23900156.0000 - mae: 2640.9114 - val_loss: 1249103.0000 - val_mae: 885.9609\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23870416.0000 - mae: 2639.5000 - val_loss: 1247907.6250 - val_mae: 885.3837\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23817078.0000 - mae: 2638.2090 - val_loss: 1246863.0000 - val_mae: 884.8398\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23775556.0000 - mae: 2635.7007 - val_loss: 1246212.6250 - val_mae: 884.4783\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23740042.0000 - mae: 2632.5073 - val_loss: 1245866.3750 - val_mae: 884.2181\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 23699884.0000 - mae: 2628.7070 - val_loss: 1245194.0000 - val_mae: 883.8569\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23656854.0000 - mae: 2628.4336 - val_loss: 1244094.7500 - val_mae: 883.3110\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 23594556.0000 - mae: 2627.2092 - val_loss: 1243256.3750 - val_mae: 882.8400\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 23542784.0000 - mae: 2627.5308 - val_loss: 1242073.6250 - val_mae: 882.1947\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23477480.0000 - mae: 2628.5552 - val_loss: 1240710.7500 - val_mae: 881.4874\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 23429164.0000 - mae: 2630.2910 - val_loss: 1239387.3750 - val_mae: 880.7488\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23394906.0000 - mae: 2632.9143 - val_loss: 1238681.2500 - val_mae: 880.2469\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23333692.0000 - mae: 2632.7612 - val_loss: 1238497.8750 - val_mae: 879.9606\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23277424.0000 - mae: 2630.8745 - val_loss: 1238541.1250 - val_mae: 879.7427\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 23226676.0000 - mae: 2628.9797 - val_loss: 1238441.1250 - val_mae: 879.4992\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23190310.0000 - mae: 2627.1333 - val_loss: 1238227.0000 - val_mae: 879.1715\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23152308.0000 - mae: 2626.5293 - val_loss: 1237315.1250 - val_mae: 878.4752\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23078076.0000 - mae: 2626.2639 - val_loss: 1237005.0000 - val_mae: 878.0753\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 23025936.0000 - mae: 2626.4202 - val_loss: 1236126.2500 - val_mae: 877.4352\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 22974580.0000 - mae: 2627.7886 - val_loss: 1235544.7500 - val_mae: 876.9594\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 22928144.0000 - mae: 2629.0181 - val_loss: 1235104.7500 - val_mae: 876.5345\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22887300.0000 - mae: 2628.8240 - val_loss: 1234645.1250 - val_mae: 876.0983\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 22843874.0000 - mae: 2628.2554 - val_loss: 1234414.8750 - val_mae: 875.7623\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22799130.0000 - mae: 2626.6665 - val_loss: 1234303.7500 - val_mae: 875.4767\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 22755070.0000 - mae: 2624.6587 - val_loss: 1234162.2500 - val_mae: 875.1633\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 22708422.0000 - mae: 2620.7852 - val_loss: 1233875.7500 - val_mae: 874.7878\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 22669682.0000 - mae: 2618.9224 - val_loss: 1233576.2500 - val_mae: 874.4027\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 22648578.0000 - mae: 2619.1636 - val_loss: 1232976.5000 - val_mae: 873.7616\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22570436.0000 - mae: 2618.5603 - val_loss: 1233021.7500 - val_mae: 873.4517\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 22529524.0000 - mae: 2618.0696 - val_loss: 1232668.6250 - val_mae: 872.9572\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22485424.0000 - mae: 2618.2673 - val_loss: 1232206.2500 - val_mae: 872.4164\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22450110.0000 - mae: 2618.6116 - val_loss: 1231688.7500 - val_mae: 872.0786\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 22408506.0000 - mae: 2617.1003 - val_loss: 1231609.7500 - val_mae: 872.2697\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 22388160.0000 - mae: 2617.2651 - val_loss: 1231312.0000 - val_mae: 872.6100\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22327576.0000 - mae: 2615.9751 - val_loss: 1231371.6250 - val_mae: 872.7848\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 22294396.0000 - mae: 2615.0283 - val_loss: 1230798.0000 - val_mae: 872.9067\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 22239482.0000 - mae: 2614.7339 - val_loss: 1230687.3750 - val_mae: 872.9249\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 22194666.0000 - mae: 2611.5703 - val_loss: 1230789.3750 - val_mae: 873.0812\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22146406.0000 - mae: 2608.0889 - val_loss: 1231017.2500 - val_mae: 873.3168\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 22109768.0000 - mae: 2606.3354 - val_loss: 1230753.6250 - val_mae: 873.4227\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 22075808.0000 - mae: 2605.5662 - val_loss: 1230750.7500 - val_mae: 873.6898\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 22027178.0000 - mae: 2604.3352 - val_loss: 1231002.0000 - val_mae: 873.9514\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22006742.0000 - mae: 2603.6169 - val_loss: 1231304.1250 - val_mae: 874.4268\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21943598.0000 - mae: 2602.1836 - val_loss: 1232072.2500 - val_mae: 874.9500\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 21906618.0000 - mae: 2601.9377 - val_loss: 1232418.5000 - val_mae: 875.4469\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 21858904.0000 - mae: 2601.9214 - val_loss: 1232618.2500 - val_mae: 875.7144\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21820176.0000 - mae: 2600.4302 - val_loss: 1232829.2500 - val_mae: 875.8937\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Results for year =  2016\n",
      "8/8 [==============================] - 3s 134ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 172ms/step - loss: 48139672.0000 - mae: 2990.9031 - val_loss: 2026866.7500 - val_mae: 1160.6497\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 48139352.0000 - mae: 2990.8823 - val_loss: 2026849.6250 - val_mae: 1160.6439\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48139024.0000 - mae: 2990.8672 - val_loss: 2026834.3750 - val_mae: 1160.6383\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48138668.0000 - mae: 2990.8511 - val_loss: 2026821.0000 - val_mae: 1160.6335\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48138428.0000 - mae: 2990.8384 - val_loss: 2026808.2500 - val_mae: 1160.6287\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 48138180.0000 - mae: 2990.8242 - val_loss: 2026795.6250 - val_mae: 1160.6241\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48137904.0000 - mae: 2990.8071 - val_loss: 2026783.3750 - val_mae: 1160.6194\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48137548.0000 - mae: 2990.7915 - val_loss: 2026770.2500 - val_mae: 1160.6144\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48137292.0000 - mae: 2990.7749 - val_loss: 2026755.7500 - val_mae: 1160.6088\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48136936.0000 - mae: 2990.7566 - val_loss: 2026740.6250 - val_mae: 1160.6033\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48136560.0000 - mae: 2990.7351 - val_loss: 2026725.6250 - val_mae: 1160.5974\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 48136200.0000 - mae: 2990.7146 - val_loss: 2026708.2500 - val_mae: 1160.5912\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48135756.0000 - mae: 2990.6899 - val_loss: 2026692.3750 - val_mae: 1160.5857\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48135304.0000 - mae: 2990.6675 - val_loss: 2026679.2500 - val_mae: 1160.5804\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 48134888.0000 - mae: 2990.6445 - val_loss: 2026660.0000 - val_mae: 1160.5730\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 48134312.0000 - mae: 2990.6167 - val_loss: 2026633.3750 - val_mae: 1160.5636\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 48133740.0000 - mae: 2990.5906 - val_loss: 2026603.0000 - val_mae: 1160.5530\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 48133192.0000 - mae: 2990.5586 - val_loss: 2026574.3750 - val_mae: 1160.5422\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 48132584.0000 - mae: 2990.5249 - val_loss: 2026541.6250 - val_mae: 1160.5306\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48131784.0000 - mae: 2990.4954 - val_loss: 2026511.7500 - val_mae: 1160.5205\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 48131048.0000 - mae: 2990.4546 - val_loss: 2026475.6250 - val_mae: 1160.5078\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48130148.0000 - mae: 2990.4146 - val_loss: 2026438.7500 - val_mae: 1160.4948\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48129500.0000 - mae: 2990.3770 - val_loss: 2026406.0000 - val_mae: 1160.4839\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48128600.0000 - mae: 2990.3337 - val_loss: 2026373.7500 - val_mae: 1160.4735\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48127852.0000 - mae: 2990.2922 - val_loss: 2026331.6250 - val_mae: 1160.4598\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48126864.0000 - mae: 2990.2500 - val_loss: 2026283.3750 - val_mae: 1160.4440\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48125940.0000 - mae: 2990.1946 - val_loss: 2026241.6250 - val_mae: 1160.4299\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48124872.0000 - mae: 2990.1479 - val_loss: 2026195.6250 - val_mae: 1160.4153\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 48123840.0000 - mae: 2990.0933 - val_loss: 2026152.0000 - val_mae: 1160.4019\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48122692.0000 - mae: 2990.0449 - val_loss: 2026099.2500 - val_mae: 1160.3864\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48121304.0000 - mae: 2989.9734 - val_loss: 2026043.2500 - val_mae: 1160.3699\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48120192.0000 - mae: 2989.9148 - val_loss: 2025988.3750 - val_mae: 1160.3534\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48118952.0000 - mae: 2989.8494 - val_loss: 2025933.6250 - val_mae: 1160.3370\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48117560.0000 - mae: 2989.7769 - val_loss: 2025877.2500 - val_mae: 1160.3192\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 48115896.0000 - mae: 2989.7000 - val_loss: 2025806.3750 - val_mae: 1160.2965\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48114392.0000 - mae: 2989.6243 - val_loss: 2025735.6250 - val_mae: 1160.2737\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48112596.0000 - mae: 2989.5366 - val_loss: 2025664.7500 - val_mae: 1160.2511\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48110864.0000 - mae: 2989.4470 - val_loss: 2025590.7500 - val_mae: 1160.2278\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48109300.0000 - mae: 2989.3643 - val_loss: 2025514.7500 - val_mae: 1160.2037\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48107180.0000 - mae: 2989.2734 - val_loss: 2025436.6250 - val_mae: 1160.1780\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 48105244.0000 - mae: 2989.1641 - val_loss: 2025354.2500 - val_mae: 1160.1521\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48103028.0000 - mae: 2989.0764 - val_loss: 2025262.7500 - val_mae: 1160.1244\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48100840.0000 - mae: 2988.9626 - val_loss: 2025161.0000 - val_mae: 1160.0934\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48098516.0000 - mae: 2988.8428 - val_loss: 2025059.2500 - val_mae: 1160.0624\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48095668.0000 - mae: 2988.7043 - val_loss: 2024967.3750 - val_mae: 1160.0354\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48092796.0000 - mae: 2988.5874 - val_loss: 2024870.3750 - val_mae: 1160.0055\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48089952.0000 - mae: 2988.4478 - val_loss: 2024755.6250 - val_mae: 1159.9717\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 48087456.0000 - mae: 2988.2983 - val_loss: 2024614.3750 - val_mae: 1159.9292\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48084112.0000 - mae: 2988.1396 - val_loss: 2024480.7500 - val_mae: 1159.8928\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48080688.0000 - mae: 2987.9832 - val_loss: 2024333.2500 - val_mae: 1159.8516\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 48076700.0000 - mae: 2987.8108 - val_loss: 2024171.0000 - val_mae: 1159.8082\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48072184.0000 - mae: 2987.6311 - val_loss: 2023973.2500 - val_mae: 1159.7539\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48068148.0000 - mae: 2987.4297 - val_loss: 2023742.0000 - val_mae: 1159.6904\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48062760.0000 - mae: 2987.1941 - val_loss: 2023532.7500 - val_mae: 1159.6350\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48057324.0000 - mae: 2986.9507 - val_loss: 2023317.3750 - val_mae: 1159.5793\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48051368.0000 - mae: 2986.6802 - val_loss: 2023094.3750 - val_mae: 1159.5217\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48044992.0000 - mae: 2986.4204 - val_loss: 2022852.0000 - val_mae: 1159.4581\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48037516.0000 - mae: 2986.0864 - val_loss: 2022578.3750 - val_mae: 1159.3833\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48031712.0000 - mae: 2985.8230 - val_loss: 2022291.7500 - val_mae: 1159.3074\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48024336.0000 - mae: 2985.4727 - val_loss: 2021968.7500 - val_mae: 1159.2206\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48014392.0000 - mae: 2985.0942 - val_loss: 2021637.2500 - val_mae: 1159.1323\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 48006264.0000 - mae: 2984.7378 - val_loss: 2021283.2500 - val_mae: 1159.0378\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47998260.0000 - mae: 2984.3462 - val_loss: 2020898.2500 - val_mae: 1158.9336\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47988024.0000 - mae: 2983.9448 - val_loss: 2020522.7500 - val_mae: 1158.8333\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47979028.0000 - mae: 2983.4746 - val_loss: 2020146.0000 - val_mae: 1158.7340\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 47967552.0000 - mae: 2983.0095 - val_loss: 2019760.7500 - val_mae: 1158.6323\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 47957728.0000 - mae: 2982.5308 - val_loss: 2019370.3750 - val_mae: 1158.5302\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 47943560.0000 - mae: 2982.0068 - val_loss: 2018944.0000 - val_mae: 1158.4156\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47934904.0000 - mae: 2981.4673 - val_loss: 2018448.2500 - val_mae: 1158.2836\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47919976.0000 - mae: 2980.8359 - val_loss: 2017954.6250 - val_mae: 1158.1539\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 47907156.0000 - mae: 2980.2629 - val_loss: 2017418.6250 - val_mae: 1158.0129\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47891224.0000 - mae: 2979.6428 - val_loss: 2016837.2500 - val_mae: 1157.8586\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47876748.0000 - mae: 2978.9705 - val_loss: 2016188.0000 - val_mae: 1157.6832\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 47863192.0000 - mae: 2978.2583 - val_loss: 2015500.2500 - val_mae: 1157.4973\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47843544.0000 - mae: 2977.5181 - val_loss: 2014854.2500 - val_mae: 1157.3240\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47826008.0000 - mae: 2976.8225 - val_loss: 2014224.7500 - val_mae: 1157.1580\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 47809644.0000 - mae: 2975.9792 - val_loss: 2013469.0000 - val_mae: 1156.9529\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47789784.0000 - mae: 2975.1106 - val_loss: 2012707.2500 - val_mae: 1156.7483\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47766420.0000 - mae: 2974.2339 - val_loss: 2011907.3750 - val_mae: 1156.5319\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 47745208.0000 - mae: 2973.3015 - val_loss: 2011032.3750 - val_mae: 1156.2960\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 47725312.0000 - mae: 2972.3850 - val_loss: 2010128.3750 - val_mae: 1156.0505\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47696088.0000 - mae: 2971.2563 - val_loss: 2009186.2500 - val_mae: 1155.7914\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 47665708.0000 - mae: 2970.1680 - val_loss: 2008225.2500 - val_mae: 1155.5303\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 47637744.0000 - mae: 2968.8862 - val_loss: 2007227.6250 - val_mae: 1155.2621\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47607404.0000 - mae: 2967.8999 - val_loss: 2006195.0000 - val_mae: 1154.9863\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47579448.0000 - mae: 2966.3223 - val_loss: 2005100.7500 - val_mae: 1154.6940\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47543848.0000 - mae: 2964.9290 - val_loss: 2003954.2500 - val_mae: 1154.3823\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47510136.0000 - mae: 2963.8611 - val_loss: 2002804.0000 - val_mae: 1154.0649\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47468912.0000 - mae: 2962.2134 - val_loss: 2001648.7500 - val_mae: 1153.7419\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 47427852.0000 - mae: 2960.7798 - val_loss: 2000434.3750 - val_mae: 1153.4059\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47393412.0000 - mae: 2959.0618 - val_loss: 1999152.0000 - val_mae: 1153.0549\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47348488.0000 - mae: 2957.3687 - val_loss: 1997848.3750 - val_mae: 1152.6970\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47303124.0000 - mae: 2955.6782 - val_loss: 1996496.7500 - val_mae: 1152.3209\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 47254504.0000 - mae: 2953.6912 - val_loss: 1995134.0000 - val_mae: 1151.9412\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 47207660.0000 - mae: 2951.9802 - val_loss: 1993741.3750 - val_mae: 1151.5500\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 47153868.0000 - mae: 2950.3574 - val_loss: 1992246.7500 - val_mae: 1151.1233\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 47104704.0000 - mae: 2948.3003 - val_loss: 1990655.2500 - val_mae: 1150.6703\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47053792.0000 - mae: 2946.0461 - val_loss: 1989039.2500 - val_mae: 1150.2058\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 46982604.0000 - mae: 2944.0867 - val_loss: 1987462.7500 - val_mae: 1149.7474\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 46934272.0000 - mae: 2942.2544 - val_loss: 1985736.0000 - val_mae: 1149.2468\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 46853704.0000 - mae: 2940.2192 - val_loss: 1984059.3750 - val_mae: 1148.7600\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46802564.0000 - mae: 2938.0532 - val_loss: 1982180.0000 - val_mae: 1148.2147\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 46740200.0000 - mae: 2935.9565 - val_loss: 1980248.3750 - val_mae: 1147.6541\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 46658636.0000 - mae: 2934.1382 - val_loss: 1978373.2500 - val_mae: 1147.1117\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 46602284.0000 - mae: 2931.9077 - val_loss: 1976365.2500 - val_mae: 1146.5303\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 46522112.0000 - mae: 2929.4377 - val_loss: 1974411.2500 - val_mae: 1145.9631\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 46443240.0000 - mae: 2927.4636 - val_loss: 1972499.6250 - val_mae: 1145.4059\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 46370044.0000 - mae: 2924.8596 - val_loss: 1970566.2500 - val_mae: 1144.8406\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 46288380.0000 - mae: 2922.7598 - val_loss: 1968588.0000 - val_mae: 1144.2592\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46221440.0000 - mae: 2920.1367 - val_loss: 1966426.2500 - val_mae: 1143.6200\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 46137536.0000 - mae: 2917.8286 - val_loss: 1964247.6250 - val_mae: 1142.9766\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 46032560.0000 - mae: 2915.0110 - val_loss: 1962094.2500 - val_mae: 1142.3395\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 45967784.0000 - mae: 2912.7671 - val_loss: 1959689.7500 - val_mae: 1141.6340\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 45862796.0000 - mae: 2909.6001 - val_loss: 1957350.7500 - val_mae: 1140.9501\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 45781204.0000 - mae: 2906.8647 - val_loss: 1954894.0000 - val_mae: 1140.2367\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 45673092.0000 - mae: 2903.7844 - val_loss: 1952404.7500 - val_mae: 1139.5167\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 45568832.0000 - mae: 2900.7375 - val_loss: 1949790.0000 - val_mae: 1138.7596\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 45483488.0000 - mae: 2898.0398 - val_loss: 1946968.2500 - val_mae: 1137.9377\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 45384372.0000 - mae: 2894.8594 - val_loss: 1944267.6250 - val_mae: 1137.1385\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 45261304.0000 - mae: 2891.8257 - val_loss: 1941612.7500 - val_mae: 1136.3470\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 45148808.0000 - mae: 2888.7046 - val_loss: 1938836.7500 - val_mae: 1135.5164\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 45057240.0000 - mae: 2885.3442 - val_loss: 1935844.6250 - val_mae: 1134.6195\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 44938504.0000 - mae: 2882.0286 - val_loss: 1932961.0000 - val_mae: 1133.7493\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 44809084.0000 - mae: 2878.7188 - val_loss: 1930222.0000 - val_mae: 1132.9167\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 44727444.0000 - mae: 2875.9387 - val_loss: 1927351.6250 - val_mae: 1132.0511\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 44593264.0000 - mae: 2872.0093 - val_loss: 1924599.3750 - val_mae: 1131.2185\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 44499760.0000 - mae: 2868.7532 - val_loss: 1921770.3750 - val_mae: 1130.3590\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 44393384.0000 - mae: 2865.5386 - val_loss: 1918863.6250 - val_mae: 1129.4719\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 44266260.0000 - mae: 2864.1238 - val_loss: 1915952.6250 - val_mae: 1128.5801\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 44139592.0000 - mae: 2861.7690 - val_loss: 1913010.0000 - val_mae: 1127.6843\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 44020664.0000 - mae: 2860.4028 - val_loss: 1909871.0000 - val_mae: 1126.7253\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 43933492.0000 - mae: 2859.3706 - val_loss: 1906460.7500 - val_mae: 1125.6821\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 43779744.0000 - mae: 2859.0273 - val_loss: 1903275.6250 - val_mae: 1124.7028\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 43623112.0000 - mae: 2855.9038 - val_loss: 1900175.3750 - val_mae: 1123.7478\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 43505684.0000 - mae: 2854.8208 - val_loss: 1896733.6250 - val_mae: 1122.6868\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 43386344.0000 - mae: 2853.1477 - val_loss: 1893081.7500 - val_mae: 1121.5466\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 43270772.0000 - mae: 2853.1978 - val_loss: 1889371.0000 - val_mae: 1120.3962\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 43079136.0000 - mae: 2850.6038 - val_loss: 1886062.6250 - val_mae: 1119.3647\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 42959472.0000 - mae: 2849.1445 - val_loss: 1882529.6250 - val_mae: 1118.2473\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 42809360.0000 - mae: 2848.2573 - val_loss: 1879081.7500 - val_mae: 1117.1484\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 42646360.0000 - mae: 2845.9387 - val_loss: 1875822.7500 - val_mae: 1116.1002\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 42544976.0000 - mae: 2845.1423 - val_loss: 1872324.7500 - val_mae: 1114.9777\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 42371276.0000 - mae: 2844.6255 - val_loss: 1868936.3750 - val_mae: 1113.8916\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 42267656.0000 - mae: 2844.7864 - val_loss: 1865312.7500 - val_mae: 1112.7242\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 42113848.0000 - mae: 2843.6697 - val_loss: 1861902.3750 - val_mae: 1111.6322\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 41965996.0000 - mae: 2842.5073 - val_loss: 1858638.0000 - val_mae: 1110.5823\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 41792080.0000 - mae: 2840.2515 - val_loss: 1855462.7500 - val_mae: 1109.5586\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 41661016.0000 - mae: 2839.1331 - val_loss: 1851929.3750 - val_mae: 1108.4174\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 41522168.0000 - mae: 2837.7942 - val_loss: 1848196.7500 - val_mae: 1107.1986\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 41360884.0000 - mae: 2835.5789 - val_loss: 1844553.3750 - val_mae: 1106.0029\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 41238808.0000 - mae: 2835.6179 - val_loss: 1840789.2500 - val_mae: 1104.7688\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 41074848.0000 - mae: 2833.9949 - val_loss: 1837191.0000 - val_mae: 1103.5875\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 40947924.0000 - mae: 2832.7192 - val_loss: 1833602.7500 - val_mae: 1102.4028\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 40766680.0000 - mae: 2830.8696 - val_loss: 1830101.2500 - val_mae: 1101.2526\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 40648176.0000 - mae: 2829.6799 - val_loss: 1826258.0000 - val_mae: 1099.9840\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 40448948.0000 - mae: 2827.0195 - val_loss: 1822542.7500 - val_mae: 1098.7520\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 40295152.0000 - mae: 2824.6167 - val_loss: 1818612.2500 - val_mae: 1097.4519\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 40153016.0000 - mae: 2823.8228 - val_loss: 1814557.6250 - val_mae: 1096.0964\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 39991764.0000 - mae: 2821.7036 - val_loss: 1810777.7500 - val_mae: 1094.8219\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 39796564.0000 - mae: 2818.8516 - val_loss: 1807203.2500 - val_mae: 1093.6251\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 39723788.0000 - mae: 2818.5981 - val_loss: 1803005.0000 - val_mae: 1092.2025\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 39514796.0000 - mae: 2815.0396 - val_loss: 1799185.2500 - val_mae: 1090.9000\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39348000.0000 - mae: 2812.6772 - val_loss: 1795516.3750 - val_mae: 1089.6470\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 39201244.0000 - mae: 2809.4536 - val_loss: 1792121.6250 - val_mae: 1088.4675\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 39055272.0000 - mae: 2805.7729 - val_loss: 1788737.0000 - val_mae: 1087.2869\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 38926528.0000 - mae: 2803.1741 - val_loss: 1785091.7500 - val_mae: 1086.0023\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 38757916.0000 - mae: 2799.8496 - val_loss: 1781780.7500 - val_mae: 1084.8093\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 38605012.0000 - mae: 2797.1772 - val_loss: 1778307.6250 - val_mae: 1083.5687\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 38486240.0000 - mae: 2794.0454 - val_loss: 1774717.3750 - val_mae: 1082.4775\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 38330168.0000 - mae: 2790.8560 - val_loss: 1771193.2500 - val_mae: 1081.3940\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 38194180.0000 - mae: 2788.2661 - val_loss: 1767823.6250 - val_mae: 1080.3135\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 38011172.0000 - mae: 2784.3735 - val_loss: 1764743.6250 - val_mae: 1079.3168\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 37816032.0000 - mae: 2779.3828 - val_loss: 1761491.6250 - val_mae: 1078.2644\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 37730424.0000 - mae: 2776.6255 - val_loss: 1757473.2500 - val_mae: 1077.0123\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 37564152.0000 - mae: 2774.6929 - val_loss: 1753651.0000 - val_mae: 1075.7877\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 37335840.0000 - mae: 2770.9429 - val_loss: 1750114.2500 - val_mae: 1074.6344\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 37222424.0000 - mae: 2768.2415 - val_loss: 1746348.2500 - val_mae: 1073.4250\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 37031700.0000 - mae: 2764.8770 - val_loss: 1742768.2500 - val_mae: 1072.2800\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 36908532.0000 - mae: 2763.1821 - val_loss: 1738701.6250 - val_mae: 1071.0681\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 36741508.0000 - mae: 2759.2639 - val_loss: 1734830.0000 - val_mae: 1069.8577\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 36524428.0000 - mae: 2755.9724 - val_loss: 1731233.7500 - val_mae: 1068.6696\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 36420888.0000 - mae: 2752.8499 - val_loss: 1726848.7500 - val_mae: 1067.3424\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 36228392.0000 - mae: 2749.4719 - val_loss: 1723002.3750 - val_mae: 1066.1213\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 36071896.0000 - mae: 2746.7961 - val_loss: 1719044.2500 - val_mae: 1064.8616\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 35935296.0000 - mae: 2744.5977 - val_loss: 1714848.7500 - val_mae: 1063.5465\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 35760968.0000 - mae: 2740.5586 - val_loss: 1710891.7500 - val_mae: 1062.2822\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 35581072.0000 - mae: 2737.6606 - val_loss: 1706722.3750 - val_mae: 1060.9779\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 35440120.0000 - mae: 2734.3696 - val_loss: 1702148.6250 - val_mae: 1059.5647\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 35294980.0000 - mae: 2733.1304 - val_loss: 1697450.3750 - val_mae: 1058.1118\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 35102732.0000 - mae: 2729.9492 - val_loss: 1693314.2500 - val_mae: 1056.7845\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 34932756.0000 - mae: 2726.4988 - val_loss: 1689499.3750 - val_mae: 1055.4866\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 34776800.0000 - mae: 2722.7224 - val_loss: 1685442.7500 - val_mae: 1054.1404\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 34660868.0000 - mae: 2720.6233 - val_loss: 1681251.6250 - val_mae: 1052.7594\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 34492900.0000 - mae: 2718.6560 - val_loss: 1677065.2500 - val_mae: 1051.3845\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 34303860.0000 - mae: 2715.9141 - val_loss: 1673445.6250 - val_mae: 1050.1377\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 34191892.0000 - mae: 2713.3298 - val_loss: 1669691.3750 - val_mae: 1048.7939\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 34005280.0000 - mae: 2709.4050 - val_loss: 1665967.2500 - val_mae: 1047.4904\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 33853532.0000 - mae: 2708.4751 - val_loss: 1661104.5000 - val_mae: 1045.8799\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 33775192.0000 - mae: 2708.5564 - val_loss: 1656044.3750 - val_mae: 1044.1798\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33606860.0000 - mae: 2707.7400 - val_loss: 1651833.3750 - val_mae: 1042.6924\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 33409462.0000 - mae: 2704.1294 - val_loss: 1648260.7500 - val_mae: 1041.3092\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 33288364.0000 - mae: 2701.7039 - val_loss: 1644483.1250 - val_mae: 1039.8994\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33128012.0000 - mae: 2697.6667 - val_loss: 1640680.2500 - val_mae: 1038.5425\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32962224.0000 - mae: 2694.6008 - val_loss: 1637021.7500 - val_mae: 1037.2449\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 32868716.0000 - mae: 2693.5537 - val_loss: 1632406.0000 - val_mae: 1035.6833\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32712596.0000 - mae: 2692.7441 - val_loss: 1628613.7500 - val_mae: 1034.3339\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32556922.0000 - mae: 2690.0186 - val_loss: 1625225.1250 - val_mae: 1033.1060\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32449004.0000 - mae: 2686.6523 - val_loss: 1621407.0000 - val_mae: 1031.7551\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 32319366.0000 - mae: 2685.2786 - val_loss: 1617697.3750 - val_mae: 1030.4006\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 32157702.0000 - mae: 2682.0884 - val_loss: 1614281.2500 - val_mae: 1029.1516\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 32070528.0000 - mae: 2680.3276 - val_loss: 1610044.3750 - val_mae: 1027.6526\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31880432.0000 - mae: 2676.6824 - val_loss: 1606455.7500 - val_mae: 1026.3616\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 31752326.0000 - mae: 2674.5508 - val_loss: 1602756.8750 - val_mae: 1025.0457\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 31638356.0000 - mae: 2672.0796 - val_loss: 1598430.8750 - val_mae: 1023.5629\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 31458080.0000 - mae: 2669.2551 - val_loss: 1594518.6250 - val_mae: 1022.1580\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 31370916.0000 - mae: 2667.6257 - val_loss: 1590378.2500 - val_mae: 1020.6652\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 31235542.0000 - mae: 2665.2161 - val_loss: 1586543.7500 - val_mae: 1019.2703\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 31029804.0000 - mae: 2661.4954 - val_loss: 1582927.3750 - val_mae: 1017.9277\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30921372.0000 - mae: 2660.7097 - val_loss: 1578159.7500 - val_mae: 1016.2404\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30789162.0000 - mae: 2658.5007 - val_loss: 1573741.0000 - val_mae: 1014.6129\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30658044.0000 - mae: 2655.4468 - val_loss: 1570081.1250 - val_mae: 1013.1709\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 30514780.0000 - mae: 2652.0071 - val_loss: 1566634.2500 - val_mae: 1011.8170\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 30381076.0000 - mae: 2648.1753 - val_loss: 1563312.6250 - val_mae: 1010.4713\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 30275024.0000 - mae: 2645.4761 - val_loss: 1559811.2500 - val_mae: 1009.0407\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30144308.0000 - mae: 2642.3159 - val_loss: 1555856.7500 - val_mae: 1007.5213\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 30016480.0000 - mae: 2640.9868 - val_loss: 1551990.0000 - val_mae: 1006.0052\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 29893594.0000 - mae: 2638.4927 - val_loss: 1548275.0000 - val_mae: 1004.5394\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 29774140.0000 - mae: 2637.0874 - val_loss: 1544802.0000 - val_mae: 1003.1174\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 29623926.0000 - mae: 2635.1968 - val_loss: 1541482.7500 - val_mae: 1001.7550\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29495340.0000 - mae: 2634.3303 - val_loss: 1537254.2500 - val_mae: 1000.0936\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 29398080.0000 - mae: 2634.1907 - val_loss: 1533265.2500 - val_mae: 998.4590\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 29252608.0000 - mae: 2632.3286 - val_loss: 1529781.2500 - val_mae: 996.9611\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 29106220.0000 - mae: 2631.2324 - val_loss: 1525929.5000 - val_mae: 995.4526\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 29007360.0000 - mae: 2630.9763 - val_loss: 1521812.6250 - val_mae: 993.8783\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28845772.0000 - mae: 2629.6265 - val_loss: 1518166.2500 - val_mae: 992.5209\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28779754.0000 - mae: 2629.6313 - val_loss: 1514084.2500 - val_mae: 991.0965\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28640812.0000 - mae: 2628.5522 - val_loss: 1510502.2500 - val_mae: 989.8382\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28471146.0000 - mae: 2626.7925 - val_loss: 1507046.2500 - val_mae: 988.6404\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28362720.0000 - mae: 2624.6851 - val_loss: 1503386.7500 - val_mae: 987.3434\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28301754.0000 - mae: 2625.7720 - val_loss: 1499618.6250 - val_mae: 986.0170\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28152794.0000 - mae: 2623.8098 - val_loss: 1496688.7500 - val_mae: 984.9647\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28044800.0000 - mae: 2621.8794 - val_loss: 1493872.2500 - val_mae: 983.9598\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 27947526.0000 - mae: 2619.5696 - val_loss: 1490603.0000 - val_mae: 982.8382\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 27842742.0000 - mae: 2618.2874 - val_loss: 1487694.5000 - val_mae: 981.8431\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27752948.0000 - mae: 2618.5493 - val_loss: 1484796.7500 - val_mae: 980.8397\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27654628.0000 - mae: 2616.9307 - val_loss: 1482091.5000 - val_mae: 979.9283\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27558540.0000 - mae: 2615.5015 - val_loss: 1479552.5000 - val_mae: 979.0530\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27460740.0000 - mae: 2613.5020 - val_loss: 1477198.5000 - val_mae: 978.2599\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27381850.0000 - mae: 2611.9443 - val_loss: 1474380.3750 - val_mae: 977.3010\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27269276.0000 - mae: 2609.7844 - val_loss: 1471917.8750 - val_mae: 976.4846\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 27186532.0000 - mae: 2608.5190 - val_loss: 1468823.7500 - val_mae: 975.4008\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 27115802.0000 - mae: 2607.9380 - val_loss: 1465434.2500 - val_mae: 974.1789\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26958660.0000 - mae: 2605.5327 - val_loss: 1462695.7500 - val_mae: 973.1738\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26848188.0000 - mae: 2604.6360 - val_loss: 1459011.2500 - val_mae: 971.7702\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 26765222.0000 - mae: 2604.5593 - val_loss: 1455575.6250 - val_mae: 970.3981\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26648476.0000 - mae: 2603.9255 - val_loss: 1452365.0000 - val_mae: 969.1258\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26508238.0000 - mae: 2601.4634 - val_loss: 1449438.0000 - val_mae: 967.9515\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26459820.0000 - mae: 2602.0234 - val_loss: 1445715.7500 - val_mae: 966.4123\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26304266.0000 - mae: 2599.6047 - val_loss: 1442783.7500 - val_mae: 965.2061\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26194266.0000 - mae: 2598.3984 - val_loss: 1440119.3750 - val_mae: 964.2389\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 26092052.0000 - mae: 2596.8394 - val_loss: 1437374.7500 - val_mae: 963.4180\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 26002630.0000 - mae: 2595.5112 - val_loss: 1434525.3750 - val_mae: 962.5167\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 25901028.0000 - mae: 2594.3528 - val_loss: 1432191.5000 - val_mae: 961.7979\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 25838148.0000 - mae: 2593.3491 - val_loss: 1428904.0000 - val_mae: 960.5997\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 25690876.0000 - mae: 2591.5911 - val_loss: 1426578.3750 - val_mae: 959.8332\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 25613524.0000 - mae: 2590.8567 - val_loss: 1424198.1250 - val_mae: 959.0259\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 25511580.0000 - mae: 2588.0320 - val_loss: 1421884.0000 - val_mae: 958.2316\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25444432.0000 - mae: 2587.1250 - val_loss: 1419262.1250 - val_mae: 957.3037\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 25300998.0000 - mae: 2584.1609 - val_loss: 1416842.2500 - val_mae: 956.4562\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 25237244.0000 - mae: 2583.8228 - val_loss: 1413691.7500 - val_mae: 955.2406\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25145614.0000 - mae: 2582.5754 - val_loss: 1411049.7500 - val_mae: 954.2451\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 25029302.0000 - mae: 2580.2476 - val_loss: 1408871.6250 - val_mae: 953.6436\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24941428.0000 - mae: 2578.0659 - val_loss: 1406359.2500 - val_mae: 952.8602\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 24820164.0000 - mae: 2575.9851 - val_loss: 1404343.2500 - val_mae: 952.3175\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24731100.0000 - mae: 2573.8225 - val_loss: 1402079.2500 - val_mae: 951.6167\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24647590.0000 - mae: 2572.3938 - val_loss: 1399513.5000 - val_mae: 950.7704\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 24573844.0000 - mae: 2571.8940 - val_loss: 1396904.2500 - val_mae: 949.8668\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 24445840.0000 - mae: 2569.9993 - val_loss: 1394612.6250 - val_mae: 949.2323\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24359548.0000 - mae: 2568.3716 - val_loss: 1391995.0000 - val_mae: 948.3976\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24292150.0000 - mae: 2567.5029 - val_loss: 1389629.6250 - val_mae: 947.6818\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 24209194.0000 - mae: 2565.0962 - val_loss: 1387772.2500 - val_mae: 947.1921\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24104676.0000 - mae: 2562.1499 - val_loss: 1386116.6250 - val_mae: 946.7860\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24035268.0000 - mae: 2560.4744 - val_loss: 1384260.1250 - val_mae: 946.2633\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23958806.0000 - mae: 2558.0610 - val_loss: 1382439.6250 - val_mae: 945.7617\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23850356.0000 - mae: 2554.4680 - val_loss: 1379884.7500 - val_mae: 945.1024\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 23795562.0000 - mae: 2554.1362 - val_loss: 1376791.6250 - val_mae: 944.3781\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23721420.0000 - mae: 2554.6855 - val_loss: 1374176.0000 - val_mae: 943.8057\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 23590020.0000 - mae: 2551.5593 - val_loss: 1372148.7500 - val_mae: 943.4576\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 23505942.0000 - mae: 2549.1875 - val_loss: 1370200.6250 - val_mae: 943.0716\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23427526.0000 - mae: 2547.1614 - val_loss: 1368253.6250 - val_mae: 942.7264\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 23333880.0000 - mae: 2544.0701 - val_loss: 1366551.7500 - val_mae: 942.4611\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 23269596.0000 - mae: 2541.7139 - val_loss: 1364917.3750 - val_mae: 942.2301\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23178986.0000 - mae: 2538.0352 - val_loss: 1363162.6250 - val_mae: 941.9901\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 23106856.0000 - mae: 2535.9434 - val_loss: 1361125.3750 - val_mae: 941.5886\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23014176.0000 - mae: 2533.1382 - val_loss: 1359072.2500 - val_mae: 941.1758\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 22941296.0000 - mae: 2531.4167 - val_loss: 1356970.2500 - val_mae: 940.7383\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 22850728.0000 - mae: 2529.3313 - val_loss: 1355040.3750 - val_mae: 940.3690\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22764402.0000 - mae: 2527.5464 - val_loss: 1353231.3750 - val_mae: 940.0187\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22689628.0000 - mae: 2525.7542 - val_loss: 1351300.6250 - val_mae: 939.5924\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22609976.0000 - mae: 2523.7158 - val_loss: 1349482.2500 - val_mae: 939.1978\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22539642.0000 - mae: 2521.7290 - val_loss: 1347522.6250 - val_mae: 938.7260\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 22467366.0000 - mae: 2520.8804 - val_loss: 1345378.2500 - val_mae: 938.0848\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 22398772.0000 - mae: 2520.1399 - val_loss: 1343473.6250 - val_mae: 937.5543\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22303894.0000 - mae: 2518.4871 - val_loss: 1341959.2500 - val_mae: 937.1846\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 22222820.0000 - mae: 2515.7473 - val_loss: 1340583.6250 - val_mae: 936.9261\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 22169972.0000 - mae: 2513.7449 - val_loss: 1339085.7500 - val_mae: 936.5541\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 22100384.0000 - mae: 2511.0896 - val_loss: 1337833.8750 - val_mae: 936.3514\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 22028212.0000 - mae: 2507.8425 - val_loss: 1335992.7500 - val_mae: 935.8594\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21944600.0000 - mae: 2506.3628 - val_loss: 1334367.8750 - val_mae: 935.4973\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21882092.0000 - mae: 2504.9521 - val_loss: 1332733.7500 - val_mae: 935.1268\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21804540.0000 - mae: 2502.8203 - val_loss: 1331259.6250 - val_mae: 934.8166\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21784074.0000 - mae: 2503.4426 - val_loss: 1329368.7500 - val_mae: 934.1324\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21659080.0000 - mae: 2502.8003 - val_loss: 1327823.2500 - val_mae: 933.6449\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 21598548.0000 - mae: 2500.8354 - val_loss: 1326590.6250 - val_mae: 933.2891\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 21521348.0000 - mae: 2497.3608 - val_loss: 1325545.7500 - val_mae: 933.0831\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21484726.0000 - mae: 2496.7983 - val_loss: 1324119.8750 - val_mae: 932.5715\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21394682.0000 - mae: 2495.0867 - val_loss: 1322887.7500 - val_mae: 932.1561\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 21312348.0000 - mae: 2492.0938 - val_loss: 1321777.2500 - val_mae: 931.9208\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 21256600.0000 - mae: 2489.3708 - val_loss: 1320722.0000 - val_mae: 931.7074\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21193994.0000 - mae: 2485.9121 - val_loss: 1319736.7500 - val_mae: 931.6008\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 21137436.0000 - mae: 2482.8894 - val_loss: 1318560.3750 - val_mae: 931.3449\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 21073612.0000 - mae: 2479.8691 - val_loss: 1317512.2500 - val_mae: 931.1613\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 21028498.0000 - mae: 2478.0945 - val_loss: 1316386.2500 - val_mae: 930.7990\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 20960102.0000 - mae: 2475.9009 - val_loss: 1315348.6250 - val_mae: 930.5779\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20889690.0000 - mae: 2472.7954 - val_loss: 1314204.0000 - val_mae: 930.1880\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20820372.0000 - mae: 2470.5195 - val_loss: 1313101.0000 - val_mae: 929.9220\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20773092.0000 - mae: 2469.6323 - val_loss: 1311845.3750 - val_mae: 929.4746\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 20716910.0000 - mae: 2467.3098 - val_loss: 1310785.2500 - val_mae: 929.1238\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 20643620.0000 - mae: 2464.5083 - val_loss: 1309798.8750 - val_mae: 928.8576\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20580570.0000 - mae: 2460.5840 - val_loss: 1308862.6250 - val_mae: 928.6440\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 20518700.0000 - mae: 2457.1274 - val_loss: 1307972.8750 - val_mae: 928.4992\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 20455434.0000 - mae: 2454.2622 - val_loss: 1307044.3750 - val_mae: 928.1678\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 20383546.0000 - mae: 2452.1431 - val_loss: 1306168.0000 - val_mae: 927.9165\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20330576.0000 - mae: 2450.0740 - val_loss: 1305233.7500 - val_mae: 927.4276\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20271724.0000 - mae: 2447.8552 - val_loss: 1304454.7500 - val_mae: 927.0812\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 20194224.0000 - mae: 2444.2368 - val_loss: 1303869.1250 - val_mae: 926.9059\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 20125734.0000 - mae: 2440.3997 - val_loss: 1303309.2500 - val_mae: 926.7738\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 20068292.0000 - mae: 2437.7280 - val_loss: 1302760.6250 - val_mae: 926.6963\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 20022924.0000 - mae: 2435.1772 - val_loss: 1302155.5000 - val_mae: 926.4927\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19961878.0000 - mae: 2431.6160 - val_loss: 1301516.7500 - val_mae: 926.3195\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19904774.0000 - mae: 2428.1833 - val_loss: 1300979.6250 - val_mae: 926.2494\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 19852304.0000 - mae: 2425.4761 - val_loss: 1300479.7500 - val_mae: 926.3646\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 19801016.0000 - mae: 2422.1777 - val_loss: 1299986.7500 - val_mae: 926.3160\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 19752286.0000 - mae: 2419.2749 - val_loss: 1299464.7500 - val_mae: 926.1158\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19687308.0000 - mae: 2415.6038 - val_loss: 1298880.6250 - val_mae: 925.9049\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 19624062.0000 - mae: 2412.8640 - val_loss: 1298160.2500 - val_mae: 925.3887\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 19543286.0000 - mae: 2411.1731 - val_loss: 1297524.8750 - val_mae: 924.7637\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19477782.0000 - mae: 2410.1538 - val_loss: 1296944.5000 - val_mae: 924.9288\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 19438044.0000 - mae: 2412.5127 - val_loss: 1296603.3750 - val_mae: 925.4999\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19379474.0000 - mae: 2413.1482 - val_loss: 1296395.3750 - val_mae: 925.9303\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19306206.0000 - mae: 2410.7534 - val_loss: 1296124.7500 - val_mae: 926.1642\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19228730.0000 - mae: 2406.2219 - val_loss: 1295929.6250 - val_mae: 926.3649\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 19183052.0000 - mae: 2402.8079 - val_loss: 1295668.5000 - val_mae: 926.5697\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 19121442.0000 - mae: 2400.2808 - val_loss: 1295388.7500 - val_mae: 926.9437\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 19045472.0000 - mae: 2398.2427 - val_loss: 1295156.3750 - val_mae: 927.2899\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 18984802.0000 - mae: 2396.5767 - val_loss: 1294996.6250 - val_mae: 927.7885\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18917860.0000 - mae: 2395.9087 - val_loss: 1294924.2500 - val_mae: 928.2545\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18843452.0000 - mae: 2394.9802 - val_loss: 1294938.3750 - val_mae: 928.7903\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 18798996.0000 - mae: 2395.5579 - val_loss: 1295057.3750 - val_mae: 929.3098\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 18759052.0000 - mae: 2396.7273 - val_loss: 1295161.7500 - val_mae: 929.7217\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18685476.0000 - mae: 2393.2871 - val_loss: 1295188.1250 - val_mae: 929.9215\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 18635568.0000 - mae: 2390.3130 - val_loss: 1295221.0000 - val_mae: 930.1051\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 18576874.0000 - mae: 2385.0095 - val_loss: 1295136.5000 - val_mae: 930.2127\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18530262.0000 - mae: 2381.7617 - val_loss: 1295054.7500 - val_mae: 930.3676\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 18490566.0000 - mae: 2379.3677 - val_loss: 1295184.8750 - val_mae: 930.7798\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 18421592.0000 - mae: 2376.6934 - val_loss: 1295323.1250 - val_mae: 931.1784\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18373844.0000 - mae: 2375.1782 - val_loss: 1295590.6250 - val_mae: 931.7738\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Results for year =  2017\n",
      "8/8 [==============================] - 3s 127ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 181ms/step - loss: 48908520.0000 - mae: 3014.2063 - val_loss: 2001732.7500 - val_mae: 1158.2395\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48908384.0000 - mae: 3014.1997 - val_loss: 2001741.2500 - val_mae: 1158.2426\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 48908244.0000 - mae: 3014.1941 - val_loss: 2001748.7500 - val_mae: 1158.2452\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48908104.0000 - mae: 3014.1890 - val_loss: 2001755.6250 - val_mae: 1158.2474\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48908000.0000 - mae: 3014.1836 - val_loss: 2001763.6250 - val_mae: 1158.2502\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48907880.0000 - mae: 3014.1772 - val_loss: 2001772.2500 - val_mae: 1158.2532\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48907752.0000 - mae: 3014.1711 - val_loss: 2001779.2500 - val_mae: 1158.2556\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48907580.0000 - mae: 3014.1663 - val_loss: 2001786.0000 - val_mae: 1158.2581\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 48907460.0000 - mae: 3014.1606 - val_loss: 2001792.7500 - val_mae: 1158.2605\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 48907288.0000 - mae: 3014.1550 - val_loss: 2001798.7500 - val_mae: 1158.2629\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48907128.0000 - mae: 3014.1489 - val_loss: 2001804.2500 - val_mae: 1158.2649\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Results for year =  2018\n",
      "8/8 [==============================] - 3s 132ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 182ms/step - loss: 49107536.0000 - mae: 3021.6133 - val_loss: 1786129.3750 - val_mae: 1124.0701\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 49107184.0000 - mae: 3021.5935 - val_loss: 1786142.0000 - val_mae: 1124.0742\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 49106892.0000 - mae: 3021.5767 - val_loss: 1786157.3750 - val_mae: 1124.0790\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 49106632.0000 - mae: 3021.5608 - val_loss: 1786167.3750 - val_mae: 1124.0818\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 49106460.0000 - mae: 3021.5493 - val_loss: 1786175.6250 - val_mae: 1124.0839\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 49106252.0000 - mae: 3021.5356 - val_loss: 1786182.6250 - val_mae: 1124.0863\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 49106072.0000 - mae: 3021.5254 - val_loss: 1786187.6250 - val_mae: 1124.0881\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 49105888.0000 - mae: 3021.5173 - val_loss: 1786189.7500 - val_mae: 1124.0898\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 49105760.0000 - mae: 3021.5073 - val_loss: 1786191.2500 - val_mae: 1124.0917\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 49105620.0000 - mae: 3021.4978 - val_loss: 1786194.0000 - val_mae: 1124.0945\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 49105464.0000 - mae: 3021.4878 - val_loss: 1786197.0000 - val_mae: 1124.0978\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Results for year =  2019\n",
      "8/8 [==============================] - 3s 123ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 2s 201ms/step - loss: 48674488.0000 - mae: 2990.7830 - val_loss: 1818678.0000 - val_mae: 1096.4573\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48673904.0000 - mae: 2990.7646 - val_loss: 1818678.7500 - val_mae: 1096.4600\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48673256.0000 - mae: 2990.7468 - val_loss: 1818678.6250 - val_mae: 1096.4619\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 48672648.0000 - mae: 2990.7285 - val_loss: 1818672.6250 - val_mae: 1096.4619\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48672224.0000 - mae: 2990.7114 - val_loss: 1818669.2500 - val_mae: 1096.4646\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48671700.0000 - mae: 2990.6938 - val_loss: 1818662.3750 - val_mae: 1096.4670\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48671116.0000 - mae: 2990.6743 - val_loss: 1818649.0000 - val_mae: 1096.4668\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 48670424.0000 - mae: 2990.6580 - val_loss: 1818625.6250 - val_mae: 1096.4625\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48669920.0000 - mae: 2990.6379 - val_loss: 1818610.7500 - val_mae: 1096.4617\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48669240.0000 - mae: 2990.6196 - val_loss: 1818592.0000 - val_mae: 1096.4601\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48668552.0000 - mae: 2990.6006 - val_loss: 1818566.6250 - val_mae: 1096.4562\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48667936.0000 - mae: 2990.5867 - val_loss: 1818541.3750 - val_mae: 1096.4529\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48667168.0000 - mae: 2990.5608 - val_loss: 1818519.2500 - val_mae: 1096.4512\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48666344.0000 - mae: 2990.5410 - val_loss: 1818492.3750 - val_mae: 1096.4486\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48665672.0000 - mae: 2990.5254 - val_loss: 1818458.3750 - val_mae: 1096.4449\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48664532.0000 - mae: 2990.4961 - val_loss: 1818427.2500 - val_mae: 1096.4418\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48663572.0000 - mae: 2990.4695 - val_loss: 1818389.7500 - val_mae: 1096.4363\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48662688.0000 - mae: 2990.4407 - val_loss: 1818367.2500 - val_mae: 1096.4368\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48661712.0000 - mae: 2990.4102 - val_loss: 1818345.6250 - val_mae: 1096.4377\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48660428.0000 - mae: 2990.3894 - val_loss: 1818332.7500 - val_mae: 1096.4420\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 48659368.0000 - mae: 2990.3601 - val_loss: 1818312.0000 - val_mae: 1096.4441\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48657896.0000 - mae: 2990.3220 - val_loss: 1818278.3750 - val_mae: 1096.4399\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 48656984.0000 - mae: 2990.2957 - val_loss: 1818267.6250 - val_mae: 1096.4465\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48655564.0000 - mae: 2990.2603 - val_loss: 1818256.3750 - val_mae: 1096.4531\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 48654472.0000 - mae: 2990.2280 - val_loss: 1818228.2500 - val_mae: 1096.4525\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48652840.0000 - mae: 2990.1865 - val_loss: 1818182.0000 - val_mae: 1096.4430\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48651352.0000 - mae: 2990.1401 - val_loss: 1818148.0000 - val_mae: 1096.4385\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48649636.0000 - mae: 2990.0955 - val_loss: 1818105.6250 - val_mae: 1096.4277\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48648120.0000 - mae: 2990.0566 - val_loss: 1818068.6250 - val_mae: 1096.4207\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48646196.0000 - mae: 2990.0149 - val_loss: 1818025.3750 - val_mae: 1096.4109\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48644048.0000 - mae: 2989.9399 - val_loss: 1817992.2500 - val_mae: 1096.4053\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48642300.0000 - mae: 2989.8911 - val_loss: 1817979.6250 - val_mae: 1096.4091\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48640344.0000 - mae: 2989.8291 - val_loss: 1817962.3750 - val_mae: 1096.4125\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48638088.0000 - mae: 2989.7656 - val_loss: 1817925.3750 - val_mae: 1096.4092\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48635432.0000 - mae: 2989.6929 - val_loss: 1817861.6250 - val_mae: 1096.3939\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 48632964.0000 - mae: 2989.6235 - val_loss: 1817810.0000 - val_mae: 1096.3833\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48630024.0000 - mae: 2989.5388 - val_loss: 1817762.0000 - val_mae: 1096.3734\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48627180.0000 - mae: 2989.4595 - val_loss: 1817705.6250 - val_mae: 1096.3600\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48624556.0000 - mae: 2989.3630 - val_loss: 1817659.3750 - val_mae: 1096.3519\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48621064.0000 - mae: 2989.2805 - val_loss: 1817604.0000 - val_mae: 1096.3394\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48617904.0000 - mae: 2989.1702 - val_loss: 1817551.0000 - val_mae: 1096.3271\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48614092.0000 - mae: 2989.0923 - val_loss: 1817501.6250 - val_mae: 1096.3190\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48610508.0000 - mae: 2988.9690 - val_loss: 1817436.7500 - val_mae: 1096.3059\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48606552.0000 - mae: 2988.8511 - val_loss: 1817402.7500 - val_mae: 1096.3070\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48601704.0000 - mae: 2988.7061 - val_loss: 1817388.2500 - val_mae: 1096.3180\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48596760.0000 - mae: 2988.5967 - val_loss: 1817334.3750 - val_mae: 1096.3110\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48591836.0000 - mae: 2988.4431 - val_loss: 1817279.2500 - val_mae: 1096.3042\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48587704.0000 - mae: 2988.2917 - val_loss: 1817208.3750 - val_mae: 1096.2902\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48581832.0000 - mae: 2988.1199 - val_loss: 1817156.6250 - val_mae: 1096.2856\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48575976.0000 - mae: 2987.9282 - val_loss: 1817053.2500 - val_mae: 1096.2594\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 48569096.0000 - mae: 2987.7349 - val_loss: 1816959.2500 - val_mae: 1096.2383\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48561832.0000 - mae: 2987.5356 - val_loss: 1816818.3750 - val_mae: 1096.1970\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 48555928.0000 - mae: 2987.3081 - val_loss: 1816684.7500 - val_mae: 1096.1644\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48547960.0000 - mae: 2987.0464 - val_loss: 1816552.0000 - val_mae: 1096.1355\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48540088.0000 - mae: 2986.7993 - val_loss: 1816435.3750 - val_mae: 1096.1154\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48531444.0000 - mae: 2986.5527 - val_loss: 1816346.7500 - val_mae: 1096.1125\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48522136.0000 - mae: 2986.2788 - val_loss: 1816200.0000 - val_mae: 1096.0859\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48511588.0000 - mae: 2985.9517 - val_loss: 1816031.2500 - val_mae: 1096.0508\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48503272.0000 - mae: 2985.6741 - val_loss: 1815893.6250 - val_mae: 1096.0332\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48492768.0000 - mae: 2985.2964 - val_loss: 1815721.6250 - val_mae: 1096.0037\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48478456.0000 - mae: 2984.9209 - val_loss: 1815570.7500 - val_mae: 1095.9822\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 48466804.0000 - mae: 2984.5122 - val_loss: 1815410.7500 - val_mae: 1095.9559\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48455772.0000 - mae: 2984.1255 - val_loss: 1815187.3750 - val_mae: 1095.9055\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48440984.0000 - mae: 2983.6743 - val_loss: 1814950.0000 - val_mae: 1095.8502\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48428340.0000 - mae: 2983.1746 - val_loss: 1814777.6250 - val_mae: 1095.8297\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48412040.0000 - mae: 2982.6987 - val_loss: 1814615.0000 - val_mae: 1095.8164\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 48398224.0000 - mae: 2982.1951 - val_loss: 1814455.3750 - val_mae: 1095.8083\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48378860.0000 - mae: 2981.6184 - val_loss: 1814152.7500 - val_mae: 1095.7361\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48366844.0000 - mae: 2981.0847 - val_loss: 1813888.6250 - val_mae: 1095.6903\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48346272.0000 - mae: 2980.4216 - val_loss: 1813628.3750 - val_mae: 1095.6482\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48328284.0000 - mae: 2979.7676 - val_loss: 1813324.3750 - val_mae: 1095.5856\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48306836.0000 - mae: 2979.1489 - val_loss: 1813006.6250 - val_mae: 1095.5208\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48287032.0000 - mae: 2978.3071 - val_loss: 1812644.2500 - val_mae: 1095.4352\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 48270388.0000 - mae: 2977.6675 - val_loss: 1812277.6250 - val_mae: 1095.3514\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48243384.0000 - mae: 2976.7468 - val_loss: 1812034.0000 - val_mae: 1095.3270\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 48219780.0000 - mae: 2976.0078 - val_loss: 1811816.7500 - val_mae: 1095.3157\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48198968.0000 - mae: 2975.0923 - val_loss: 1811382.0000 - val_mae: 1095.2076\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48173116.0000 - mae: 2974.2024 - val_loss: 1810970.7500 - val_mae: 1095.1145\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48143704.0000 - mae: 2973.1372 - val_loss: 1810477.6250 - val_mae: 1094.9879\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48117360.0000 - mae: 2971.9846 - val_loss: 1810038.0000 - val_mae: 1094.8953\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48092568.0000 - mae: 2971.1438 - val_loss: 1809581.3750 - val_mae: 1094.7986\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 48057340.0000 - mae: 2969.8450 - val_loss: 1808969.6250 - val_mae: 1094.6304\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48020800.0000 - mae: 2968.7781 - val_loss: 1808322.7500 - val_mae: 1094.4476\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 47987500.0000 - mae: 2967.3762 - val_loss: 1807852.0000 - val_mae: 1094.3539\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 47951416.0000 - mae: 2966.1309 - val_loss: 1807528.0000 - val_mae: 1094.3329\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47919916.0000 - mae: 2964.7212 - val_loss: 1807228.3750 - val_mae: 1094.3254\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47880896.0000 - mae: 2963.4360 - val_loss: 1806714.3750 - val_mae: 1094.2219\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47840856.0000 - mae: 2962.0842 - val_loss: 1806108.3750 - val_mae: 1094.0790\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 47795028.0000 - mae: 2960.5615 - val_loss: 1805408.0000 - val_mae: 1093.8986\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47749920.0000 - mae: 2959.1570 - val_loss: 1804695.7500 - val_mae: 1093.7253\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47709880.0000 - mae: 2957.3938 - val_loss: 1804110.0000 - val_mae: 1093.6184\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 47662284.0000 - mae: 2956.0300 - val_loss: 1803469.2500 - val_mae: 1093.4894\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47612372.0000 - mae: 2954.3760 - val_loss: 1802763.2500 - val_mae: 1093.3307\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47561316.0000 - mae: 2952.5034 - val_loss: 1801841.2500 - val_mae: 1093.0673\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47511496.0000 - mae: 2950.6694 - val_loss: 1801040.7500 - val_mae: 1092.8616\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 47453556.0000 - mae: 2949.0083 - val_loss: 1800141.7500 - val_mae: 1092.6168\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 47401496.0000 - mae: 2946.8833 - val_loss: 1799288.0000 - val_mae: 1092.4065\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47348136.0000 - mae: 2944.7671 - val_loss: 1798458.0000 - val_mae: 1092.2118\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47271880.0000 - mae: 2942.5627 - val_loss: 1797673.0000 - val_mae: 1092.0420\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47221444.0000 - mae: 2940.5942 - val_loss: 1796935.2500 - val_mae: 1091.9038\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47136660.0000 - mae: 2938.0918 - val_loss: 1795996.0000 - val_mae: 1091.6642\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 47080884.0000 - mae: 2935.5161 - val_loss: 1795024.2500 - val_mae: 1091.4161\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 47016448.0000 - mae: 2933.0693 - val_loss: 1794071.6250 - val_mae: 1091.1897\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 46932424.0000 - mae: 2930.9167 - val_loss: 1793190.3750 - val_mae: 1090.9952\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 46872780.0000 - mae: 2928.0750 - val_loss: 1792160.7500 - val_mae: 1090.7361\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 46790248.0000 - mae: 2925.3687 - val_loss: 1791198.6250 - val_mae: 1090.5056\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 46708972.0000 - mae: 2922.8286 - val_loss: 1790397.6250 - val_mae: 1090.3425\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 46632564.0000 - mae: 2919.9307 - val_loss: 1789417.6250 - val_mae: 1090.1007\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 46548160.0000 - mae: 2917.4578 - val_loss: 1788390.0000 - val_mae: 1089.8376\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 46481692.0000 - mae: 2914.7737 - val_loss: 1787448.7500 - val_mae: 1089.6310\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 46393272.0000 - mae: 2911.9927 - val_loss: 1786474.0000 - val_mae: 1089.4050\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 46286312.0000 - mae: 2908.4719 - val_loss: 1785354.6250 - val_mae: 1089.1082\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 46219112.0000 - mae: 2906.1021 - val_loss: 1784398.7500 - val_mae: 1088.9050\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 46112120.0000 - mae: 2902.6301 - val_loss: 1783219.3750 - val_mae: 1088.5923\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 46027168.0000 - mae: 2899.5950 - val_loss: 1782232.7500 - val_mae: 1088.3719\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 45917288.0000 - mae: 2896.0386 - val_loss: 1781291.2500 - val_mae: 1088.1682\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 45809336.0000 - mae: 2892.4873 - val_loss: 1780326.0000 - val_mae: 1087.9580\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45723236.0000 - mae: 2889.2693 - val_loss: 1779092.3750 - val_mae: 1087.6323\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45619480.0000 - mae: 2886.0525 - val_loss: 1778086.2500 - val_mae: 1087.4098\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45496328.0000 - mae: 2882.1997 - val_loss: 1777029.6250 - val_mae: 1087.1581\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 45379988.0000 - mae: 2878.2488 - val_loss: 1775686.0000 - val_mae: 1086.7812\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 45285668.0000 - mae: 2874.8718 - val_loss: 1774378.6250 - val_mae: 1086.4420\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 45162400.0000 - mae: 2871.5288 - val_loss: 1773167.3750 - val_mae: 1086.1399\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 45032420.0000 - mae: 2867.5625 - val_loss: 1771739.2500 - val_mae: 1085.7380\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 44945140.0000 - mae: 2864.5747 - val_loss: 1770296.0000 - val_mae: 1085.3354\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 44807080.0000 - mae: 2861.5747 - val_loss: 1768920.7500 - val_mae: 1084.9586\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 44707912.0000 - mae: 2859.8044 - val_loss: 1767436.7500 - val_mae: 1084.5266\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 44597064.0000 - mae: 2857.1147 - val_loss: 1766035.6250 - val_mae: 1084.1254\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 44464744.0000 - mae: 2854.9412 - val_loss: 1764493.3750 - val_mae: 1083.6545\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 44336584.0000 - mae: 2851.1216 - val_loss: 1762687.2500 - val_mae: 1083.0752\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 44209368.0000 - mae: 2848.0938 - val_loss: 1761412.2500 - val_mae: 1082.7435\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 44116796.0000 - mae: 2845.7966 - val_loss: 1759962.3750 - val_mae: 1082.3475\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 43953572.0000 - mae: 2843.2729 - val_loss: 1758335.7500 - val_mae: 1081.8512\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 43798004.0000 - mae: 2839.9602 - val_loss: 1756317.0000 - val_mae: 1081.1708\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 43678456.0000 - mae: 2837.9370 - val_loss: 1754436.3750 - val_mae: 1080.5734\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 43544092.0000 - mae: 2835.1021 - val_loss: 1752534.3750 - val_mae: 1079.9713\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 43423312.0000 - mae: 2833.3450 - val_loss: 1750610.0000 - val_mae: 1079.3582\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 43230560.0000 - mae: 2830.2419 - val_loss: 1748693.7500 - val_mae: 1078.7424\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 43105276.0000 - mae: 2827.7644 - val_loss: 1747090.2500 - val_mae: 1078.2644\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 42948008.0000 - mae: 2825.5024 - val_loss: 1745263.2500 - val_mae: 1077.6826\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 42781932.0000 - mae: 2822.0994 - val_loss: 1743307.6250 - val_mae: 1077.0325\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 42671736.0000 - mae: 2819.6084 - val_loss: 1741300.0000 - val_mae: 1076.3645\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 42497716.0000 - mae: 2817.0491 - val_loss: 1739442.0000 - val_mae: 1075.7562\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 42381336.0000 - mae: 2814.5664 - val_loss: 1737410.3750 - val_mae: 1075.0668\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 42227436.0000 - mae: 2811.5896 - val_loss: 1735130.2500 - val_mae: 1074.2576\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 42066200.0000 - mae: 2807.6328 - val_loss: 1732990.6250 - val_mae: 1073.5044\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 41893288.0000 - mae: 2804.1860 - val_loss: 1730533.6250 - val_mae: 1072.6139\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 41753588.0000 - mae: 2801.4275 - val_loss: 1728512.0000 - val_mae: 1071.9116\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 41610696.0000 - mae: 2798.5269 - val_loss: 1726389.3750 - val_mae: 1071.1550\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 41439276.0000 - mae: 2793.7903 - val_loss: 1724245.7500 - val_mae: 1070.3905\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 41311992.0000 - mae: 2792.2336 - val_loss: 1722130.3750 - val_mae: 1069.6379\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 41138984.0000 - mae: 2787.8652 - val_loss: 1719994.0000 - val_mae: 1068.8713\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 41001004.0000 - mae: 2784.7437 - val_loss: 1717846.0000 - val_mae: 1068.0996\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 40809648.0000 - mae: 2780.2388 - val_loss: 1715547.7500 - val_mae: 1067.3357\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 40687752.0000 - mae: 2776.8418 - val_loss: 1712998.3750 - val_mae: 1066.4606\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 40479756.0000 - mae: 2772.5864 - val_loss: 1710142.3750 - val_mae: 1065.4349\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 40320376.0000 - mae: 2768.3921 - val_loss: 1707549.2500 - val_mae: 1064.5131\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 40170180.0000 - mae: 2764.5039 - val_loss: 1704975.6250 - val_mae: 1063.5854\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 39998004.0000 - mae: 2760.9641 - val_loss: 1702753.6250 - val_mae: 1062.8096\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39795664.0000 - mae: 2756.2708 - val_loss: 1699781.2500 - val_mae: 1061.6488\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39709008.0000 - mae: 2753.4363 - val_loss: 1696779.2500 - val_mae: 1060.4915\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39497444.0000 - mae: 2748.2927 - val_loss: 1693250.0000 - val_mae: 1059.0815\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 39325768.0000 - mae: 2743.5776 - val_loss: 1689834.3750 - val_mae: 1057.7307\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 39165840.0000 - mae: 2738.5220 - val_loss: 1686634.7500 - val_mae: 1056.4414\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 39015136.0000 - mae: 2733.8335 - val_loss: 1683220.3750 - val_mae: 1055.0404\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 38874968.0000 - mae: 2728.7666 - val_loss: 1680160.7500 - val_mae: 1053.8152\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 38702356.0000 - mae: 2724.2893 - val_loss: 1676960.2500 - val_mae: 1052.5071\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 38538200.0000 - mae: 2719.3286 - val_loss: 1673911.3750 - val_mae: 1051.2933\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 38415008.0000 - mae: 2714.6016 - val_loss: 1670563.3750 - val_mae: 1049.9318\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 38259508.0000 - mae: 2709.9839 - val_loss: 1667290.3750 - val_mae: 1048.5999\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 38120476.0000 - mae: 2705.7603 - val_loss: 1663945.2500 - val_mae: 1047.2039\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 37932504.0000 - mae: 2700.9773 - val_loss: 1660696.5000 - val_mae: 1045.8297\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 37738740.0000 - mae: 2694.8889 - val_loss: 1657542.2500 - val_mae: 1044.4906\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 37654712.0000 - mae: 2691.9048 - val_loss: 1654283.3750 - val_mae: 1043.0918\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 37485024.0000 - mae: 2687.7856 - val_loss: 1650631.2500 - val_mae: 1041.4954\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 37255824.0000 - mae: 2682.0571 - val_loss: 1647144.6250 - val_mae: 1039.9832\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 37148488.0000 - mae: 2677.6335 - val_loss: 1643687.7500 - val_mae: 1038.4786\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 36963212.0000 - mae: 2674.1199 - val_loss: 1640374.7500 - val_mae: 1037.0244\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 36843648.0000 - mae: 2672.2346 - val_loss: 1637525.3750 - val_mae: 1035.7737\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 36683492.0000 - mae: 2669.1157 - val_loss: 1634333.7500 - val_mae: 1034.3633\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 36487500.0000 - mae: 2666.0415 - val_loss: 1630604.0000 - val_mae: 1032.7009\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 36378616.0000 - mae: 2661.9814 - val_loss: 1627622.2500 - val_mae: 1031.3883\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 36191720.0000 - mae: 2659.0647 - val_loss: 1624884.2500 - val_mae: 1030.1721\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 36036784.0000 - mae: 2656.9038 - val_loss: 1621912.2500 - val_mae: 1028.8229\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 35911024.0000 - mae: 2655.6895 - val_loss: 1618730.0000 - val_mae: 1027.3723\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 35752040.0000 - mae: 2653.6177 - val_loss: 1615443.1250 - val_mae: 1025.8837\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 35576164.0000 - mae: 2651.5344 - val_loss: 1612619.3750 - val_mae: 1024.5955\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 35442648.0000 - mae: 2650.3628 - val_loss: 1609434.8750 - val_mae: 1023.0949\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 35295560.0000 - mae: 2649.2703 - val_loss: 1606630.6250 - val_mae: 1021.7488\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 35107048.0000 - mae: 2648.0559 - val_loss: 1603601.2500 - val_mae: 1020.3148\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 34942216.0000 - mae: 2645.7200 - val_loss: 1600203.7500 - val_mae: 1018.6646\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 34800292.0000 - mae: 2643.4146 - val_loss: 1596628.7500 - val_mae: 1017.0726\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 34676952.0000 - mae: 2641.1714 - val_loss: 1593289.7500 - val_mae: 1015.6674\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 34506824.0000 - mae: 2637.5552 - val_loss: 1589988.0000 - val_mae: 1014.2800\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 34325448.0000 - mae: 2633.1731 - val_loss: 1586811.7500 - val_mae: 1012.9287\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 34238788.0000 - mae: 2630.1047 - val_loss: 1582931.1250 - val_mae: 1011.1732\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 34044416.0000 - mae: 2626.5742 - val_loss: 1580059.3750 - val_mae: 1009.9885\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 33894976.0000 - mae: 2624.7278 - val_loss: 1577960.7500 - val_mae: 1009.3096\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33817600.0000 - mae: 2625.4246 - val_loss: 1575756.2500 - val_mae: 1008.5737\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 33650740.0000 - mae: 2625.1523 - val_loss: 1573172.2500 - val_mae: 1007.5353\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 33460250.0000 - mae: 2621.0942 - val_loss: 1570273.0000 - val_mae: 1006.2510\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 33351188.0000 - mae: 2620.0610 - val_loss: 1567531.7500 - val_mae: 1005.1740\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33198692.0000 - mae: 2617.9744 - val_loss: 1564823.2500 - val_mae: 1004.0973\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 33035542.0000 - mae: 2615.3167 - val_loss: 1561834.0000 - val_mae: 1002.8086\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 32947946.0000 - mae: 2613.7188 - val_loss: 1558539.0000 - val_mae: 1001.3461\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 32796086.0000 - mae: 2611.9358 - val_loss: 1555484.0000 - val_mae: 999.9684\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32657728.0000 - mae: 2609.8120 - val_loss: 1552530.7500 - val_mae: 998.6449\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 32550880.0000 - mae: 2607.5911 - val_loss: 1549478.8750 - val_mae: 997.3066\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 32442342.0000 - mae: 2607.3660 - val_loss: 1545792.2500 - val_mae: 995.5607\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 32275564.0000 - mae: 2602.7581 - val_loss: 1542875.5000 - val_mae: 994.1955\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 32194868.0000 - mae: 2601.1250 - val_loss: 1539695.3750 - val_mae: 992.7059\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 32021606.0000 - mae: 2597.0054 - val_loss: 1536710.3750 - val_mae: 991.2746\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 31908358.0000 - mae: 2595.2827 - val_loss: 1534047.6250 - val_mae: 990.0205\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 31786940.0000 - mae: 2592.5859 - val_loss: 1532507.6250 - val_mae: 989.3794\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 31622684.0000 - mae: 2592.1206 - val_loss: 1530498.7500 - val_mae: 988.5270\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 31537386.0000 - mae: 2590.3696 - val_loss: 1528805.0000 - val_mae: 987.8335\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 31417876.0000 - mae: 2589.6638 - val_loss: 1527282.6250 - val_mae: 987.1906\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 31210304.0000 - mae: 2586.3918 - val_loss: 1525330.2500 - val_mae: 986.4310\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 31110068.0000 - mae: 2585.1367 - val_loss: 1523891.7500 - val_mae: 986.0463\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 30988410.0000 - mae: 2583.5530 - val_loss: 1521908.7500 - val_mae: 985.3723\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30856394.0000 - mae: 2579.4731 - val_loss: 1519279.6250 - val_mae: 984.3047\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 30731222.0000 - mae: 2576.3179 - val_loss: 1516890.6250 - val_mae: 983.3461\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30612172.0000 - mae: 2573.5129 - val_loss: 1513927.1250 - val_mae: 982.1097\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30492570.0000 - mae: 2570.5078 - val_loss: 1511226.7500 - val_mae: 981.0303\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 30373210.0000 - mae: 2567.9526 - val_loss: 1509075.6250 - val_mae: 980.2151\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 30255984.0000 - mae: 2567.1567 - val_loss: 1506807.0000 - val_mae: 979.3011\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 30158944.0000 - mae: 2566.4902 - val_loss: 1504439.5000 - val_mae: 978.3309\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 30040828.0000 - mae: 2564.2109 - val_loss: 1502036.7500 - val_mae: 977.2980\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29895404.0000 - mae: 2562.2114 - val_loss: 1500356.3750 - val_mae: 976.6686\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29767338.0000 - mae: 2561.1226 - val_loss: 1499399.8750 - val_mae: 976.5472\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 29687856.0000 - mae: 2562.3176 - val_loss: 1497770.7500 - val_mae: 976.2490\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 29547386.0000 - mae: 2560.7063 - val_loss: 1495759.7500 - val_mae: 975.6248\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 29410420.0000 - mae: 2558.9961 - val_loss: 1493843.3750 - val_mae: 975.0262\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29324842.0000 - mae: 2558.3730 - val_loss: 1492155.2500 - val_mae: 974.6176\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 29170822.0000 - mae: 2555.8250 - val_loss: 1490780.0000 - val_mae: 974.2933\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 29119094.0000 - mae: 2556.3997 - val_loss: 1490200.2500 - val_mae: 974.4828\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 28989242.0000 - mae: 2555.3838 - val_loss: 1489550.7500 - val_mae: 974.5328\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 28837146.0000 - mae: 2553.6008 - val_loss: 1487658.7500 - val_mae: 973.7806\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28738828.0000 - mae: 2551.2720 - val_loss: 1485900.8750 - val_mae: 973.1190\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28664556.0000 - mae: 2549.6074 - val_loss: 1484484.1250 - val_mae: 972.6496\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28543988.0000 - mae: 2547.7717 - val_loss: 1482543.2500 - val_mae: 971.8781\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28447396.0000 - mae: 2545.1606 - val_loss: 1480951.6250 - val_mae: 971.3055\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 28355894.0000 - mae: 2542.5159 - val_loss: 1479951.7500 - val_mae: 971.0635\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 28254870.0000 - mae: 2541.2720 - val_loss: 1479019.0000 - val_mae: 970.7990\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28170788.0000 - mae: 2540.8376 - val_loss: 1477582.6250 - val_mae: 970.2459\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28081194.0000 - mae: 2538.6790 - val_loss: 1476096.6250 - val_mae: 969.6226\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27988330.0000 - mae: 2536.3445 - val_loss: 1473203.2500 - val_mae: 968.2148\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 27902378.0000 - mae: 2532.0698 - val_loss: 1470868.0000 - val_mae: 967.0920\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 27829386.0000 - mae: 2529.7297 - val_loss: 1469370.0000 - val_mae: 966.4697\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27723814.0000 - mae: 2526.8489 - val_loss: 1468052.7500 - val_mae: 965.9081\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27653510.0000 - mae: 2524.8220 - val_loss: 1467137.7500 - val_mae: 965.6235\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27586468.0000 - mae: 2524.2417 - val_loss: 1467212.3750 - val_mae: 965.8771\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27427072.0000 - mae: 2521.0615 - val_loss: 1465623.8750 - val_mae: 965.1913\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 27337270.0000 - mae: 2520.4036 - val_loss: 1465096.2500 - val_mae: 965.0699\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27258368.0000 - mae: 2519.5627 - val_loss: 1463634.7500 - val_mae: 964.4256\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 27133868.0000 - mae: 2517.6641 - val_loss: 1462627.0000 - val_mae: 963.9830\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27024682.0000 - mae: 2515.7563 - val_loss: 1460960.3750 - val_mae: 963.1683\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 26972800.0000 - mae: 2516.5725 - val_loss: 1461101.2500 - val_mae: 963.3179\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26834020.0000 - mae: 2515.2402 - val_loss: 1460366.3750 - val_mae: 962.9764\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26721220.0000 - mae: 2514.5684 - val_loss: 1459171.1250 - val_mae: 962.3522\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 26631740.0000 - mae: 2512.4702 - val_loss: 1457872.5000 - val_mae: 961.6400\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 26539808.0000 - mae: 2510.1860 - val_loss: 1457051.7500 - val_mae: 961.2136\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 26467612.0000 - mae: 2508.2192 - val_loss: 1455528.5000 - val_mae: 960.5199\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26392538.0000 - mae: 2505.3198 - val_loss: 1455774.7500 - val_mae: 960.7037\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26260486.0000 - mae: 2504.4478 - val_loss: 1455035.8750 - val_mae: 960.4169\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26185696.0000 - mae: 2501.9973 - val_loss: 1453260.7500 - val_mae: 959.6239\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26097352.0000 - mae: 2499.4900 - val_loss: 1452210.7500 - val_mae: 959.1674\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 26040404.0000 - mae: 2498.0249 - val_loss: 1450441.2500 - val_mae: 958.3164\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25907568.0000 - mae: 2496.0378 - val_loss: 1449462.8750 - val_mae: 957.8586\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25846788.0000 - mae: 2495.3452 - val_loss: 1449823.2500 - val_mae: 957.9948\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 25764904.0000 - mae: 2494.6572 - val_loss: 1449768.7500 - val_mae: 958.1261\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25661900.0000 - mae: 2492.7056 - val_loss: 1448609.7500 - val_mae: 957.9219\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25582890.0000 - mae: 2490.2996 - val_loss: 1448761.0000 - val_mae: 958.4130\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 25471732.0000 - mae: 2488.7869 - val_loss: 1448125.3750 - val_mae: 958.4398\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 25383818.0000 - mae: 2486.4080 - val_loss: 1448113.1250 - val_mae: 958.8065\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25316004.0000 - mae: 2485.1443 - val_loss: 1447692.1250 - val_mae: 958.9473\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25249584.0000 - mae: 2484.3230 - val_loss: 1448052.6250 - val_mae: 959.4455\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25136320.0000 - mae: 2482.1167 - val_loss: 1447764.2500 - val_mae: 959.5156\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 25064960.0000 - mae: 2480.3181 - val_loss: 1448437.3750 - val_mae: 960.0768\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25001412.0000 - mae: 2480.4358 - val_loss: 1448619.6250 - val_mae: 960.3535\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 24932260.0000 - mae: 2478.4878 - val_loss: 1448011.1250 - val_mae: 960.2394\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 24840812.0000 - mae: 2475.6626 - val_loss: 1447181.0000 - val_mae: 960.0124\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 24780036.0000 - mae: 2473.1763 - val_loss: 1446143.0000 - val_mae: 959.7277\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 24704100.0000 - mae: 2469.8560 - val_loss: 1445667.3750 - val_mae: 959.6930\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 24615210.0000 - mae: 2467.1860 - val_loss: 1446640.7500 - val_mae: 960.3879\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 24574510.0000 - mae: 2467.7251 - val_loss: 1449048.0000 - val_mae: 961.7858\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 24508682.0000 - mae: 2467.2380 - val_loss: 1450256.8750 - val_mae: 962.5491\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 24382750.0000 - mae: 2464.2446 - val_loss: 1450396.2500 - val_mae: 962.7467\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 24296178.0000 - mae: 2461.5972 - val_loss: 1450910.5000 - val_mae: 963.1481\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 24232798.0000 - mae: 2460.4609 - val_loss: 1451687.5000 - val_mae: 963.6680\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 24137618.0000 - mae: 2457.9089 - val_loss: 1451922.6250 - val_mae: 963.9160\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 24078942.0000 - mae: 2454.6995 - val_loss: 1451634.3750 - val_mae: 963.8828\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 23995976.0000 - mae: 2450.3940 - val_loss: 1452300.6250 - val_mae: 964.3073\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 23924724.0000 - mae: 2447.8074 - val_loss: 1454709.5000 - val_mae: 965.5371\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Results for year =  2020\n",
      "8/8 [==============================] - 4s 137ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 3s 208ms/step - loss: 48689696.0000 - mae: 3005.9302 - val_loss: 1799606.2500 - val_mae: 1092.4547\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 48689396.0000 - mae: 3005.9121 - val_loss: 1799617.2500 - val_mae: 1092.4669\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48689080.0000 - mae: 3005.8967 - val_loss: 1799627.2500 - val_mae: 1092.4781\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 48688800.0000 - mae: 3005.8848 - val_loss: 1799630.3750 - val_mae: 1092.4865\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 48688576.0000 - mae: 3005.8723 - val_loss: 1799633.6250 - val_mae: 1092.4941\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 48688336.0000 - mae: 3005.8599 - val_loss: 1799638.0000 - val_mae: 1092.5026\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 48688108.0000 - mae: 3005.8503 - val_loss: 1799645.3750 - val_mae: 1092.5120\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 48687848.0000 - mae: 3005.8394 - val_loss: 1799651.6250 - val_mae: 1092.5199\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48687648.0000 - mae: 3005.8274 - val_loss: 1799662.2500 - val_mae: 1092.5303\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 48687376.0000 - mae: 3005.8127 - val_loss: 1799670.2500 - val_mae: 1092.5391\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 48687128.0000 - mae: 3005.8008 - val_loss: 1799680.3750 - val_mae: 1092.5492\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Results for year =  2021\n"
     ]
    }
   ],
   "source": [
    "set_seed(1)\n",
    "model_cnn = define_cnn(n_features = 10, n_conv = 3, n_dense = 4)\n",
    "model_cnn.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
    "model_cnn.fit(X, y, epochs=50, batch_size=64, validation_split=0.2)\n",
    "cnn_results = pd.DataFrame(columns = [\"mae\", \"year\"])\n",
    "\n",
    "for test_year in range(2013, 2022):\n",
    "    # get indices for observations in the test and train sets\n",
    "    test_indices = np.where(ukraine[\"year\"] == test_year)[0]\n",
    "    train_indices = np.where(ukraine[\"year\"] != test_year)[0]\n",
    "\n",
    "    # get the train and test sets\n",
    "    X_train, y_train, X_test, y_test = X[train_indices], y[train_indices], X[test_indices], y[test_indices]\n",
    "    ukraine_stage_2, ukraine_test = extract_features_2(model_cnn, ukraine, test_year, X_train, X_test, 10)\n",
    "\n",
    "    # train first stage, neural network\n",
    "    for n_features in param_grid_cnn['n_features']:\n",
    "        for n_conv in param_grid_cnn['n_conv']:\n",
    "            for n_dense in param_grid_cnn['n_dense']:\n",
    "                # set_seed(1)\n",
    "                # model_cnn = define_cnn(n_features = 4, n_conv = n_conv, n_dense = n_dense)\n",
    "                # model_cnn.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
    "                # model_cnn.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)\n",
    "\n",
    "                # # extract features\n",
    "                # ukraine_stage_2, ukraine_test = extract_features_2(model_cnn, ukraine, test_year, X_train, X_test, n_features)\n",
    "\n",
    "                # train second stage, rf\n",
    "                train_data = ukraine_stage_2\n",
    "                test_data = ukraine_test\n",
    "                selected_columns =  [\"feature_\" + str(i) for i in range(1, n_features+1)] + log_bin_columns + ['allangle_snow_free_hq_sum']\n",
    "\n",
    "                # calculate differences\n",
    "                ukraine = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "                ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "                ukraine_sum = ukraine[['year', 'region', 'allangle_snow_free_hq_sum'] + log_bin_columns]\n",
    "                ukraine = ukraine[ukraine[\"year\"] < 2022]\n",
    "\n",
    "                full_data = pd.concat([train_data, test_data])\n",
    "                full_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "                full_data = pd.merge(full_data, ukraine_sum, on=['year', 'region'])\n",
    "                full_data_diff = full_data.groupby('region').diff()\n",
    "                full_data_diff['region'] = full_data['region']\n",
    "                full_data_diff['year'] = full_data['year']\n",
    "                full_data_diff.reset_index(drop=True, inplace=True)\n",
    "                full_data_diff.dropna(inplace=True)\n",
    "\n",
    "                train_data_diff = full_data_diff[full_data_diff[\"year\"] != test_year]\n",
    "                test_data_diff = full_data_diff[full_data_diff[\"year\"] == test_year]\n",
    "                test_data_diff.reset_index(drop=True, inplace=True)\n",
    "                train_data_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # build the model\n",
    "                # mae, _, _ = build_model(train_data_diff, test_data_diff, selected_columns, \"random_forest\", param_grid_rf, \n",
    "                #                                                                             log_transform = False, scale = False)\n",
    "\n",
    "                train_data_nn = train_data_diff.copy()\n",
    "                pred_data_nn = test_data_diff.copy()\n",
    "\n",
    "                train_data_nn = pd.get_dummies(train_data_nn, columns=[\"region\"])\n",
    "                pred_data_nn = pd.get_dummies(pred_data_nn, columns=[\"region\"])\n",
    "\n",
    "                X_train_nn = train_data_nn.drop(columns=[\"year\", \"real_gdp\"])\n",
    "                X_train_nn = X_train_nn.drop(columns=log_bin_columns)\n",
    "                y_train_nn = train_data_nn[\"real_gdp\"]\n",
    "\n",
    "                X_test_nn = pred_data_nn.drop(columns=[\"year\", \"real_gdp\"])\n",
    "                X_test_nn = X_test_nn.drop(columns=log_bin_columns)\n",
    "                y_test_nn = pred_data_nn[\"real_gdp\"]\n",
    "\n",
    "                X_train_nn = np.array(X_train_nn, dtype=np.float32)\n",
    "                X_test_nn = np.array(X_test_nn, dtype=np.float32)\n",
    "                y_train_nn = np.array(y_train_nn, dtype=np.float32)\n",
    "                y_test_nn = np.array(y_test_nn, dtype=np.float32)\n",
    "\n",
    "\n",
    "                # scale the data\n",
    "                scaler = StandardScaler()\n",
    "                X_train_nn = scaler.fit_transform(X_train_nn)\n",
    "                X_test_nn = scaler.transform(X_test_nn)\n",
    "\n",
    "                # fit the model on the X_train and y_train\n",
    "                model = Sequential()\n",
    "                # model.add(Dense(256, activation=\"relu\", input_dim=X_train_nn.shape[1]))  # First layer\n",
    "                # model.add(Dense(128, activation=\"relu\"))  # First layer\n",
    "                # model.add(Dense(64, activation=\"relu\"))  # First layer\n",
    "                model.add(Dense(32, activation=\"relu\", input_dim=X_train_nn.shape[1]))  # Fourth layer\n",
    "                model.add(Dense(16, activation=\"relu\"))  # New additional layer\n",
    "                model.add(Dense(8, activation=\"relu\"))  # New additional layer\n",
    "                model.add(Dense(1, activation = 'linear')) \n",
    "\n",
    "                model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "                early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "                model.fit(X_train_nn, y_train_nn, epochs=500, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "                y_pred = model.predict(X_test_nn).flatten()\n",
    "                mae = np.mean(np.abs(y_pred - y_test_nn))\n",
    "\n",
    "                # add the results to the dataframe\n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"mae\": mae,\n",
    "                    \"year\": test_year\n",
    "                }])\n",
    "                \n",
    "                cnn_results = pd.concat([cnn_results, new_row], ignore_index=True)\n",
    "                print(\"Results for year = \", test_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cnn results\n",
    "cnn_results.to_csv(\"cnn_results_allangle_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2635.9597"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_results[\"mae\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction data\n",
    "X_pred = np.zeros((len(ukraine_2022), 765, 1076, 1))\n",
    "for i in range(len(ukraine_2022)):\n",
    "\n",
    "    year = ukraine_2022[\"year\"][i]\n",
    "    region = ukraine_2022[\"region\"][i]\n",
    "\n",
    "    file_name = f\"{year}_{region}.h5\"\n",
    "    file_path = f\"data/annual_region_images/{file_name}\"\n",
    "\n",
    "    with h5py.File(file_path, 'r') as annual_region:\n",
    "        allangle_snow_free = annual_region[\"AllAngle_Composite_Snow_Covered\"][:]\n",
    "    \n",
    "    X_pred[i, :, :, 0] = allangle_snow_free\n",
    "\n",
    "X_pred = X_pred / maximum_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 12s 2s/step - loss: 0.1286 - mae: 0.2437 - val_loss: 0.4354 - val_mae: 0.5071\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 557ms/step - loss: 0.0435 - mae: 0.1470 - val_loss: 0.7307 - val_mae: 0.6781\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 504ms/step - loss: 0.0262 - mae: 0.1144 - val_loss: 0.7288 - val_mae: 0.6782\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 0.0224 - mae: 0.0991 - val_loss: 0.7673 - val_mae: 0.6895\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 2s 488ms/step - loss: 0.0184 - mae: 0.0910 - val_loss: 0.5222 - val_mae: 0.5698\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 0.0142 - mae: 0.0786 - val_loss: 0.2071 - val_mae: 0.3433\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 2s 503ms/step - loss: 0.0106 - mae: 0.0719 - val_loss: 0.1859 - val_mae: 0.2933\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 0.0106 - mae: 0.0719 - val_loss: 0.2099 - val_mae: 0.3119\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 0.0075 - mae: 0.0637 - val_loss: 0.2054 - val_mae: 0.2954\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 2s 472ms/step - loss: 0.0063 - mae: 0.0561 - val_loss: 0.1910 - val_mae: 0.2836\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 2s 476ms/step - loss: 0.0053 - mae: 0.0496 - val_loss: 0.1819 - val_mae: 0.2744\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 0.0049 - mae: 0.0453 - val_loss: 0.1780 - val_mae: 0.2678\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 2s 501ms/step - loss: 0.0044 - mae: 0.0444 - val_loss: 0.1699 - val_mae: 0.2545\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 0.0040 - mae: 0.0436 - val_loss: 0.1626 - val_mae: 0.2398\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 2s 471ms/step - loss: 0.0033 - mae: 0.0392 - val_loss: 0.1578 - val_mae: 0.2311\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 2s 517ms/step - loss: 0.0029 - mae: 0.0367 - val_loss: 0.1574 - val_mae: 0.2289\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.0027 - mae: 0.0346 - val_loss: 0.1580 - val_mae: 0.2277\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 2s 492ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.1545 - val_mae: 0.2214\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 2s 484ms/step - loss: 0.0025 - mae: 0.0321 - val_loss: 0.1504 - val_mae: 0.2131\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 2s 480ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.1484 - val_mae: 0.2070\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 2s 476ms/step - loss: 0.0018 - mae: 0.0276 - val_loss: 0.1477 - val_mae: 0.2044\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 2s 487ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.1473 - val_mae: 0.2027\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 2s 484ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.1471 - val_mae: 0.2012\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 0.1470 - val_mae: 0.2005\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 2s 502ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.1468 - val_mae: 0.1994\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 0.1468 - val_mae: 0.1971\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.0013 - mae: 0.0227 - val_loss: 0.1470 - val_mae: 0.1948\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 2s 490ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.1472 - val_mae: 0.1937\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 2s 486ms/step - loss: 9.8204e-04 - mae: 0.0200 - val_loss: 0.1473 - val_mae: 0.1933\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 2s 506ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 0.1475 - val_mae: 0.1918\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 9.2888e-04 - mae: 0.0195 - val_loss: 0.1478 - val_mae: 0.1908\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 9.0681e-04 - mae: 0.0191 - val_loss: 0.1481 - val_mae: 0.1906\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 9.1096e-04 - mae: 0.0193 - val_loss: 0.1481 - val_mae: 0.1904\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 8.1635e-04 - mae: 0.0182 - val_loss: 0.1480 - val_mae: 0.1897\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 2s 479ms/step - loss: 7.9357e-04 - mae: 0.0180 - val_loss: 0.1480 - val_mae: 0.1890\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 7.7440e-04 - mae: 0.0180 - val_loss: 0.1479 - val_mae: 0.1885\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 2s 488ms/step - loss: 8.2707e-04 - mae: 0.0188 - val_loss: 0.1482 - val_mae: 0.1888\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 2s 520ms/step - loss: 7.5807e-04 - mae: 0.0178 - val_loss: 0.1487 - val_mae: 0.1894\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 7.2205e-04 - mae: 0.0175 - val_loss: 0.1490 - val_mae: 0.1898\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 2s 492ms/step - loss: 6.5688e-04 - mae: 0.0164 - val_loss: 0.1498 - val_mae: 0.1910\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 7.0650e-04 - mae: 0.0172 - val_loss: 0.1508 - val_mae: 0.1928\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 2s 475ms/step - loss: 7.9250e-04 - mae: 0.0184 - val_loss: 0.1511 - val_mae: 0.1933\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 2s 523ms/step - loss: 6.7999e-04 - mae: 0.0172 - val_loss: 0.1511 - val_mae: 0.1933\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 2s 486ms/step - loss: 6.1061e-04 - mae: 0.0165 - val_loss: 0.1511 - val_mae: 0.1935\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 2s 503ms/step - loss: 6.8913e-04 - mae: 0.0174 - val_loss: 0.1514 - val_mae: 0.1941\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 5.7041e-04 - mae: 0.0160 - val_loss: 0.1517 - val_mae: 0.1946\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 5.9702e-04 - mae: 0.0166 - val_loss: 0.1517 - val_mae: 0.1947\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 2s 488ms/step - loss: 5.9444e-04 - mae: 0.0168 - val_loss: 0.1517 - val_mae: 0.1948\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 2s 505ms/step - loss: 6.0887e-04 - mae: 0.0167 - val_loss: 0.1522 - val_mae: 0.1957\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 2s 493ms/step - loss: 5.9880e-04 - mae: 0.0165 - val_loss: 0.1520 - val_mae: 0.1956\n",
      "8/8 [==============================] - 4s 130ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "ukraine = pd.read_csv(\"data/tabular_data_ukraine.csv\")\n",
    "ukraine = ukraine[ukraine[\"region\"] != \"Kyiv_Oblast_City\"]\n",
    "ukraine = ukraine[ukraine[\"year\"] < 2023]\n",
    "ukraine_sum = ukraine[['year', 'region', 'allangle_snow_free_hq_sum'] + log_bin_columns]\n",
    "set_seed(123)\n",
    "model = define_cnn(n_features = 10, n_conv = 2, n_dense = 4)\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X, y, epochs=50, batch_size=64, validation_split=0.2)\n",
    "\n",
    "ukraine_stage_2, ukraine_pred = extract_features_2(model, ukraine, 2022, X, X_pred, 10)\n",
    "selected_columns =  [\"feature_\" + str(i) for i in range(1, 11)] + log_bin_columns + ['allangle_snow_free_hq_sum']\n",
    "\n",
    "full_data = pd.concat([ukraine_stage_2, ukraine_pred])\n",
    "full_data.sort_values(by=['region', 'year'], inplace=True)\n",
    "full_data = pd.merge(full_data, ukraine_sum, on=['year', 'region'])\n",
    "full_data_diff = full_data.groupby('region').diff()\n",
    "full_data_diff['region'] = full_data['region']\n",
    "full_data_diff['year'] = full_data['year']\n",
    "full_data_diff.reset_index(drop=True, inplace=True)\n",
    "full_data_diff = full_data_diff[full_data_diff[\"year\"] != 2012]\n",
    "\n",
    "train_data_diff = full_data_diff[full_data_diff[\"year\"] != 2022]\n",
    "pred_data_diff = full_data_diff[full_data_diff[\"year\"] == 2022]\n",
    "pred_data_diff.reset_index(drop=True, inplace=True)\n",
    "train_data_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data = full_data[full_data[\"year\"] != 2022]\n",
    "pred_data = full_data[full_data[\"year\"] == 2022]\n",
    "pred_data.reset_index(drop=True, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# _, y_pred, best_params = predict_with_model(train_data_diff, pred_data_diff, selected_columns, \"random_forest\", param_grid_rf, log_transform = False, scale = False)\n",
    "\n",
    "train_data_nn = train_data_diff.copy()\n",
    "pred_data_nn = pred_data_diff.copy()\n",
    "\n",
    "train_data_nn = pd.get_dummies(train_data_nn, columns=[\"region\"])\n",
    "pred_data_nn = pd.get_dummies(pred_data_nn, columns=[\"region\"])\n",
    "\n",
    "X_train_nn = train_data_nn.drop(columns=[\"year\", \"real_gdp\"])\n",
    "X_train_nn = X_train_nn.drop(columns=log_bin_columns)\n",
    "y_train_nn = train_data_nn[\"real_gdp\"]\n",
    "\n",
    "X_test_nn = pred_data_nn.drop(columns=[\"year\", \"real_gdp\"])\n",
    "X_test_nn = X_test_nn.drop(columns=log_bin_columns)\n",
    "y_test_nn = pred_data_nn[\"real_gdp\"]\n",
    "\n",
    "X_train_nn = np.array(X_train_nn, dtype=np.float32)\n",
    "X_test_nn = np.array(X_test_nn, dtype=np.float32)\n",
    "y_train_nn = np.array(y_train_nn, dtype=np.float32)\n",
    "y_test_nn = np.array(y_test_nn, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 2s 226ms/step - loss: 44506904.0000 - mae: 2893.3250 - val_loss: 1933743.8750 - val_mae: 1146.0807\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 44506640.0000 - mae: 2893.3103 - val_loss: 1933739.3750 - val_mae: 1146.0798\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 44506456.0000 - mae: 2893.2986 - val_loss: 1933734.7500 - val_mae: 1146.0801\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 44506204.0000 - mae: 2893.2876 - val_loss: 1933731.5000 - val_mae: 1146.0819\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 44505928.0000 - mae: 2893.2805 - val_loss: 1933727.1250 - val_mae: 1146.0852\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 44505612.0000 - mae: 2893.2671 - val_loss: 1933728.3750 - val_mae: 1146.0906\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 44505320.0000 - mae: 2893.2559 - val_loss: 1933735.8750 - val_mae: 1146.0990\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 44504980.0000 - mae: 2893.2432 - val_loss: 1933743.6250 - val_mae: 1146.1069\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 44504688.0000 - mae: 2893.2334 - val_loss: 1933749.1250 - val_mae: 1146.1143\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 44504344.0000 - mae: 2893.2195 - val_loss: 1933759.1250 - val_mae: 1146.1237\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 44504000.0000 - mae: 2893.2075 - val_loss: 1933776.1250 - val_mae: 1146.1345\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 44503632.0000 - mae: 2893.1926 - val_loss: 1933787.2500 - val_mae: 1146.1434\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 44503244.0000 - mae: 2893.1809 - val_loss: 1933793.3750 - val_mae: 1146.1517\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 44502876.0000 - mae: 2893.1650 - val_loss: 1933797.5000 - val_mae: 1146.1595\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 44502444.0000 - mae: 2893.1487 - val_loss: 1933796.6250 - val_mae: 1146.1652\n",
      "1/1 [==============================] - 0s 154ms/step\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = scaler.fit_transform(X_train_nn)\n",
    "X_test_nn = scaler.transform(X_test_nn)\n",
    "\n",
    "# fit the model on the X_train and y_train\n",
    "model = Sequential()\n",
    "# model.add(Dense(256, activation=\"relu\", input_dim=X_train_nn.shape[1]))  # First layer\n",
    "# model.add(Dense(128, activation=\"relu\"))  # First layer\n",
    "# model.add(Dense(64, activation=\"relu\"))  # First layer\n",
    "model.add(Dense(32, activation=\"relu\", input_dim=X_train_nn.shape[1]))  # Fourth layer\n",
    "model.add(Dense(16, activation=\"relu\"))  # New additional layer\n",
    "model.add(Dense(8, activation=\"relu\"))  # New additional layer\n",
    "model.add(Dense(1, activation = 'linear')) \n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "model.fit(X_train_nn, y_train_nn, epochs=1000, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# # get the predictions\n",
    "# boolean_columns = [col for col in X_test_nn.columns if X_test_nn[col].dtype == bool]\n",
    "# for col in boolean_columns:\n",
    "#     X_test_nn[col] = X_test_nn[col].astype(int)\n",
    "\n",
    "y_pred = model.predict(X_test_nn).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.433042733184804e-06\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_pred)/ukraine_2021[\"real_gdp\"].sum())\n",
    "\n",
    "pred_data_diff[\"gdp_prediction\"] = y_pred\n",
    "ukraine_2022_pred = pd.merge(ukraine_2022, pred_data_diff[[\"region\", \"year\", \"gdp_prediction\"]], on=[\"region\", \"year\"])\n",
    "ukraine_2022_pred = ukraine_2022_pred[[\"region\", \"year\", \"gdp_prediction\"]]\n",
    "ukraine_2022_pred = pd.merge(ukraine_2022_pred, ukraine_2021[[\"region\", \"year\", \"real_gdp\"]], on=[\"region\"])\n",
    "ukraine_2022_pred[\"gdp_prediction\"] = ukraine_2022_pred[\"gdp_prediction\"] + ukraine_2022_pred[\"real_gdp\"]\n",
    "ukraine_2022_pred = ukraine_2022_pred[[\"region\", \"gdp_prediction\"]]\n",
    "\n",
    "# ukraine_2022_pred.to_csv(\"gdp_predictions_ukraine_on_sc_lq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3276464907828875\n"
     ]
    }
   ],
   "source": [
    "### RESULTS\n",
    "# All Angles, Snow Free, High-Quality: -29.4%\n",
    "# Near Nadir, Snow Free, High-Quality: -39.3%\n",
    "# Off Nadir, Snow Free, High-Quality: -12.6%\n",
    "# All Angles, Snow Covered, High-Quality: \n",
    "# Near Nadir, Snow Covered, High-Quality\n",
    "# Off Nadir, Snow Covered, High-Quality: \n",
    "# All Angles, Snow Free, All-Quality: -36.9%\n",
    "# Near Nadir, Snow Free, All-Quality: -40.8%\n",
    "# Off Nadir, Snow Free, All-Quality: -16.1%\n",
    "# All Angles, Snow Covered, All-Quality: -7.7%\n",
    "# Near Nadir, Snow Covered, All-Quality: -5.0%\n",
    "# Off Nadir, Snow Covered, All-Quality: -6.4%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
